{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm as notebook_tqdm\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from datasets import load_dataset\n",
    "from sacrebleu.metrics import BLEU\n",
    "from tqdm import tqdm\n",
    "import sentencepiece as spm\n",
    "import ctranslate2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/zindi\n"
     ]
    }
   ],
   "source": [
    "# %cd /home/rana/Projects/zindi\n",
    "%cd /root/zindi/\n",
    "import yaml\n",
    "with open('common/config.yaml', 'r') as f:\n",
    "    config = yaml.load(f, Loader=yaml.SafeLoader)\n",
    "\n",
    "checkpoint = config.get('checkpoint')\n",
    "new_model_path=config.get('new_model_path')+checkpoint\n",
    "ct_model_path=config.get('ct_model_path')+checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Translating:   0%|          | 6/1471 [00:00<00:29, 50.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comment t ⁇ appelles-tu ? ---- Tu portes un nom de fantaisie.\n",
      "Les trois premiers. ---- Trois points d’avance.\n",
      "L'écoulement de soleil ---- Le soleil s’est couché.\n",
      "À propos de l'une ---- Mêmes mouvements.\n",
      "Nous n'avons pas de nourriture. ---- Je n’ai pas encore déjeuné.\n",
      "\" Elle m'a ouvert la bouche. ---- Arrêtez de vous moquer de moi.\n",
      "Je suis américain. ---- Je suis Américain.\n",
      "Monsieur Dextrine, monsieur le député ---- Merci, monsieur le député\n",
      "Il n'a jamais connu son père ---- Jean n’a pas connu son père.\n",
      "Nous devons le mettre à l'intérieur. ---- Il faudra rentrer dedans.\n",
      "0 ---- Neuf heures dix.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Translating:   1%|          | 18/1471 [00:00<00:27, 53.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ça va faire peur. ---- Cela serait épouvantable.\n",
      "\" Qu'est-ce que je vais faire ? ---- Comment je fais pour y aller ?\n",
      "Ma mère me l'a dit de nouveau. ---- Ma mère me le répète.\n",
      "Certains sont très tôt installés. ---- D’autres maisons plus jaunes.\n",
      "Quel est l'hommage du sang ? ---- Ce coureur était le combien ?\n",
      "J'ai pris les nombres suivants. ---- J'étais à deux pas.\n",
      "Je vous trouve à la porte. ---- J'ouvre la porte.\n",
      "Qu ⁇ est-ce que vous avez fait ? ---- Et pourquoi donc ?\n",
      "Vous savez que vous n'avez pas confiance en vous ---- Que vous soyez retenue ou non.\n",
      "Regard sur l'homme de Canaan ---- Hum! fit le Canadien.\n",
      "Il répondit à la question. ---- Jusqu'à en tomber amoureuse...\n",
      "deux portes. ---- C'est deux francs !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Translating:   2%|▏         | 31/1471 [00:00<00:25, 56.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Est-ce qu'il est venu ici ? ---- Il est venu ici hier ?\n",
      "0 ---- Voilà qui est bien !\n",
      "C ⁇ est mon premier frère. ---- C’est mon frère ainé.\n",
      "Il s'inclina. ---- Il se trouve à Elgin.\n",
      "L'intégrité dans la bonté ---- Juste d’une bonne occasion.\n",
      "Puis les parents s'en sont sortis. ---- Puis les parents craquent.\n",
      "Elle va à l'école ---- il va à l'école.\n",
      "Il m'a ouvert les yeux ---- Il venait souvent me voir.\n",
      "Les bienfaits de la jeunesse ---- La principale leçon.\n",
      "0 ---- Défais ce bouton.\n",
      "\" Vous devez avoir de bonnes relations avec un homme. ---- Elle est jolie votre raison !…\n",
      "Vous n'êtes pas un farceur. ---- Il ne s’agit pas d’un jeu.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Translating:   3%|▎         | 43/1471 [00:00<00:25, 56.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Je suis sûr qu ⁇ il aimera. ---- Je suis sûr que j’aimerai.\n",
      "Mais elle ne parlait pas. ---- Mais il ne parlait pas.\n",
      "L'obéissance est une injustice ---- Son attente fut vaine.\n",
      "Il y en a un autre. ---- La réalité est tout autre.\n",
      "La fête de Pâques ---- Lundi de Pâques.\n",
      "Mais qu'est-ce que le prélèvement? ---- Comment allez-vous ?\n",
      "J'ai un b.B.C. ---- Je suis diplômé de B.E.\n",
      "Ses parents ne sont pas d'accord. ---- Ses parents sont séparés.\n",
      "Demain on cherchera un poisson. ---- demain nous pêcherons.\n",
      "0 ---- Vingt-quatre jeux.\n",
      "vingt et un. ---- Un vingt-et-unième.\n",
      "0 ---- Il faut que je travaille.\n",
      "C ⁇ est mon fils ! ---- Ah ! c’est mon fils.\n",
      "0 ---- Je suis toute mouillée.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Translating:   4%|▍         | 58/1471 [00:01<00:23, 60.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le langage de l'avoine ---- Vous parlez français ?\n",
      "vingt et une chiennes. ---- vingt et une chiennes.\n",
      "Deux femmes ont été tuées. ---- Elle jouait avec elle.\n",
      "Un oiseau qui se tient sur nos genoux. ---- Je suis soumise, testez-moi!\n",
      "Il s'est bien amusé ! ---- Ah ! c’est très fort !\n",
      "Maintenant, c ⁇ est Sarah. ---- Paris, de nos jours.\n",
      "C ⁇ est un professeur. ---- C’est votre entraineur ?\n",
      "Avez-vous déjà eu l ⁇ occasion d ⁇ apprendre ? ---- Tu apprends bien tes leçons.\n",
      "J ⁇ ai toujours aimé. ---- Je suis sûr que j’aurais aimé.\n",
      "0 ---- Il est malheureux\n",
      "C ⁇ est le sang de la même journée. ---- Combien ça coûte par jour ?\n",
      "0 ---- Voilà qui est bien\n",
      "Rue Achiten, Aurillon ---- L'action se déroule à Palerme.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Translating:   5%|▍         | 69/1471 [00:01<00:24, 56.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Je ne sais pas ce qu ⁇ il veut. ---- je ne sais pas ce qu'il veut.\n",
      "0 ---- Peut-être que j’irai.\n",
      "- Vous comprenez ? ---- Vous conprenez ?\n",
      "Je ne l'ai pas vue. ---- Je ne les ai pas trouvés.\n",
      "La voix est trop haute. ---- un longue lettre.\n",
      "0 ---- Un pressoir daté du le jouxte.\n",
      "La paix dans le monde ? ---- mille cent onze-deux et L.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[68], line 54\u001b[0m\n\u001b[1;32m     51\u001b[0m     bleu_score \u001b[38;5;241m=\u001b[39m calculate_bleu(references, hypotheses)\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBLEU Score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbleu_score\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 54\u001b[0m \u001b[43mvalidate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mct_model_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muvci/Koumankan_mt_dyu_fr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalidation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[68], line 45\u001b[0m, in \u001b[0;36mvalidate_model\u001b[0;34m(model_path, dataset_name, split)\u001b[0m\n\u001b[1;32m     41\u001b[0m reference \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtranslation\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfr\u001b[39m\u001b[38;5;124m'\u001b[39m]  \u001b[38;5;66;03m# Adjust this based on your dataset's column names\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# translation = translate(translator, tokenizer, source_text, device)[0]\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# tokenizer=None\u001b[39;00m\n\u001b[0;32m---> 45\u001b[0m translation \u001b[38;5;241m=\u001b[39m \u001b[43mtranslate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtranslator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msource_text\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     46\u001b[0m hypotheses\u001b[38;5;241m.\u001b[39mappend(translation)\n\u001b[1;32m     47\u001b[0m references\u001b[38;5;241m.\u001b[39mappend(reference)\n",
      "Cell \u001b[0;32mIn[68], line 15\u001b[0m, in \u001b[0;36mtranslate\u001b[0;34m(translator, text)\u001b[0m\n\u001b[1;32m     13\u001b[0m tokens \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdyu\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m tokens \u001b[38;5;241m+\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m</s>\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfra\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 15\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mtranslator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranslate_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;66;03m# The translated results are token strings, so we need to convert them to IDs before decoding\u001b[39;00m\n\u001b[1;32m     17\u001b[0m     translations \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "### Eval ct model\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "sp_source_model = spm.SentencePieceProcessor(model_file=ct_model_path+'/source.spm')\n",
    "sp_target_model = spm.SentencePieceProcessor(model_file=ct_model_path+'/target.spm')\n",
    "\n",
    "\n",
    "def translate(translator, text):\n",
    "    tokens = sp_source_model.encode(text, out_type=str)\n",
    "    # print(tokens)\n",
    "    tokens = ['dyu'] + tokens + [\"</s>\"] +['fra']\n",
    "    try:\n",
    "        results = translator.translate_batch([tokens])\n",
    "        # The translated results are token strings, so we need to convert them to IDs before decoding\n",
    "        translations = []\n",
    "        for translation in results:\n",
    "            decoded_text = sp_target_model.decode(translation.hypotheses[0])\n",
    "            translations.append(decoded_text)\n",
    "    except Exception as e:\n",
    "        print(f\"Translation error: {e}\")\n",
    "        translations = [\"\"]  # Return empty string if translation fails\n",
    "    return translations\n",
    "\n",
    "def calculate_bleu(references, hypotheses):\n",
    "    bleu = BLEU()\n",
    "    return bleu.corpus_score(hypotheses, [references]).score\n",
    "\n",
    "def validate_model(model_path, dataset_name, split):\n",
    "    # Load CTranslate2 model\n",
    "    translator = ctranslate2.Translator(model_path, device=device)\n",
    "    # Load dataset\n",
    "    dataset = load_dataset(dataset_name, split=split)\n",
    "    # Translate and calculate BLEU score\n",
    "    hypotheses = []\n",
    "    references = []\n",
    "\n",
    "    for batch in tqdm(dataset, desc=\"Translating\"):\n",
    "        source_text = batch['translation']['dyu']  # Adjust this based on your dataset's column names\n",
    "        reference = batch['translation']['fr']  # Adjust this based on your dataset's column names\n",
    "        \n",
    "        # translation = translate(translator, tokenizer, source_text, device)[0]\n",
    "        # tokenizer=None\n",
    "        translation = translate(translator, source_text)[0]\n",
    "        hypotheses.append(translation)\n",
    "        references.append(reference)\n",
    "        # print(translation, \"----\", reference)\n",
    "        # break\n",
    "\n",
    "    bleu_score = calculate_bleu(references, hypotheses)\n",
    "    print(f\"BLEU Score: {bleu_score:.2f}\")\n",
    "\n",
    "validate_model(ct_model_path, \"uvci/Koumankan_mt_dyu_fr\", \"validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Translating: 100%|██████████| 8065/8065 [02:58<00:00, 45.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score: 7.67\n"
     ]
    }
   ],
   "source": [
    "validate_model(ct_model_path, \"uvci/Koumankan_mt_dyu_fr\", \"train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Eval original model \n",
    "\n",
    "# def translate(model, tokenizer, text, device):\n",
    "#     inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=150).to(device)\n",
    "#     translated = model.generate(**inputs)\n",
    "#     return tokenizer.batch_decode(translated, skip_special_tokens=True)\n",
    "\n",
    "# def calculate_bleu(references, hypotheses):\n",
    "#     bleu = BLEU()\n",
    "#     return bleu.corpus_score(hypotheses, [references]).score\n",
    "\n",
    "# def validate_model(model_name, dataset_name, split):\n",
    "#     device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#     print(f\"Using device: {device}\")\n",
    "\n",
    "#     # Load model and tokenizer\n",
    "#     tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "#     model = AutoModelForSeq2SeqLM.from_pretrained(model_name).to(device)\n",
    "\n",
    "#     # Load dataset\n",
    "#     dataset = load_dataset(dataset_name, split=split)\n",
    "\n",
    "#     # Translate and calculate BLEU score\n",
    "#     hypotheses = []\n",
    "#     references = []\n",
    "\n",
    "#     for batch in tqdm(dataset, desc=\"Translating\"):\n",
    "#         source_text = batch['translation']['dyu']  # Adjust this based on your dataset's column names\n",
    "#         reference = batch['translation']['fr']  # Adjust this based on your dataset's column names\n",
    "        \n",
    "#         translation = translate(model, tokenizer, source_text, device)[0]\n",
    "#         # print(reference)\n",
    "#         # print(translation)\n",
    "        \n",
    "#         hypotheses.append(translation)\n",
    "#         references.append(reference)\n",
    "#         # break\n",
    "\n",
    "#     bleu_score = calculate_bleu(references, hypotheses)\n",
    "#     print(f\"BLEU Score: {bleu_score:.2f}\")\n",
    "\n",
    "# # Run validation with GPU\n",
    "# # validate_model(model_checkpoint, \"uvci/Koumankan_mt_dyu_fr\", use_gpu=True)\n",
    "\n",
    "# # Run validation without GPU\n",
    "# validate_model(new_model_path, \"uvci/Koumankan_mt_dyu_fr\", \"validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zindi-z3yfXQo9-py3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
