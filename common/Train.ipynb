{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rana/Projects/zindi\n"
     ]
    }
   ],
   "source": [
    "%cd /home/rana/Projects/zindi\n",
    "# %cd /root/zindi/\n",
    "import yaml\n",
    "with open('common/config.yaml', 'r') as f:\n",
    "    config = yaml.load(f, Loader=yaml.SafeLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#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\n",
    "# !huggingface-cli login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Device specific params\n",
    "import os\n",
    "os.environ['model_name_or_path'] = \"Helsinki-NLP/opus-mt-af-fr\"\n",
    "os.environ['per_device_eval_batch_size']=\"1\"\n",
    "os.environ['per_device_train_batch_size']=\"1\"\n",
    "# use_cpu=False\n",
    "# os.environ['save_steps']=2000\n",
    "# os.environ['num_train_epochs']=10000.0\n",
    "# os.environ['logging_steps']=10\n",
    "# os.environ['label_smoothing_factor']=0.00001\n",
    "# os.environ['learning_rate']=5e-04\n",
    "# os.environ['gradient_accumulation_steps']=8\n",
    "# os.environ['generation_max_length']=150\n",
    "# os.environ['generation_num_beams']=1\n",
    "# os.environ['max_source_length']= 150\n",
    "# os.environ['warmup_steps']=10\n",
    "# os.environ['weight_decay']=0.00001\n",
    "# os.environ['seed']=42\n",
    "# os.environ['eval_steps']=50\n",
    "# os.environ['save_total_limit']=5\n",
    "# os.environ['overwrite_output_dir']=\"True\"\n",
    "# os.environ['fp16']=\"True\"\n",
    "# os.environ['fp16_backend']=\"auto\"\n",
    "# os.environ['fp16_full_eval']=\"True\"\n",
    "# os.environ['full_determinism']=\"True\"\n",
    "# os.environ['run_name']=\"marian-1\"\n",
    "# os.environ['output_dir']=\"../models/marian/marian_output\"\n",
    "\n",
    "# os.environ['dataset_name'] = \"uvci/Koumankan_mt_dyu_fr\"\n",
    "# os.environ['source_lang']=\"dyu\"\n",
    "# os.environ['target_lang']=\"fr\"\n",
    "# os.environ['dataset_config_name']= \"default\"\n",
    "# os.environ['predict_with_generate']=\"True\"\n",
    "# os.environ['dataloader_drop_last']=\"True\"\n",
    "\n",
    "# os.environ['jit_mode_eval']=\"False\"\n",
    "# os.environ['do_eval']=\"True\"\n",
    "# os.environ['do_predict']=\"False\"\n",
    "# os.environ['do_train']=\"True\"\n",
    "\n",
    "\n",
    "# model_name_or_path = \"Helsinki-NLP/opus-mt-af-fr\"\n",
    "# per_device_eval_batch_size=1\n",
    "# per_device_train_batch_size=1\n",
    "# # use_cpu=False\n",
    "# save_steps=2000\n",
    "# num_train_epochs=10000.0\n",
    "# logging_steps=10\n",
    "# label_smoothing_factor=0.00001\n",
    "# learning_rate=5e-04\n",
    "# gradient_accumulation_steps=8\n",
    "# generation_max_length=150\n",
    "# generation_num_beams=1\n",
    "# max_source_length= 150\n",
    "# warmup_steps=10\n",
    "# weight_decay=0.00001\n",
    "# seed=42\n",
    "# eval_steps=50\n",
    "# save_total_limit=5\n",
    "# overwrite_output_dir=\"True\"\n",
    "# fp16=\"True\"\n",
    "# fp16_backend=\"auto\"\n",
    "# fp16_full_eval=\"True\"\n",
    "# full_determinism=\"True\"\n",
    "# run_name=\"marian-1\"\n",
    "# output_dir=\"../models/marian/marian_output\"\n",
    "\n",
    "# dataset_name = \"uvci/Koumankan_mt_dyu_fr\"\n",
    "# source_lang=\"dyu\"\n",
    "# target_lang=\"fr\"\n",
    "# dataset_config_name= \"default\"\n",
    "# predict_with_generate=\"True\"\n",
    "# dataloader_drop_last=\"True\"\n",
    "\n",
    "# jit_mode_eval=\"False\"\n",
    "# do_eval=\"True\"\n",
    "# do_predict=\"False\"\n",
    "# do_train=\"True\"\n",
    "\n",
    "# Seq2SeqTrainingArguments(\n",
    "# _n_gpu=0,\n",
    "# accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\n",
    "# adafactor=False,\n",
    "# adam_beta1=0.9,\n",
    "# adam_beta2=0.999,\n",
    "# adam_epsilon=1e-08,\n",
    "# auto_find_batch_size=False,\n",
    "# batch_eval_metrics=False,\n",
    "# bf16=False,\n",
    "# bf16_full_eval=False,\n",
    "# data_seed=None,\n",
    "# dataloader_num_workers=0,\n",
    "# dataloader_persistent_workers=False,\n",
    "# dataloader_pin_memory=True,\n",
    "# dataloader_prefetch_factor=None,\n",
    "# ddp_backend=None,\n",
    "# ddp_broadcast_buffers=None,\n",
    "# ddp_bucket_cap_mb=None,\n",
    "# ddp_find_unused_parameters=None,\n",
    "# ddp_timeout=1800,\n",
    "# debug=[],\n",
    "# deepspeed=None,\n",
    "# disable_tqdm=False,\n",
    "# dispatch_batches=None,\n",
    "# eval_accumulation_steps=None,\n",
    "# eval_delay=0,\n",
    "# eval_do_concat_batches=True,\n",
    "# eval_on_start=False,\n",
    "# eval_strategy=no,\n",
    "# eval_use_gather_object=False,\n",
    "# evaluation_strategy=None,\n",
    "# fp16_opt_level=O1,\n",
    "# fsdp=[],\n",
    "# fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
    "# fsdp_min_num_params=0,\n",
    "# fsdp_transformer_layer_cls_to_wrap=None,\n",
    "# gradient_checkpointing=False,\n",
    "# gradient_checkpointing_kwargs=None,\n",
    "# greater_is_better=None,\n",
    "# group_by_length=False,\n",
    "# half_precision_backend=auto,\n",
    "# hub_always_push=False,\n",
    "# hub_model_id=None,\n",
    "# hub_private_repo=False,\n",
    "# hub_strategy=every_save,\n",
    "# hub_token=<HUB_TOKEN>,\n",
    "# ignore_data_skip=False,\n",
    "# include_inputs_for_metrics=False,\n",
    "# include_num_input_tokens_seen=False,\n",
    "# include_tokens_per_second=False,\n",
    "# label_names=None,\n",
    "# length_column_name=length,\n",
    "# load_best_model_at_end=False,\n",
    "# local_rank=0,\n",
    "# log_level=passive,\n",
    "# log_level_replica=warning,\n",
    "# log_on_each_node=True,\n",
    "# logging_first_step=False,\n",
    "# logging_nan_inf_filter=True,\n",
    "# logging_strategy=steps,\n",
    "# lr_scheduler_kwargs={},\n",
    "# lr_scheduler_type=linear,\n",
    "# max_grad_norm=1.0,\n",
    "# max_steps=-1,\n",
    "# metric_for_best_model=None,\n",
    "# mp_parameters=,\n",
    "# neftune_noise_alpha=None,\n",
    "# no_cuda=False,\n",
    "# optim=adamw_torch,\n",
    "# optim_args=None,\n",
    "# optim_target_modules=None,\n",
    "# past_index=-1,\n",
    "# predict_with_generate=True,\n",
    "# prediction_loss_only=False,\n",
    "# push_to_hub=False,\n",
    "# push_to_hub_model_id=None,\n",
    "# push_to_hub_organization=None,\n",
    "# push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
    "# ray_scope=last,\n",
    "# remove_unused_columns=True,\n",
    "# report_to=[],\n",
    "# restore_callback_states_from_checkpoint=False,\n",
    "# save_on_each_node=False,\n",
    "# save_only_model=False,\n",
    "# save_safetensors=True,\n",
    "# save_strategy=steps,\n",
    "# skip_memory_metrics=True,\n",
    "# sortish_sampler=False,\n",
    "# split_batches=None,\n",
    "# tf32=None,\n",
    "# torch_compile=False,\n",
    "# torch_compile_backend=None,\n",
    "# torch_compile_mode=None,\n",
    "# torch_empty_cache_steps=None,\n",
    "# torchdynamo=None,\n",
    "# tpu_metrics_debug=False,\n",
    "# tpu_num_cores=None,\n",
    "# use_ipex=False,\n",
    "# use_legacy_prediction_loop=False,\n",
    "# use_mps_device=False,\n",
    "# warmup_ratio=0.0,\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "!echo $$per_device_train_batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[59421]], 'forced_eos_token_id': 0}\n",
      "Some weights of MarianMTModel were not initialized from the model checkpoint at models/marian/marian_output/base_model and are newly initialized because the shapes did not match:\n",
      "- model.decoder.layers.0.fc1.bias: found shape torch.Size([2048]) in the checkpoint and torch.Size([1024]) in the model instantiated\n",
      "- model.decoder.layers.0.fc1.weight: found shape torch.Size([2048, 512]) in the checkpoint and torch.Size([1024, 512]) in the model instantiated\n",
      "- model.decoder.layers.0.fc2.weight: found shape torch.Size([512, 2048]) in the checkpoint and torch.Size([512, 1024]) in the model instantiated\n",
      "- model.decoder.layers.1.fc1.bias: found shape torch.Size([2048]) in the checkpoint and torch.Size([1024]) in the model instantiated\n",
      "- model.decoder.layers.1.fc1.weight: found shape torch.Size([2048, 512]) in the checkpoint and torch.Size([1024, 512]) in the model instantiated\n",
      "- model.decoder.layers.1.fc2.weight: found shape torch.Size([512, 2048]) in the checkpoint and torch.Size([512, 1024]) in the model instantiated\n",
      "- model.decoder.layers.2.fc1.bias: found shape torch.Size([2048]) in the checkpoint and torch.Size([1024]) in the model instantiated\n",
      "- model.decoder.layers.2.fc1.weight: found shape torch.Size([2048, 512]) in the checkpoint and torch.Size([1024, 512]) in the model instantiated\n",
      "- model.decoder.layers.2.fc2.weight: found shape torch.Size([512, 2048]) in the checkpoint and torch.Size([512, 1024]) in the model instantiated\n",
      "- model.decoder.layers.3.fc1.bias: found shape torch.Size([2048]) in the checkpoint and torch.Size([1024]) in the model instantiated\n",
      "- model.decoder.layers.3.fc1.weight: found shape torch.Size([2048, 512]) in the checkpoint and torch.Size([1024, 512]) in the model instantiated\n",
      "- model.decoder.layers.3.fc2.weight: found shape torch.Size([512, 2048]) in the checkpoint and torch.Size([512, 1024]) in the model instantiated\n",
      "- model.decoder.layers.4.fc1.bias: found shape torch.Size([2048]) in the checkpoint and torch.Size([1024]) in the model instantiated\n",
      "- model.decoder.layers.4.fc1.weight: found shape torch.Size([2048, 512]) in the checkpoint and torch.Size([1024, 512]) in the model instantiated\n",
      "- model.decoder.layers.4.fc2.weight: found shape torch.Size([512, 2048]) in the checkpoint and torch.Size([512, 1024]) in the model instantiated\n",
      "- model.decoder.layers.5.fc1.bias: found shape torch.Size([2048]) in the checkpoint and torch.Size([1024]) in the model instantiated\n",
      "- model.decoder.layers.5.fc1.weight: found shape torch.Size([2048, 512]) in the checkpoint and torch.Size([1024, 512]) in the model instantiated\n",
      "- model.decoder.layers.5.fc2.weight: found shape torch.Size([512, 2048]) in the checkpoint and torch.Size([512, 1024]) in the model instantiated\n",
      "- model.encoder.layers.0.fc1.bias: found shape torch.Size([2048]) in the checkpoint and torch.Size([1024]) in the model instantiated\n",
      "- model.encoder.layers.0.fc1.weight: found shape torch.Size([2048, 512]) in the checkpoint and torch.Size([1024, 512]) in the model instantiated\n",
      "- model.encoder.layers.0.fc2.weight: found shape torch.Size([512, 2048]) in the checkpoint and torch.Size([512, 1024]) in the model instantiated\n",
      "- model.encoder.layers.1.fc1.bias: found shape torch.Size([2048]) in the checkpoint and torch.Size([1024]) in the model instantiated\n",
      "- model.encoder.layers.1.fc1.weight: found shape torch.Size([2048, 512]) in the checkpoint and torch.Size([1024, 512]) in the model instantiated\n",
      "- model.encoder.layers.1.fc2.weight: found shape torch.Size([512, 2048]) in the checkpoint and torch.Size([512, 1024]) in the model instantiated\n",
      "- model.encoder.layers.2.fc1.bias: found shape torch.Size([2048]) in the checkpoint and torch.Size([1024]) in the model instantiated\n",
      "- model.encoder.layers.2.fc1.weight: found shape torch.Size([2048, 512]) in the checkpoint and torch.Size([1024, 512]) in the model instantiated\n",
      "- model.encoder.layers.2.fc2.weight: found shape torch.Size([512, 2048]) in the checkpoint and torch.Size([512, 1024]) in the model instantiated\n",
      "- model.encoder.layers.3.fc1.bias: found shape torch.Size([2048]) in the checkpoint and torch.Size([1024]) in the model instantiated\n",
      "- model.encoder.layers.3.fc1.weight: found shape torch.Size([2048, 512]) in the checkpoint and torch.Size([1024, 512]) in the model instantiated\n",
      "- model.encoder.layers.3.fc2.weight: found shape torch.Size([512, 2048]) in the checkpoint and torch.Size([512, 1024]) in the model instantiated\n",
      "- model.encoder.layers.4.fc1.bias: found shape torch.Size([2048]) in the checkpoint and torch.Size([1024]) in the model instantiated\n",
      "- model.encoder.layers.4.fc1.weight: found shape torch.Size([2048, 512]) in the checkpoint and torch.Size([1024, 512]) in the model instantiated\n",
      "- model.encoder.layers.4.fc2.weight: found shape torch.Size([512, 2048]) in the checkpoint and torch.Size([512, 1024]) in the model instantiated\n",
      "- model.encoder.layers.5.fc1.bias: found shape torch.Size([2048]) in the checkpoint and torch.Size([1024]) in the model instantiated\n",
      "- model.encoder.layers.5.fc1.weight: found shape torch.Size([2048, 512]) in the checkpoint and torch.Size([1024, 512]) in the model instantiated\n",
      "- model.encoder.layers.5.fc2.weight: found shape torch.Size([512, 2048]) in the checkpoint and torch.Size([512, 1024]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 512, 'bad_words_ids': [[59421]], 'forced_eos_token_id': 0}\n"
     ]
    }
   ],
   "source": [
    "### Update model config:\n",
    "import json\n",
    "base_model_path = \"models/marian/marian_output/base_model\"\n",
    "# Load model:\n",
    "from transformers import AutoModelForSeq2SeqLM\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name_or_path)\n",
    "# Save model\n",
    "model.save_pretrained(base_model_path)\n",
    "# Update config\n",
    "config_path = base_model_path+'/config.json'\n",
    "with open(config_path, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "data['decoder_attention_heads']=4\n",
    "data['decoder_ffn_dim']=1024\n",
    "data['decoder_layers']=6\n",
    "data['decoder_vocab_size']=59422\n",
    "data['dropout']=0.3\n",
    "data['encoder_attention_heads']=4\n",
    "data['encoder_ffn_dim']=1024\n",
    "data['encoder_layers']=6\n",
    "data['max_length']=512\n",
    "data['max_position_embeddings']=512\n",
    "data['num_beams']=1\n",
    "data['num_hidden_layers']=6\n",
    "data['torch_dtype']=\"float32\"\n",
    "data['vocab_size']=59422\n",
    "\n",
    "with open(config_path, 'w') as f:\n",
    "    json.dump(data, f, indent=2)\n",
    "\n",
    "# Update model_name_or_path\n",
    "model_name_or_path = base_model_path\n",
    "\n",
    "# Load model with updated config and save it\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name_or_path, ignore_mismatched_sizes=True)\n",
    "# Save model\n",
    "model.save_pretrained(base_model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GenerationConfig\n",
    "\n",
    "translation_generation_config = GenerationConfig(\n",
    "    num_beams=1,\n",
    "    max_length=128\n",
    ")\n",
    "translation_generation_config.save_pretrained(base_model_path, \"translation_generation_config.json\")\n",
    "generation_config=base_model_path+\"/translation_generation_config.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{per_device_train_batch_size}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: run_translation.py [-h] --model_name_or_path MODEL_NAME_OR_PATH\n",
      "                          [--config_name CONFIG_NAME]\n",
      "                          [--tokenizer_name TOKENIZER_NAME]\n",
      "                          [--cache_dir CACHE_DIR]\n",
      "                          [--use_fast_tokenizer [USE_FAST_TOKENIZER]]\n",
      "                          [--no_use_fast_tokenizer]\n",
      "                          [--model_revision MODEL_REVISION] [--token TOKEN]\n",
      "                          [--trust_remote_code [TRUST_REMOTE_CODE]]\n",
      "                          [--source_lang SOURCE_LANG]\n",
      "                          [--target_lang TARGET_LANG]\n",
      "                          [--dataset_name DATASET_NAME]\n",
      "                          [--dataset_config_name DATASET_CONFIG_NAME]\n",
      "                          [--train_file TRAIN_FILE]\n",
      "                          [--validation_file VALIDATION_FILE]\n",
      "                          [--test_file TEST_FILE]\n",
      "                          [--overwrite_cache [OVERWRITE_CACHE]]\n",
      "                          [--preprocessing_num_workers PREPROCESSING_NUM_WORKERS]\n",
      "                          [--max_source_length MAX_SOURCE_LENGTH]\n",
      "                          [--max_target_length MAX_TARGET_LENGTH]\n",
      "                          [--val_max_target_length VAL_MAX_TARGET_LENGTH]\n",
      "                          [--pad_to_max_length [PAD_TO_MAX_LENGTH]]\n",
      "                          [--max_train_samples MAX_TRAIN_SAMPLES]\n",
      "                          [--max_eval_samples MAX_EVAL_SAMPLES]\n",
      "                          [--max_predict_samples MAX_PREDICT_SAMPLES]\n",
      "                          [--num_beams NUM_BEAMS]\n",
      "                          [--ignore_pad_token_for_loss [IGNORE_PAD_TOKEN_FOR_LOSS]]\n",
      "                          [--no_ignore_pad_token_for_loss]\n",
      "                          [--source_prefix SOURCE_PREFIX]\n",
      "                          [--forced_bos_token FORCED_BOS_TOKEN] --output_dir\n",
      "                          OUTPUT_DIR\n",
      "                          [--overwrite_output_dir [OVERWRITE_OUTPUT_DIR]]\n",
      "                          [--do_train [DO_TRAIN]] [--do_eval [DO_EVAL]]\n",
      "                          [--do_predict [DO_PREDICT]]\n",
      "                          [--eval_strategy {no,steps,epoch}]\n",
      "                          [--prediction_loss_only [PREDICTION_LOSS_ONLY]]\n",
      "                          [--per_device_train_batch_size PER_DEVICE_TRAIN_BATCH_SIZE]\n",
      "                          [--per_device_eval_batch_size PER_DEVICE_EVAL_BATCH_SIZE]\n",
      "                          [--per_gpu_train_batch_size PER_GPU_TRAIN_BATCH_SIZE]\n",
      "                          [--per_gpu_eval_batch_size PER_GPU_EVAL_BATCH_SIZE]\n",
      "                          [--gradient_accumulation_steps GRADIENT_ACCUMULATION_STEPS]\n",
      "                          [--eval_accumulation_steps EVAL_ACCUMULATION_STEPS]\n",
      "                          [--eval_delay EVAL_DELAY]\n",
      "                          [--torch_empty_cache_steps TORCH_EMPTY_CACHE_STEPS]\n",
      "                          [--learning_rate LEARNING_RATE]\n",
      "                          [--weight_decay WEIGHT_DECAY]\n",
      "                          [--adam_beta1 ADAM_BETA1] [--adam_beta2 ADAM_BETA2]\n",
      "                          [--adam_epsilon ADAM_EPSILON]\n",
      "                          [--max_grad_norm MAX_GRAD_NORM]\n",
      "                          [--num_train_epochs NUM_TRAIN_EPOCHS]\n",
      "                          [--max_steps MAX_STEPS]\n",
      "                          [--lr_scheduler_type {linear,cosine,cosine_with_restarts,polynomial,constant,constant_with_warmup,inverse_sqrt,reduce_lr_on_plateau,cosine_with_min_lr,warmup_stable_decay}]\n",
      "                          [--lr_scheduler_kwargs LR_SCHEDULER_KWARGS]\n",
      "                          [--warmup_ratio WARMUP_RATIO]\n",
      "                          [--warmup_steps WARMUP_STEPS]\n",
      "                          [--log_level {detail,debug,info,warning,error,critical,passive}]\n",
      "                          [--log_level_replica {detail,debug,info,warning,error,critical,passive}]\n",
      "                          [--log_on_each_node [LOG_ON_EACH_NODE]]\n",
      "                          [--no_log_on_each_node] [--logging_dir LOGGING_DIR]\n",
      "                          [--logging_strategy {no,steps,epoch}]\n",
      "                          [--logging_first_step [LOGGING_FIRST_STEP]]\n",
      "                          [--logging_steps LOGGING_STEPS]\n",
      "                          [--logging_nan_inf_filter [LOGGING_NAN_INF_FILTER]]\n",
      "                          [--no_logging_nan_inf_filter]\n",
      "                          [--save_strategy {no,steps,epoch}]\n",
      "                          [--save_steps SAVE_STEPS]\n",
      "                          [--save_total_limit SAVE_TOTAL_LIMIT]\n",
      "                          [--save_safetensors [SAVE_SAFETENSORS]]\n",
      "                          [--no_save_safetensors]\n",
      "                          [--save_on_each_node [SAVE_ON_EACH_NODE]]\n",
      "                          [--save_only_model [SAVE_ONLY_MODEL]]\n",
      "                          [--restore_callback_states_from_checkpoint [RESTORE_CALLBACK_STATES_FROM_CHECKPOINT]]\n",
      "                          [--no_cuda [NO_CUDA]] [--use_cpu [USE_CPU]]\n",
      "                          [--use_mps_device [USE_MPS_DEVICE]] [--seed SEED]\n",
      "                          [--data_seed DATA_SEED]\n",
      "                          [--jit_mode_eval [JIT_MODE_EVAL]]\n",
      "                          [--use_ipex [USE_IPEX]] [--bf16 [BF16]]\n",
      "                          [--fp16 [FP16]] [--fp16_opt_level FP16_OPT_LEVEL]\n",
      "                          [--half_precision_backend {auto,apex,cpu_amp}]\n",
      "                          [--bf16_full_eval [BF16_FULL_EVAL]]\n",
      "                          [--fp16_full_eval [FP16_FULL_EVAL]] [--tf32 TF32]\n",
      "                          [--local_rank LOCAL_RANK]\n",
      "                          [--ddp_backend {nccl,gloo,mpi,ccl,hccl,cncl}]\n",
      "                          [--tpu_num_cores TPU_NUM_CORES]\n",
      "                          [--tpu_metrics_debug [TPU_METRICS_DEBUG]]\n",
      "                          [--debug DEBUG [DEBUG ...]]\n",
      "                          [--dataloader_drop_last [DATALOADER_DROP_LAST]]\n",
      "                          [--eval_steps EVAL_STEPS]\n",
      "                          [--dataloader_num_workers DATALOADER_NUM_WORKERS]\n",
      "                          [--dataloader_prefetch_factor DATALOADER_PREFETCH_FACTOR]\n",
      "                          [--past_index PAST_INDEX] [--run_name RUN_NAME]\n",
      "                          [--disable_tqdm DISABLE_TQDM]\n",
      "                          [--remove_unused_columns [REMOVE_UNUSED_COLUMNS]]\n",
      "                          [--no_remove_unused_columns]\n",
      "                          [--label_names LABEL_NAMES [LABEL_NAMES ...]]\n",
      "                          [--load_best_model_at_end [LOAD_BEST_MODEL_AT_END]]\n",
      "                          [--metric_for_best_model METRIC_FOR_BEST_MODEL]\n",
      "                          [--greater_is_better GREATER_IS_BETTER]\n",
      "                          [--ignore_data_skip [IGNORE_DATA_SKIP]]\n",
      "                          [--fsdp FSDP]\n",
      "                          [--fsdp_min_num_params FSDP_MIN_NUM_PARAMS]\n",
      "                          [--fsdp_config FSDP_CONFIG]\n",
      "                          [--fsdp_transformer_layer_cls_to_wrap FSDP_TRANSFORMER_LAYER_CLS_TO_WRAP]\n",
      "                          [--accelerator_config ACCELERATOR_CONFIG]\n",
      "                          [--deepspeed DEEPSPEED]\n",
      "                          [--label_smoothing_factor LABEL_SMOOTHING_FACTOR]\n",
      "                          [--optim {adamw_hf,adamw_torch,adamw_torch_fused,adamw_torch_xla,adamw_torch_npu_fused,adamw_apex_fused,adafactor,adamw_anyprecision,sgd,adagrad,adamw_bnb_8bit,adamw_8bit,lion_8bit,lion_32bit,paged_adamw_32bit,paged_adamw_8bit,paged_lion_32bit,paged_lion_8bit,rmsprop,rmsprop_bnb,rmsprop_bnb_8bit,rmsprop_bnb_32bit,galore_adamw,galore_adamw_8bit,galore_adafactor,galore_adamw_layerwise,galore_adamw_8bit_layerwise,galore_adafactor_layerwise,lomo,adalomo}]\n",
      "                          [--optim_args OPTIM_ARGS] [--adafactor [ADAFACTOR]]\n",
      "                          [--group_by_length [GROUP_BY_LENGTH]]\n",
      "                          [--length_column_name LENGTH_COLUMN_NAME]\n",
      "                          [--report_to REPORT_TO]\n",
      "                          [--ddp_find_unused_parameters DDP_FIND_UNUSED_PARAMETERS]\n",
      "                          [--ddp_bucket_cap_mb DDP_BUCKET_CAP_MB]\n",
      "                          [--ddp_broadcast_buffers DDP_BROADCAST_BUFFERS]\n",
      "                          [--dataloader_pin_memory [DATALOADER_PIN_MEMORY]]\n",
      "                          [--no_dataloader_pin_memory]\n",
      "                          [--dataloader_persistent_workers [DATALOADER_PERSISTENT_WORKERS]]\n",
      "                          [--skip_memory_metrics [SKIP_MEMORY_METRICS]]\n",
      "                          [--no_skip_memory_metrics]\n",
      "                          [--use_legacy_prediction_loop [USE_LEGACY_PREDICTION_LOOP]]\n",
      "                          [--push_to_hub [PUSH_TO_HUB]]\n",
      "                          [--resume_from_checkpoint RESUME_FROM_CHECKPOINT]\n",
      "                          [--hub_model_id HUB_MODEL_ID]\n",
      "                          [--hub_strategy {end,every_save,checkpoint,all_checkpoints}]\n",
      "                          [--hub_token HUB_TOKEN]\n",
      "                          [--hub_private_repo [HUB_PRIVATE_REPO]]\n",
      "                          [--hub_always_push [HUB_ALWAYS_PUSH]]\n",
      "                          [--gradient_checkpointing [GRADIENT_CHECKPOINTING]]\n",
      "                          [--gradient_checkpointing_kwargs GRADIENT_CHECKPOINTING_KWARGS]\n",
      "                          [--include_inputs_for_metrics [INCLUDE_INPUTS_FOR_METRICS]]\n",
      "                          [--eval_do_concat_batches [EVAL_DO_CONCAT_BATCHES]]\n",
      "                          [--no_eval_do_concat_batches]\n",
      "                          [--fp16_backend {auto,apex,cpu_amp}]\n",
      "                          [--evaluation_strategy {no,steps,epoch}]\n",
      "                          [--push_to_hub_model_id PUSH_TO_HUB_MODEL_ID]\n",
      "                          [--push_to_hub_organization PUSH_TO_HUB_ORGANIZATION]\n",
      "                          [--push_to_hub_token PUSH_TO_HUB_TOKEN]\n",
      "                          [--mp_parameters MP_PARAMETERS]\n",
      "                          [--auto_find_batch_size [AUTO_FIND_BATCH_SIZE]]\n",
      "                          [--full_determinism [FULL_DETERMINISM]]\n",
      "                          [--torchdynamo TORCHDYNAMO] [--ray_scope RAY_SCOPE]\n",
      "                          [--ddp_timeout DDP_TIMEOUT]\n",
      "                          [--torch_compile [TORCH_COMPILE]]\n",
      "                          [--torch_compile_backend TORCH_COMPILE_BACKEND]\n",
      "                          [--torch_compile_mode TORCH_COMPILE_MODE]\n",
      "                          [--dispatch_batches DISPATCH_BATCHES]\n",
      "                          [--split_batches SPLIT_BATCHES]\n",
      "                          [--include_tokens_per_second [INCLUDE_TOKENS_PER_SECOND]]\n",
      "                          [--include_num_input_tokens_seen [INCLUDE_NUM_INPUT_TOKENS_SEEN]]\n",
      "                          [--neftune_noise_alpha NEFTUNE_NOISE_ALPHA]\n",
      "                          [--optim_target_modules OPTIM_TARGET_MODULES]\n",
      "                          [--batch_eval_metrics [BATCH_EVAL_METRICS]]\n",
      "                          [--eval_on_start [EVAL_ON_START]]\n",
      "                          [--eval_use_gather_object [EVAL_USE_GATHER_OBJECT]]\n",
      "                          [--sortish_sampler [SORTISH_SAMPLER]]\n",
      "                          [--predict_with_generate [PREDICT_WITH_GENERATE]]\n",
      "                          [--generation_max_length GENERATION_MAX_LENGTH]\n",
      "                          [--generation_num_beams GENERATION_NUM_BEAMS]\n",
      "                          [--generation_config GENERATION_CONFIG]\n",
      "run_translation.py: error: the following arguments are required: --model_name_or_path, --output_dir\n"
     ]
    }
   ],
   "source": [
    "!python transformers/examples/pytorch/translation/run_translation.py \\\n",
    "--per_device_train_batch_size $$per_device_train_batch_size\n",
    "\n",
    "\n",
    "# --save_steps {save_steps} \\\n",
    "# --num_train_epochs {num_train_epochs} \\\n",
    "# --logging_steps {logging_steps} \\\n",
    "# --label_smoothing_factor {label_smoothing_factor} \\\n",
    "# --learning_rate {learning_rate} \\\n",
    "# --run_name {run_name} \\\n",
    "# --output_dir {output_dir} \\\n",
    "# --logging_dir {logging_dir} \\\n",
    "# --eval_steps {eval_steps} \\\n",
    "# --gradient_accumulation_steps {gradient_accumulation_steps} \\\n",
    "# --model_name_or_path  {model_name_or_path } \\\n",
    "# --dataset_name  {dataset_name } \\\n",
    "# --generation_max_length {generation_max_length} \\\n",
    "# --generation_num_beams {generation_num_beams} \\\n",
    "# --source_lang {source_lang} \\\n",
    "# --target_lang {target_lang} \\\n",
    "# --dataset_config_name {dataset_config_name} \\\n",
    "# --predict_with_generate {predict_with_generate} \\\n",
    "# --max_source_length {max_source_length} \\\n",
    "# --dataloader_drop_last {dataloader_drop_last} \\\n",
    "# --warmup_steps {warmup_steps} \\\n",
    "# --weight_decay {weight_decay} \\\n",
    "# --save_total_limit {save_total_limit} \\\n",
    "# --seed {seed} \\\n",
    "# --overwrite_output_dir {overwrite_output_dir} \\\n",
    "# --jit_mode_eval {jit_mode_eval} \\\n",
    "# --do_eval {do_eval} \\\n",
    "# --do_predict {do_predict} \\\n",
    "# --do_train {do_train} \\\n",
    "# --fp16 {fp16} \\\n",
    "# --fp16_backend {fp16_backend} \\\n",
    "# --fp16_full_eval {fp16_full_eval} \\\n",
    "# --full_determinism {full_determinism} \\\n",
    "# --generation_config {generation_config}\n",
    "# --resume_from_checkpoint {resume_from_checkpoint} \n",
    "# --use_cpu {use_cpu} \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "!echo $per_device_train_batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1.0}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{per_device_train_batch_size}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zindi-z3yfXQo9-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
