{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/zindi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.cache/pypoetry/virtualenvs/zindi-LtLKIbXv-py3.9/lib/python3.9/site-packages/IPython/core/magics/osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "# %cd /home/rana/Projects/zindi\n",
    "%cd /root/zindi/\n",
    "import yaml\n",
    "with open('common/config.yaml', 'r') as f:\n",
    "    config = yaml.load(f, Loader=yaml.SafeLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#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\n",
    "# !huggingface-cli login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_path = \"models/marian/marian_output/checkpoint-3750\"\n",
    "# custom_tokenizer_path = \"/home/rana/Projects/zindi/tokenizer_custom/combined_pad_V1\"\n",
    "custom_tokenizer_path = \"/root/zindi/tokenizer_custom/combined_pad_V1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save tokenizer in base_path\n",
    "# from transformers import MarianTokenizer\n",
    "# tokenizer = MarianTokenizer.from_pretrained(os.environ['model_name_or_path'])\n",
    "# tokenizer.save_pretrained(base_model_path)\n",
    "\n",
    "#Copy custom tokenizer to base path\n",
    "# !rm -rf {base_model_path}\n",
    "!cp -r {custom_tokenizer_path} {base_model_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[59421]], 'forced_eos_token_id': 0}\n",
      "Some weights of MarianMTModel were not initialized from the model checkpoint at models/marian/marian_output/base_model and are newly initialized because the shapes did not match:\n",
      "- final_logits_bias: found shape torch.Size([1, 59422]) in the checkpoint and torch.Size([1, 32000]) in the model instantiated\n",
      "- model.shared.weight: found shape torch.Size([59422, 512]) in the checkpoint and torch.Size([32000, 512]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 128, 'bad_words_ids': [[31999]], 'forced_eos_token_id': 2}\n"
     ]
    }
   ],
   "source": [
    "### Update model config:\n",
    "import json\n",
    "\n",
    "# Load model:\n",
    "from transformers import AutoModelForSeq2SeqLM\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(os.environ['model_name_or_path'] )\n",
    "# Save model\n",
    "model.save_pretrained(base_model_path)\n",
    "# Update config\n",
    "config_path = base_model_path+'/config.json'\n",
    "with open(config_path, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# data['decoder_attention_heads']=4\n",
    "# data['decoder_ffn_dim']=1024\n",
    "# data['decoder_layers']=6\n",
    "# data['dropout']=0.3\n",
    "# data['encoder_attention_heads']=4\n",
    "# data['encoder_ffn_dim']=1024\n",
    "# data['encoder_layers']=6\n",
    "# data['max_position_embeddings']=512\n",
    "# data['num_hidden_layers']=6\n",
    "# data['torch_dtype']=\"float32\"\n",
    "\n",
    "data['max_length']=128\n",
    "data['num_beams']=1\n",
    "\n",
    "\n",
    "data[\"bos_token_id\"]= 1\n",
    "data[\"eos_token_id\"]= 2\n",
    "data[\"forced_eos_token_id\"]= 2\n",
    "data[\"bad_words_ids\"]= [[31999]]\n",
    "data[\"decoder_start_token_id\"]= 31999\n",
    "data['decoder_vocab_size']=32000\n",
    "data[\"pad_token_id\"]= 31999\n",
    "data['vocab_size']=32000\n",
    "\n",
    "# data[\"bos_token_id\"]= 0\n",
    "# data[\"eos_token_id\"]= 1\n",
    "# data[\"forced_eos_token_id\"]= 1\n",
    "# data[\"bad_words_ids\"]= [[59421]]\n",
    "# data[\"decoder_start_token_id\"]= 59421\n",
    "# data['decoder_vocab_size']=59422\n",
    "# data[\"pad_token_id\"]= 59421\n",
    "# data['vocab_size']=59422\n",
    "\n",
    "with open(config_path, 'w') as f:\n",
    "    json.dump(data, f, indent=2)\n",
    "\n",
    "# Update model_name_or_path\n",
    "model_name_or_path = base_model_path\n",
    "os.environ['model_name_or_path'] = base_model_path\n",
    "\n",
    "# Load model with updated config and save it\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name_or_path, ignore_mismatched_sizes=True)\n",
    "# Save model\n",
    "model.save_pretrained(base_model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 128, 'bad_words_ids': [[31999]], 'forced_eos_token_id': 2}\n"
     ]
    }
   ],
   "source": [
    "from transformers import GenerationConfig\n",
    "\n",
    "# Create a custom generation config\n",
    "custom_gen_config = GenerationConfig(\n",
    "    bad_words_ids=[[31999]],\n",
    "    bos_token_id=1,\n",
    "    decoder_start_token_id=31999,\n",
    "    eos_token_id=2,\n",
    "    forced_eos_token_id=2,\n",
    "    pad_token_id=31999,\n",
    "    num_beams=1,\n",
    "    max_length=128\n",
    "    # Add any other parameters you want to override\n",
    ")\n",
    "\n",
    "custom_gen_config.save_pretrained(base_model_path, \"generation_config.json\")\n",
    "os.environ['generation_config']=base_model_path+\"/generation_config.json\"\n",
    "\n",
    "# Save model\n",
    "model.generation_config=custom_gen_config\n",
    "model.save_pretrained(base_model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "368"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "del model\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Device specific params\n",
    "import os\n",
    "os.environ['model_name_or_path'] = \"Helsinki-NLP/opus-mt-af-fr\"\n",
    "os.environ['dataset_name'] = \"Rana-Banerjee/zindi-train-eval\"\n",
    "os.environ['source_lang']=\"dyu\"\n",
    "os.environ['target_lang']=\"fra\"\n",
    "os.environ['dataset_config_name']= \"default\"\n",
    "os.environ['per_device_eval_batch_size']=\"128\"\n",
    "os.environ['per_device_train_batch_size']=\"128\"\n",
    "# use_cpu=False\n",
    "os.environ['save_steps']=\"250\"\n",
    "os.environ['num_train_epochs']=\"10000\"\n",
    "os.environ['logging_steps']=\"10\"\n",
    "os.environ['save_total_limit']=\"15\"\n",
    "os.environ['overwrite_output_dir']=\"True\"\n",
    "os.environ['run_name']=\"marian-1\"\n",
    "os.environ['output_dir']=\"models/marian/marian_output\"\n",
    "os.environ['logging_dir']=\"models/marian/logs\"\n",
    "os.environ['predict_with_generate']=\"True\"\n",
    "os.environ['dataloader_drop_last']=\"True\"\n",
    "os.environ['jit_mode_eval']=\"False\"\n",
    "os.environ['do_eval']=\"True\"\n",
    "os.environ['do_predict']=\"False\"\n",
    "os.environ['do_train']=\"True\"\n",
    "\n",
    "### Config\n",
    "os.environ['label_smoothing_factor']=\"0.00001\"\n",
    "os.environ['learning_rate']=\"5e-04\"\n",
    "os.environ['gradient_accumulation_steps']=\"4\"\n",
    "os.environ['generation_max_length']=\"150\"\n",
    "os.environ['generation_num_beams']=\"1\"\n",
    "os.environ['max_source_length']= \"150\"\n",
    "os.environ['warmup_steps']=\"10\"\n",
    "os.environ['weight_decay']=\"0.00001\"\n",
    "os.environ['seed']=\"42\"\n",
    "os.environ['eval_steps']=\"50\"\n",
    "os.environ['fp16']=\"True\"\n",
    "os.environ['fp16_backend']=\"auto\"\n",
    "os.environ['fp16_full_eval']=\"True\"\n",
    "os.environ['full_determinism']=\"True\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08/14/2024 11:32:34 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: False, 16-bits training: True\n",
      "08/14/2024 11:32:34 - INFO - __main__ - Training/evaluation parameters Seq2SeqTrainingArguments(\n",
      "_n_gpu=1,\n",
      "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "batch_eval_metrics=False,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=True,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_persistent_workers=False,\n",
      "dataloader_pin_memory=True,\n",
      "dataloader_prefetch_factor=None,\n",
      "ddp_backend=None,\n",
      "ddp_broadcast_buffers=None,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=1800,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "dispatch_batches=None,\n",
      "do_eval=True,\n",
      "do_predict=False,\n",
      "do_train=True,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_do_concat_batches=True,\n",
      "eval_on_start=False,\n",
      "eval_steps=50.0,\n",
      "eval_strategy=no,\n",
      "eval_use_gather_object=False,\n",
      "evaluation_strategy=None,\n",
      "fp16=True,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=True,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[],\n",
      "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=True,\n",
      "generation_config=models/marian/marian_output/base_model/generation_config.json,\n",
      "generation_max_length=150,\n",
      "generation_num_beams=1,\n",
      "gradient_accumulation_steps=4,\n",
      "gradient_checkpointing=False,\n",
      "gradient_checkpointing_kwargs=None,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_always_push=False,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=False,\n",
      "hub_strategy=every_save,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_inputs_for_metrics=False,\n",
      "include_num_input_tokens_seen=False,\n",
      "include_tokens_per_second=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=1e-05,\n",
      "learning_rate=0.0005,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=0,\n",
      "log_level=passive,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=models/marian/logs,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=10,\n",
      "logging_strategy=steps,\n",
      "lr_scheduler_kwargs={},\n",
      "lr_scheduler_type=linear,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=None,\n",
      "mp_parameters=,\n",
      "neftune_noise_alpha=None,\n",
      "no_cuda=False,\n",
      "num_train_epochs=10000.0,\n",
      "optim=adamw_torch,\n",
      "optim_args=None,\n",
      "optim_target_modules=None,\n",
      "output_dir=models/marian/marian_output,\n",
      "overwrite_output_dir=True,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=8,\n",
      "per_device_train_batch_size=128,\n",
      "predict_with_generate=True,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=True,\n",
      "report_to=[],\n",
      "restore_callback_states_from_checkpoint=False,\n",
      "resume_from_checkpoint=None,\n",
      "run_name=marian-1,\n",
      "save_on_each_node=False,\n",
      "save_only_model=False,\n",
      "save_safetensors=True,\n",
      "save_steps=250,\n",
      "save_strategy=steps,\n",
      "save_total_limit=15,\n",
      "seed=42,\n",
      "skip_memory_metrics=True,\n",
      "sortish_sampler=False,\n",
      "split_batches=None,\n",
      "tf32=None,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torch_empty_cache_steps=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_cpu=False,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=10,\n",
      "weight_decay=1e-05,\n",
      ")\n",
      "Overwrite dataset info from restored data version if exists.\n",
      "08/14/2024 11:32:36 - INFO - datasets.builder - Overwrite dataset info from restored data version if exists.\n",
      "Loading Dataset info from /root/.cache/huggingface/datasets/Rana-Banerjee___zindi-train-eval/default/0.0.0/20b2fdc9e044d05f1d58171db4ba845ef9581f5a\n",
      "08/14/2024 11:32:36 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/Rana-Banerjee___zindi-train-eval/default/0.0.0/20b2fdc9e044d05f1d58171db4ba845ef9581f5a\n",
      "Found cached dataset zindi-train-eval (/root/.cache/huggingface/datasets/Rana-Banerjee___zindi-train-eval/default/0.0.0/20b2fdc9e044d05f1d58171db4ba845ef9581f5a)\n",
      "08/14/2024 11:32:36 - INFO - datasets.builder - Found cached dataset zindi-train-eval (/root/.cache/huggingface/datasets/Rana-Banerjee___zindi-train-eval/default/0.0.0/20b2fdc9e044d05f1d58171db4ba845ef9581f5a)\n",
      "Loading Dataset info from /root/.cache/huggingface/datasets/Rana-Banerjee___zindi-train-eval/default/0.0.0/20b2fdc9e044d05f1d58171db4ba845ef9581f5a\n",
      "08/14/2024 11:32:36 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/Rana-Banerjee___zindi-train-eval/default/0.0.0/20b2fdc9e044d05f1d58171db4ba845ef9581f5a\n",
      "[INFO|configuration_utils.py:733] 2024-08-14 11:32:36,773 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Helsinki-NLP--opus-mt-af-fr/snapshots/6cc04f6929b1a149e10f2cf565e5233f35e45ec3/config.json\n",
      "[INFO|configuration_utils.py:800] 2024-08-14 11:32:36,779 >> Model config MarianConfig {\n",
      "  \"_name_or_path\": \"Helsinki-NLP/opus-mt-af-fr\",\n",
      "  \"_num_labels\": 3,\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"swish\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"MarianMTModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59421\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_attention_heads\": 8,\n",
      "  \"decoder_ffn_dim\": 2048,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 59421,\n",
      "  \"decoder_vocab_size\": 59422,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 8,\n",
      "  \"encoder_ffn_dim\": 2048,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_length\": 512,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"marian\",\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": false,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 59421,\n",
      "  \"scale_embedding\": true,\n",
      "  \"share_encoder_decoder_embeddings\": true,\n",
      "  \"static_position_embeddings\": true,\n",
      "  \"transformers_version\": \"4.45.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 59422\n",
      "}\n",
      "\n",
      "[INFO|configuration_utils.py:733] 2024-08-14 11:32:36,907 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Helsinki-NLP--opus-mt-af-fr/snapshots/6cc04f6929b1a149e10f2cf565e5233f35e45ec3/config.json\n",
      "[INFO|configuration_utils.py:800] 2024-08-14 11:32:36,909 >> Model config MarianConfig {\n",
      "  \"_name_or_path\": \"Helsinki-NLP/opus-mt-af-fr\",\n",
      "  \"_num_labels\": 3,\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"swish\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"MarianMTModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59421\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_attention_heads\": 8,\n",
      "  \"decoder_ffn_dim\": 2048,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 59421,\n",
      "  \"decoder_vocab_size\": 59422,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 8,\n",
      "  \"encoder_ffn_dim\": 2048,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_length\": 512,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"marian\",\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": false,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 59421,\n",
      "  \"scale_embedding\": true,\n",
      "  \"share_encoder_decoder_embeddings\": true,\n",
      "  \"static_position_embeddings\": true,\n",
      "  \"transformers_version\": \"4.45.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 59422\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2269] 2024-08-14 11:32:36,911 >> loading file source.spm from cache at /root/.cache/huggingface/hub/models--Helsinki-NLP--opus-mt-af-fr/snapshots/6cc04f6929b1a149e10f2cf565e5233f35e45ec3/source.spm\n",
      "[INFO|tokenization_utils_base.py:2269] 2024-08-14 11:32:36,911 >> loading file target.spm from cache at /root/.cache/huggingface/hub/models--Helsinki-NLP--opus-mt-af-fr/snapshots/6cc04f6929b1a149e10f2cf565e5233f35e45ec3/target.spm\n",
      "[INFO|tokenization_utils_base.py:2269] 2024-08-14 11:32:36,911 >> loading file vocab.json from cache at /root/.cache/huggingface/hub/models--Helsinki-NLP--opus-mt-af-fr/snapshots/6cc04f6929b1a149e10f2cf565e5233f35e45ec3/vocab.json\n",
      "[INFO|tokenization_utils_base.py:2269] 2024-08-14 11:32:36,911 >> loading file target_vocab.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:2269] 2024-08-14 11:32:36,911 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--Helsinki-NLP--opus-mt-af-fr/snapshots/6cc04f6929b1a149e10f2cf565e5233f35e45ec3/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2269] 2024-08-14 11:32:36,911 >> loading file added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:2269] 2024-08-14 11:32:36,911 >> loading file special_tokens_map.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:2269] 2024-08-14 11:32:36,911 >> loading file tokenizer.json from cache at None\n",
      "[INFO|configuration_utils.py:733] 2024-08-14 11:32:36,912 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Helsinki-NLP--opus-mt-af-fr/snapshots/6cc04f6929b1a149e10f2cf565e5233f35e45ec3/config.json\n",
      "[INFO|configuration_utils.py:800] 2024-08-14 11:32:36,914 >> Model config MarianConfig {\n",
      "  \"_name_or_path\": \"Helsinki-NLP/opus-mt-af-fr\",\n",
      "  \"_num_labels\": 3,\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"swish\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"MarianMTModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59421\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_attention_heads\": 8,\n",
      "  \"decoder_ffn_dim\": 2048,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 59421,\n",
      "  \"decoder_vocab_size\": 59422,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 8,\n",
      "  \"encoder_ffn_dim\": 2048,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_length\": 512,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"marian\",\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": false,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 59421,\n",
      "  \"scale_embedding\": true,\n",
      "  \"share_encoder_decoder_embeddings\": true,\n",
      "  \"static_position_embeddings\": true,\n",
      "  \"transformers_version\": \"4.45.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 59422\n",
      "}\n",
      "\n",
      "/root/zindi/transformers/src/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "[INFO|modeling_utils.py:3657] 2024-08-14 11:32:37,607 >> loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--Helsinki-NLP--opus-mt-af-fr/snapshots/6cc04f6929b1a149e10f2cf565e5233f35e45ec3/pytorch_model.bin\n",
      "[INFO|configuration_utils.py:1038] 2024-08-14 11:32:37,778 >> Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59421\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59421,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59421\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:4489] 2024-08-14 11:32:38,997 >> All model checkpoint weights were used when initializing MarianMTModel.\n",
      "\n",
      "[INFO|modeling_utils.py:4497] 2024-08-14 11:32:38,997 >> All the weights of MarianMTModel were initialized from the model checkpoint at Helsinki-NLP/opus-mt-af-fr.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use MarianMTModel for predictions without further training.\n",
      "[INFO|configuration_utils.py:993] 2024-08-14 11:32:39,237 >> loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--Helsinki-NLP--opus-mt-af-fr/snapshots/6cc04f6929b1a149e10f2cf565e5233f35e45ec3/generation_config.json\n",
      "[INFO|configuration_utils.py:1038] 2024-08-14 11:32:39,237 >> Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59421\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59421,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59421,\n",
      "  \"renormalize_logits\": true\n",
      "}\n",
      "\n",
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/Rana-Banerjee___zindi-train-eval/default/0.0.0/20b2fdc9e044d05f1d58171db4ba845ef9581f5a/cache-a212183b7803882d.arrow\n",
      "08/14/2024 11:32:40 - INFO - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/Rana-Banerjee___zindi-train-eval/default/0.0.0/20b2fdc9e044d05f1d58171db4ba845ef9581f5a/cache-a212183b7803882d.arrow\n",
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/Rana-Banerjee___zindi-train-eval/default/0.0.0/20b2fdc9e044d05f1d58171db4ba845ef9581f5a/cache-a5ec87479dc40501.arrow\n",
      "08/14/2024 11:32:40 - INFO - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/Rana-Banerjee___zindi-train-eval/default/0.0.0/20b2fdc9e044d05f1d58171db4ba845ef9581f5a/cache-a5ec87479dc40501.arrow\n",
      "/root/.cache/pypoetry/virtualenvs/zindi-LtLKIbXv-py3.9/lib/python3.9/site-packages/accelerate/accelerator.py:488: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n",
      "08/14/2024 11:32:41 - WARNING - accelerate.utils.other - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "[INFO|trainer.py:657] 2024-08-14 11:32:42,006 >> Using auto half precision backend\n",
      "[INFO|configuration_utils.py:991] 2024-08-14 11:32:42,006 >> loading configuration file models/marian/marian_output/base_model/generation_config.json\n",
      "[INFO|configuration_utils.py:1038] 2024-08-14 11:32:42,007 >> Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      31999\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 1,\n",
      "  \"decoder_start_token_id\": 31999,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"max_length\": 128,\n",
      "  \"pad_token_id\": 31999\n",
      "}\n",
      "\n",
      "[INFO|trainer.py:2160] 2024-08-14 11:32:42,597 >> ***** Running training *****\n",
      "[INFO|trainer.py:2161] 2024-08-14 11:32:42,597 >>   Num examples = 374,010\n",
      "[INFO|trainer.py:2162] 2024-08-14 11:32:42,597 >>   Num Epochs = 10,000\n",
      "[INFO|trainer.py:2163] 2024-08-14 11:32:42,597 >>   Instantaneous batch size per device = 128\n",
      "[INFO|trainer.py:2166] 2024-08-14 11:32:42,597 >>   Total train batch size (w. parallel, distributed & accumulation) = 512\n",
      "[INFO|trainer.py:2167] 2024-08-14 11:32:42,597 >>   Gradient Accumulation steps = 4\n",
      "[INFO|trainer.py:2168] 2024-08-14 11:32:42,597 >>   Total optimization steps = 7,300,000\n",
      "[INFO|trainer.py:2169] 2024-08-14 11:32:42,598 >>   Number of trainable parameters = 74,562,560\n",
      "{'loss': 3.9856, 'grad_norm': 1.9346331357955933, 'learning_rate': 0.0005, 'epoch': 0.01}\n",
      "{'loss': 3.5567, 'grad_norm': 1.8635042905807495, 'learning_rate': 0.0004999993150675549, 'epoch': 0.03}\n",
      "{'loss': 3.4358, 'grad_norm': 1.5752661228179932, 'learning_rate': 0.0004999986301351098, 'epoch': 0.04}\n",
      "{'loss': 3.2897, 'grad_norm': 1.7055977582931519, 'learning_rate': 0.0004999979452026647, 'epoch': 0.05}\n",
      "{'loss': 3.1812, 'grad_norm': 1.483149766921997, 'learning_rate': 0.0004999972602702196, 'epoch': 0.07}\n",
      "{'loss': 3.1149, 'grad_norm': 1.3832279443740845, 'learning_rate': 0.0004999965753377744, 'epoch': 0.08}\n",
      "{'loss': 3.0261, 'grad_norm': 1.6147234439849854, 'learning_rate': 0.0004999958904053294, 'epoch': 0.1}\n",
      "{'loss': 2.9573, 'grad_norm': 1.3599191904067993, 'learning_rate': 0.0004999952054728842, 'epoch': 0.11}\n",
      "{'loss': 2.9343, 'grad_norm': 1.2722797393798828, 'learning_rate': 0.0004999945205404391, 'epoch': 0.12}\n",
      "{'loss': 2.9126, 'grad_norm': 1.3249258995056152, 'learning_rate': 0.000499993835607994, 'epoch': 0.14}\n",
      "{'loss': 2.8765, 'grad_norm': 1.3721280097961426, 'learning_rate': 0.0004999931506755489, 'epoch': 0.15}\n",
      "{'loss': 2.8471, 'grad_norm': 1.273877739906311, 'learning_rate': 0.0004999924657431038, 'epoch': 0.16}\n",
      "{'loss': 2.7819, 'grad_norm': 1.2763643264770508, 'learning_rate': 0.0004999917808106586, 'epoch': 0.18}\n",
      "{'loss': 2.7442, 'grad_norm': 1.3647236824035645, 'learning_rate': 0.0004999910958782135, 'epoch': 0.19}\n",
      "{'loss': 2.7447, 'grad_norm': 1.4623957872390747, 'learning_rate': 0.0004999904109457684, 'epoch': 0.21}\n",
      "{'loss': 2.696, 'grad_norm': 1.4879295825958252, 'learning_rate': 0.0004999897260133233, 'epoch': 0.22}\n",
      "{'loss': 2.7011, 'grad_norm': 1.3805959224700928, 'learning_rate': 0.0004999890410808782, 'epoch': 0.23}\n",
      "{'loss': 2.7115, 'grad_norm': 1.2994261980056763, 'learning_rate': 0.000499988356148433, 'epoch': 0.25}\n",
      "{'loss': 2.6412, 'grad_norm': 1.3276426792144775, 'learning_rate': 0.000499987671215988, 'epoch': 0.26}\n",
      "{'loss': 2.623, 'grad_norm': 1.3874828815460205, 'learning_rate': 0.0004999869862835429, 'epoch': 0.27}\n",
      "{'loss': 2.6074, 'grad_norm': 1.2655608654022217, 'learning_rate': 0.0004999863013510977, 'epoch': 0.29}\n",
      "{'loss': 2.5674, 'grad_norm': 1.3235350847244263, 'learning_rate': 0.0004999856164186527, 'epoch': 0.3}\n",
      "{'loss': 2.5703, 'grad_norm': 1.273634672164917, 'learning_rate': 0.0004999849314862076, 'epoch': 0.31}\n",
      "{'loss': 2.5982, 'grad_norm': 1.3159172534942627, 'learning_rate': 0.0004999842465537624, 'epoch': 0.33}\n",
      "{'loss': 2.5704, 'grad_norm': 1.1705917119979858, 'learning_rate': 0.0004999835616213173, 'epoch': 0.34}\n",
      "  0%|                                | 250/7300000 [05:45<2847:02:46,  1.40s/it][INFO|trainer.py:3548] 2024-08-14 11:38:28,115 >> Saving model checkpoint to models/marian/marian_output/checkpoint-250\n",
      "[WARNING|configuration_utils.py:448] 2024-08-14 11:38:28,115 >> Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[59421]], 'forced_eos_token_id': 0}\n",
      "[INFO|configuration_utils.py:472] 2024-08-14 11:38:28,116 >> Configuration saved in models/marian/marian_output/checkpoint-250/config.json\n",
      "[INFO|configuration_utils.py:807] 2024-08-14 11:38:28,117 >> Configuration saved in models/marian/marian_output/checkpoint-250/generation_config.json\n",
      "[INFO|modeling_utils.py:2778] 2024-08-14 11:38:28,611 >> Model weights saved in models/marian/marian_output/checkpoint-250/model.safetensors\n",
      "[INFO|tokenization_utils_base.py:2684] 2024-08-14 11:38:28,612 >> tokenizer config file saved in models/marian/marian_output/checkpoint-250/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2693] 2024-08-14 11:38:28,612 >> Special tokens file saved in models/marian/marian_output/checkpoint-250/special_tokens_map.json\n",
      "{'loss': 2.5469, 'grad_norm': 1.2400901317596436, 'learning_rate': 0.0004999828766888723, 'epoch': 0.36}\n",
      "{'loss': 2.5598, 'grad_norm': 1.1810842752456665, 'learning_rate': 0.0004999821917564271, 'epoch': 0.37}\n",
      "{'loss': 2.5186, 'grad_norm': 1.178241491317749, 'learning_rate': 0.000499981506823982, 'epoch': 0.38}\n",
      "{'loss': 2.5169, 'grad_norm': 1.2297030687332153, 'learning_rate': 0.0004999808218915368, 'epoch': 0.4}\n",
      "{'loss': 2.5141, 'grad_norm': 1.1821882724761963, 'learning_rate': 0.0004999801369590918, 'epoch': 0.41}\n",
      "{'loss': 2.446, 'grad_norm': 1.1723767518997192, 'learning_rate': 0.0004999794520266466, 'epoch': 0.42}\n",
      "{'loss': 2.4742, 'grad_norm': 1.200032353401184, 'learning_rate': 0.0004999787670942015, 'epoch': 0.44}\n",
      "{'loss': 2.4456, 'grad_norm': 1.127816081047058, 'learning_rate': 0.0004999780821617563, 'epoch': 0.45}\n",
      "{'loss': 2.5037, 'grad_norm': 1.1749686002731323, 'learning_rate': 0.0004999773972293113, 'epoch': 0.47}\n",
      "{'loss': 2.4632, 'grad_norm': 1.3110805749893188, 'learning_rate': 0.0004999767122968662, 'epoch': 0.48}\n",
      "{'loss': 2.4426, 'grad_norm': 1.206477165222168, 'learning_rate': 0.000499976027364421, 'epoch': 0.49}\n",
      "{'loss': 2.445, 'grad_norm': 1.1753214597702026, 'learning_rate': 0.000499975342431976, 'epoch': 0.51}\n",
      "{'loss': 2.4414, 'grad_norm': 1.159306526184082, 'learning_rate': 0.0004999746574995308, 'epoch': 0.52}\n",
      "{'loss': 2.4644, 'grad_norm': 1.1888327598571777, 'learning_rate': 0.0004999739725670857, 'epoch': 0.53}\n",
      "{'loss': 2.4219, 'grad_norm': 1.227469563484192, 'learning_rate': 0.0004999732876346406, 'epoch': 0.55}\n",
      "{'loss': 2.433, 'grad_norm': 1.2872912883758545, 'learning_rate': 0.0004999726027021954, 'epoch': 0.56}\n",
      "{'loss': 2.4119, 'grad_norm': 1.119144082069397, 'learning_rate': 0.0004999719177697504, 'epoch': 0.58}\n",
      "{'loss': 2.4184, 'grad_norm': 1.2178493738174438, 'learning_rate': 0.0004999712328373053, 'epoch': 0.59}\n",
      "{'loss': 2.3901, 'grad_norm': 1.1355013847351074, 'learning_rate': 0.0004999705479048601, 'epoch': 0.6}\n",
      "{'loss': 2.371, 'grad_norm': 1.196966290473938, 'learning_rate': 0.0004999698629724151, 'epoch': 0.62}\n",
      "{'loss': 2.4094, 'grad_norm': 1.1393280029296875, 'learning_rate': 0.00049996917803997, 'epoch': 0.63}\n",
      "{'loss': 2.365, 'grad_norm': 1.1954431533813477, 'learning_rate': 0.0004999684931075248, 'epoch': 0.64}\n",
      "{'loss': 2.3421, 'grad_norm': 1.1482656002044678, 'learning_rate': 0.0004999678081750797, 'epoch': 0.66}\n",
      "{'loss': 2.3566, 'grad_norm': 1.1283037662506104, 'learning_rate': 0.0004999671232426346, 'epoch': 0.67}\n",
      "{'loss': 2.403, 'grad_norm': 1.2096854448318481, 'learning_rate': 0.0004999664383101895, 'epoch': 0.68}\n",
      "  0%|                                | 500/7300000 [14:15<3004:47:14,  1.48s/it][INFO|trainer.py:3548] 2024-08-14 11:46:58,246 >> Saving model checkpoint to models/marian/marian_output/checkpoint-500\n",
      "[WARNING|configuration_utils.py:448] 2024-08-14 11:46:58,247 >> Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[59421]], 'forced_eos_token_id': 0}\n",
      "[INFO|configuration_utils.py:472] 2024-08-14 11:46:58,248 >> Configuration saved in models/marian/marian_output/checkpoint-500/config.json\n",
      "[INFO|configuration_utils.py:807] 2024-08-14 11:46:58,248 >> Configuration saved in models/marian/marian_output/checkpoint-500/generation_config.json\n",
      "[INFO|modeling_utils.py:2778] 2024-08-14 11:46:58,697 >> Model weights saved in models/marian/marian_output/checkpoint-500/model.safetensors\n",
      "[INFO|tokenization_utils_base.py:2684] 2024-08-14 11:46:58,698 >> tokenizer config file saved in models/marian/marian_output/checkpoint-500/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2693] 2024-08-14 11:46:58,698 >> Special tokens file saved in models/marian/marian_output/checkpoint-500/special_tokens_map.json\n",
      "{'loss': 2.3427, 'grad_norm': 1.1625628471374512, 'learning_rate': 0.0004999657533777443, 'epoch': 0.7}\n",
      "{'loss': 2.3569, 'grad_norm': 1.1094125509262085, 'learning_rate': 0.0004999650684452992, 'epoch': 0.71}\n",
      "{'loss': 2.3566, 'grad_norm': 1.176579475402832, 'learning_rate': 0.0004999643835128542, 'epoch': 0.73}\n",
      "{'loss': 2.3434, 'grad_norm': 1.1756861209869385, 'learning_rate': 0.000499963698580409, 'epoch': 0.74}\n",
      "{'loss': 2.3516, 'grad_norm': 1.0942180156707764, 'learning_rate': 0.0004999630136479639, 'epoch': 0.75}\n",
      "{'loss': 2.3235, 'grad_norm': 1.2249196767807007, 'learning_rate': 0.0004999623287155187, 'epoch': 0.77}\n",
      "{'loss': 2.3471, 'grad_norm': 1.1642783880233765, 'learning_rate': 0.0004999616437830737, 'epoch': 0.78}\n",
      "{'loss': 2.3424, 'grad_norm': 1.180584192276001, 'learning_rate': 0.0004999609588506286, 'epoch': 0.79}\n",
      "{'loss': 2.3407, 'grad_norm': 1.1260768175125122, 'learning_rate': 0.0004999602739181834, 'epoch': 0.81}\n",
      "{'loss': 2.3078, 'grad_norm': 1.200819969177246, 'learning_rate': 0.0004999595889857383, 'epoch': 0.82}\n",
      "{'loss': 2.3203, 'grad_norm': 1.0880310535430908, 'learning_rate': 0.0004999589040532933, 'epoch': 0.84}\n",
      "{'loss': 2.3122, 'grad_norm': 1.0875581502914429, 'learning_rate': 0.0004999582191208481, 'epoch': 0.85}\n",
      "{'loss': 2.2767, 'grad_norm': 1.0736126899719238, 'learning_rate': 0.000499957534188403, 'epoch': 0.86}\n",
      "{'loss': 2.3166, 'grad_norm': 1.1546016931533813, 'learning_rate': 0.000499956849255958, 'epoch': 0.88}\n",
      "{'loss': 2.303, 'grad_norm': 1.1251834630966187, 'learning_rate': 0.0004999561643235128, 'epoch': 0.89}\n",
      "{'loss': 2.249, 'grad_norm': 1.0153210163116455, 'learning_rate': 0.0004999554793910677, 'epoch': 0.9}\n",
      "{'loss': 2.2973, 'grad_norm': 1.0993692874908447, 'learning_rate': 0.0004999547944586225, 'epoch': 0.92}\n",
      "{'loss': 2.2965, 'grad_norm': 1.1108850240707397, 'learning_rate': 0.0004999541095261775, 'epoch': 0.93}\n",
      "{'loss': 2.2909, 'grad_norm': 1.188091516494751, 'learning_rate': 0.0004999534245937324, 'epoch': 0.94}\n",
      "{'loss': 2.2478, 'grad_norm': 1.1179583072662354, 'learning_rate': 0.0004999527396612872, 'epoch': 0.96}\n",
      "{'loss': 2.3615, 'grad_norm': 1.1818703413009644, 'learning_rate': 0.0004999520547288421, 'epoch': 0.97}\n",
      "{'loss': 2.2736, 'grad_norm': 1.0396215915679932, 'learning_rate': 0.000499951369796397, 'epoch': 0.99}\n",
      "{'loss': 2.2996, 'grad_norm': 1.0227290391921997, 'learning_rate': 0.0004999506848639519, 'epoch': 1.0}\n",
      "{'loss': 2.085, 'grad_norm': 1.1385138034820557, 'learning_rate': 0.0004999499999315067, 'epoch': 1.01}\n",
      "{'loss': 2.051, 'grad_norm': 1.1052182912826538, 'learning_rate': 0.0004999493149990616, 'epoch': 1.03}\n",
      "  0%|                                | 750/7300000 [22:50<2873:53:25,  1.42s/it][INFO|trainer.py:3548] 2024-08-14 11:55:32,691 >> Saving model checkpoint to models/marian/marian_output/checkpoint-750\n",
      "[WARNING|configuration_utils.py:448] 2024-08-14 11:55:32,692 >> Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[59421]], 'forced_eos_token_id': 0}\n",
      "[INFO|configuration_utils.py:472] 2024-08-14 11:55:32,693 >> Configuration saved in models/marian/marian_output/checkpoint-750/config.json\n",
      "[INFO|configuration_utils.py:807] 2024-08-14 11:55:32,693 >> Configuration saved in models/marian/marian_output/checkpoint-750/generation_config.json\n",
      "[INFO|modeling_utils.py:2778] 2024-08-14 11:55:33,161 >> Model weights saved in models/marian/marian_output/checkpoint-750/model.safetensors\n",
      "[INFO|tokenization_utils_base.py:2684] 2024-08-14 11:55:33,162 >> tokenizer config file saved in models/marian/marian_output/checkpoint-750/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2693] 2024-08-14 11:55:33,162 >> Special tokens file saved in models/marian/marian_output/checkpoint-750/special_tokens_map.json\n",
      "{'loss': 2.0412, 'grad_norm': 1.037705421447754, 'learning_rate': 0.0004999486300666166, 'epoch': 1.04}\n",
      "{'loss': 2.0806, 'grad_norm': 1.1020393371582031, 'learning_rate': 0.0004999479451341714, 'epoch': 1.05}\n",
      "{'loss': 2.0805, 'grad_norm': 1.1340669393539429, 'learning_rate': 0.0004999472602017263, 'epoch': 1.07}\n",
      "{'loss': 2.0982, 'grad_norm': 1.06034517288208, 'learning_rate': 0.0004999465752692812, 'epoch': 1.08}\n",
      "{'loss': 2.072, 'grad_norm': 1.103009581565857, 'learning_rate': 0.0004999458903368361, 'epoch': 1.1}\n",
      "{'loss': 2.0697, 'grad_norm': 1.067629337310791, 'learning_rate': 0.000499945205404391, 'epoch': 1.11}\n",
      "{'loss': 2.0742, 'grad_norm': 1.1033283472061157, 'learning_rate': 0.0004999445204719459, 'epoch': 1.12}\n",
      "{'loss': 2.0906, 'grad_norm': 1.1457114219665527, 'learning_rate': 0.0004999438355395007, 'epoch': 1.14}\n",
      "{'loss': 2.0989, 'grad_norm': 1.205629587173462, 'learning_rate': 0.0004999431506070557, 'epoch': 1.15}\n",
      "{'loss': 2.0975, 'grad_norm': 1.1119564771652222, 'learning_rate': 0.0004999424656746106, 'epoch': 1.16}\n",
      "{'loss': 2.1116, 'grad_norm': 1.1029256582260132, 'learning_rate': 0.0004999417807421654, 'epoch': 1.18}\n",
      "{'loss': 2.1179, 'grad_norm': 1.1389362812042236, 'learning_rate': 0.0004999410958097203, 'epoch': 1.19}\n",
      "{'loss': 2.1055, 'grad_norm': 1.08642578125, 'learning_rate': 0.0004999404108772752, 'epoch': 1.21}\n",
      "{'loss': 2.0738, 'grad_norm': 1.1617382764816284, 'learning_rate': 0.0004999397259448301, 'epoch': 1.22}\n",
      "{'loss': 2.0981, 'grad_norm': 1.167055368423462, 'learning_rate': 0.0004999390410123849, 'epoch': 1.23}\n",
      "{'loss': 2.1145, 'grad_norm': 1.0868598222732544, 'learning_rate': 0.0004999383560799398, 'epoch': 1.25}\n",
      "{'loss': 2.0797, 'grad_norm': 1.1826478242874146, 'learning_rate': 0.0004999376711474947, 'epoch': 1.26}\n",
      "{'loss': 2.0801, 'grad_norm': 1.0788538455963135, 'learning_rate': 0.0004999369862150496, 'epoch': 1.27}\n",
      "{'loss': 2.076, 'grad_norm': 1.0842742919921875, 'learning_rate': 0.0004999363012826045, 'epoch': 1.29}\n",
      "{'loss': 2.0585, 'grad_norm': 1.056427001953125, 'learning_rate': 0.0004999356163501593, 'epoch': 1.3}\n",
      "{'loss': 2.1031, 'grad_norm': 1.0590603351593018, 'learning_rate': 0.0004999349314177143, 'epoch': 1.31}\n",
      "{'loss': 2.1156, 'grad_norm': 1.1839468479156494, 'learning_rate': 0.0004999342464852692, 'epoch': 1.33}\n",
      "{'loss': 2.0796, 'grad_norm': 1.1022480726242065, 'learning_rate': 0.000499933561552824, 'epoch': 1.34}\n",
      "{'loss': 2.1169, 'grad_norm': 1.0546168088912964, 'learning_rate': 0.000499932876620379, 'epoch': 1.36}\n",
      "{'loss': 2.1058, 'grad_norm': 1.0915815830230713, 'learning_rate': 0.0004999321916879339, 'epoch': 1.37}\n",
      "  0%|                               | 1000/7300000 [31:42<2754:54:46,  1.36s/it][INFO|trainer.py:3548] 2024-08-14 12:04:25,019 >> Saving model checkpoint to models/marian/marian_output/checkpoint-1000\n",
      "[WARNING|configuration_utils.py:448] 2024-08-14 12:04:25,020 >> Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[59421]], 'forced_eos_token_id': 0}\n",
      "[INFO|configuration_utils.py:472] 2024-08-14 12:04:25,021 >> Configuration saved in models/marian/marian_output/checkpoint-1000/config.json\n",
      "[INFO|configuration_utils.py:807] 2024-08-14 12:04:25,021 >> Configuration saved in models/marian/marian_output/checkpoint-1000/generation_config.json\n",
      "[INFO|modeling_utils.py:2778] 2024-08-14 12:04:25,600 >> Model weights saved in models/marian/marian_output/checkpoint-1000/model.safetensors\n",
      "[INFO|tokenization_utils_base.py:2684] 2024-08-14 12:04:25,601 >> tokenizer config file saved in models/marian/marian_output/checkpoint-1000/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2693] 2024-08-14 12:04:25,601 >> Special tokens file saved in models/marian/marian_output/checkpoint-1000/special_tokens_map.json\n",
      "{'loss': 2.104, 'grad_norm': 1.0651447772979736, 'learning_rate': 0.0004999315067554887, 'epoch': 1.38}\n",
      "{'loss': 2.1289, 'grad_norm': 1.1294621229171753, 'learning_rate': 0.0004999308218230436, 'epoch': 1.4}\n",
      "{'loss': 2.0766, 'grad_norm': 1.0390595197677612, 'learning_rate': 0.0004999301368905985, 'epoch': 1.41}\n",
      "{'loss': 2.0667, 'grad_norm': 1.0622330904006958, 'learning_rate': 0.0004999294519581534, 'epoch': 1.42}\n",
      "{'loss': 2.1191, 'grad_norm': 1.0935440063476562, 'learning_rate': 0.0004999287670257083, 'epoch': 1.44}\n",
      "{'loss': 2.0854, 'grad_norm': 1.042130470275879, 'learning_rate': 0.0004999280820932631, 'epoch': 1.45}\n",
      "{'loss': 2.0711, 'grad_norm': 1.0890146493911743, 'learning_rate': 0.0004999273971608181, 'epoch': 1.47}\n",
      "{'loss': 2.0909, 'grad_norm': 1.0604064464569092, 'learning_rate': 0.0004999267122283729, 'epoch': 1.48}\n",
      "{'loss': 2.1028, 'grad_norm': 1.1287143230438232, 'learning_rate': 0.0004999260272959278, 'epoch': 1.49}\n",
      "{'loss': 2.0613, 'grad_norm': 1.084856390953064, 'learning_rate': 0.0004999253423634827, 'epoch': 1.51}\n",
      "{'loss': 2.0483, 'grad_norm': 1.2147866487503052, 'learning_rate': 0.0004999246574310376, 'epoch': 1.52}\n",
      "{'loss': 2.0859, 'grad_norm': 1.0480695962905884, 'learning_rate': 0.0004999239724985925, 'epoch': 1.53}\n",
      "{'loss': 2.0745, 'grad_norm': 1.0555418729782104, 'learning_rate': 0.0004999232875661473, 'epoch': 1.55}\n",
      "{'loss': 2.0683, 'grad_norm': 1.0430344343185425, 'learning_rate': 0.0004999226026337022, 'epoch': 1.56}\n",
      "{'loss': 2.0277, 'grad_norm': 1.0595370531082153, 'learning_rate': 0.0004999219177012571, 'epoch': 1.57}\n",
      "{'loss': 2.0655, 'grad_norm': 1.119624137878418, 'learning_rate': 0.000499921232768812, 'epoch': 1.59}\n",
      "{'loss': 2.0701, 'grad_norm': 1.0616039037704468, 'learning_rate': 0.0004999205478363669, 'epoch': 1.6}\n",
      "{'loss': 2.0981, 'grad_norm': 1.0508947372436523, 'learning_rate': 0.0004999198629039217, 'epoch': 1.62}\n",
      "{'loss': 2.0832, 'grad_norm': 1.0654902458190918, 'learning_rate': 0.0004999191779714767, 'epoch': 1.63}\n",
      "{'loss': 2.0746, 'grad_norm': 1.0678153038024902, 'learning_rate': 0.0004999184930390316, 'epoch': 1.64}\n",
      "{'loss': 2.0442, 'grad_norm': 1.1259270906448364, 'learning_rate': 0.0004999178081065864, 'epoch': 1.66}\n",
      "{'loss': 2.0499, 'grad_norm': 1.0940345525741577, 'learning_rate': 0.0004999171231741414, 'epoch': 1.67}\n",
      "{'loss': 2.0614, 'grad_norm': 1.0998708009719849, 'learning_rate': 0.0004999164382416963, 'epoch': 1.68}\n",
      "{'loss': 2.1002, 'grad_norm': 1.0319805145263672, 'learning_rate': 0.0004999157533092511, 'epoch': 1.7}\n",
      "{'loss': 2.074, 'grad_norm': 1.0853372812271118, 'learning_rate': 0.000499915068376806, 'epoch': 1.71}\n",
      "  0%|                               | 1250/7300000 [37:30<2825:41:49,  1.39s/it][INFO|trainer.py:3548] 2024-08-14 12:10:12,608 >> Saving model checkpoint to models/marian/marian_output/checkpoint-1250\n",
      "[WARNING|configuration_utils.py:448] 2024-08-14 12:10:12,608 >> Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[59421]], 'forced_eos_token_id': 0}\n",
      "[INFO|configuration_utils.py:472] 2024-08-14 12:10:12,609 >> Configuration saved in models/marian/marian_output/checkpoint-1250/config.json\n",
      "[INFO|configuration_utils.py:807] 2024-08-14 12:10:12,609 >> Configuration saved in models/marian/marian_output/checkpoint-1250/generation_config.json\n",
      "[INFO|modeling_utils.py:2778] 2024-08-14 12:10:13,085 >> Model weights saved in models/marian/marian_output/checkpoint-1250/model.safetensors\n",
      "[INFO|tokenization_utils_base.py:2684] 2024-08-14 12:10:13,086 >> tokenizer config file saved in models/marian/marian_output/checkpoint-1250/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2693] 2024-08-14 12:10:13,086 >> Special tokens file saved in models/marian/marian_output/checkpoint-1250/special_tokens_map.json\n",
      "{'loss': 2.0479, 'grad_norm': 1.2063612937927246, 'learning_rate': 0.0004999143834443609, 'epoch': 1.73}\n",
      "{'loss': 2.0668, 'grad_norm': 1.0983326435089111, 'learning_rate': 0.0004999136985119158, 'epoch': 1.74}\n",
      "{'loss': 2.1254, 'grad_norm': 1.008739709854126, 'learning_rate': 0.0004999130135794707, 'epoch': 1.75}\n",
      "{'loss': 2.0778, 'grad_norm': 1.1016724109649658, 'learning_rate': 0.0004999123286470255, 'epoch': 1.77}\n",
      "{'loss': 2.0794, 'grad_norm': 1.1373094320297241, 'learning_rate': 0.0004999116437145805, 'epoch': 1.78}\n",
      "{'loss': 2.09, 'grad_norm': 1.0466892719268799, 'learning_rate': 0.0004999109587821353, 'epoch': 1.79}\n",
      "{'loss': 2.0691, 'grad_norm': 1.0998575687408447, 'learning_rate': 0.0004999102738496902, 'epoch': 1.81}\n",
      "{'loss': 2.071, 'grad_norm': 1.1611279249191284, 'learning_rate': 0.000499909588917245, 'epoch': 1.82}\n",
      "{'loss': 2.0854, 'grad_norm': 1.0872325897216797, 'learning_rate': 0.0004999089039848, 'epoch': 1.83}\n",
      "{'loss': 2.0751, 'grad_norm': 1.0453799962997437, 'learning_rate': 0.0004999082190523549, 'epoch': 1.85}\n",
      "{'loss': 2.053, 'grad_norm': 1.0645838975906372, 'learning_rate': 0.0004999075341199097, 'epoch': 1.86}\n",
      "{'loss': 2.0828, 'grad_norm': 1.1063823699951172, 'learning_rate': 0.0004999068491874646, 'epoch': 1.88}\n",
      "{'loss': 2.0774, 'grad_norm': 1.0246165990829468, 'learning_rate': 0.0004999061642550196, 'epoch': 1.89}\n",
      "{'loss': 2.0867, 'grad_norm': 1.0757148265838623, 'learning_rate': 0.0004999054793225744, 'epoch': 1.9}\n",
      "{'loss': 2.0516, 'grad_norm': 1.0002208948135376, 'learning_rate': 0.0004999047943901293, 'epoch': 1.92}\n",
      "{'loss': 2.0768, 'grad_norm': 1.0379958152770996, 'learning_rate': 0.0004999041094576843, 'epoch': 1.93}\n",
      "{'loss': 2.0873, 'grad_norm': 1.078405499458313, 'learning_rate': 0.0004999034245252391, 'epoch': 1.94}\n",
      "{'loss': 2.0605, 'grad_norm': 1.043792486190796, 'learning_rate': 0.000499902739592794, 'epoch': 1.96}\n",
      "{'loss': 2.0584, 'grad_norm': 1.070929765701294, 'learning_rate': 0.0004999020546603489, 'epoch': 1.97}\n",
      "{'loss': 2.035, 'grad_norm': 1.1208276748657227, 'learning_rate': 0.0004999013697279038, 'epoch': 1.99}\n",
      "{'loss': 2.0425, 'grad_norm': 0.9714776873588562, 'learning_rate': 0.0004999006847954587, 'epoch': 2.0}\n",
      "{'loss': 1.8462, 'grad_norm': 1.01913321018219, 'learning_rate': 0.0004998999998630135, 'epoch': 2.01}\n",
      "{'loss': 1.8158, 'grad_norm': 1.015832543373108, 'learning_rate': 0.0004998993149305684, 'epoch': 2.03}\n",
      "{'loss': 1.812, 'grad_norm': 1.048356533050537, 'learning_rate': 0.0004998986299981233, 'epoch': 2.04}\n",
      "{'loss': 1.844, 'grad_norm': 1.0732609033584595, 'learning_rate': 0.0004998979450656782, 'epoch': 2.05}\n",
      "  0%|                               | 1500/7300000 [43:17<2737:11:08,  1.35s/it][INFO|trainer.py:3548] 2024-08-14 12:16:00,182 >> Saving model checkpoint to models/marian/marian_output/checkpoint-1500\n",
      "[WARNING|configuration_utils.py:448] 2024-08-14 12:16:00,183 >> Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[59421]], 'forced_eos_token_id': 0}\n",
      "[INFO|configuration_utils.py:472] 2024-08-14 12:16:00,184 >> Configuration saved in models/marian/marian_output/checkpoint-1500/config.json\n",
      "[INFO|configuration_utils.py:807] 2024-08-14 12:16:00,184 >> Configuration saved in models/marian/marian_output/checkpoint-1500/generation_config.json\n",
      "[INFO|modeling_utils.py:2778] 2024-08-14 12:16:00,558 >> Model weights saved in models/marian/marian_output/checkpoint-1500/model.safetensors\n",
      "[INFO|tokenization_utils_base.py:2684] 2024-08-14 12:16:00,559 >> tokenizer config file saved in models/marian/marian_output/checkpoint-1500/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2693] 2024-08-14 12:16:00,560 >> Special tokens file saved in models/marian/marian_output/checkpoint-1500/special_tokens_map.json\n",
      "{'loss': 1.8448, 'grad_norm': 0.9939508438110352, 'learning_rate': 0.000499897260133233, 'epoch': 2.07}\n",
      "{'loss': 1.8533, 'grad_norm': 0.9922854900360107, 'learning_rate': 0.0004998965752007879, 'epoch': 2.08}\n",
      "{'loss': 1.8446, 'grad_norm': 1.0154858827590942, 'learning_rate': 0.0004998958902683429, 'epoch': 2.1}\n",
      "{'loss': 1.8685, 'grad_norm': 1.0557670593261719, 'learning_rate': 0.0004998952053358977, 'epoch': 2.11}\n",
      "{'loss': 1.8783, 'grad_norm': 1.049373745918274, 'learning_rate': 0.0004998945204034526, 'epoch': 2.12}\n",
      "{'loss': 1.8664, 'grad_norm': 1.0399953126907349, 'learning_rate': 0.0004998938354710075, 'epoch': 2.14}\n",
      "{'loss': 1.8464, 'grad_norm': 1.0446590185165405, 'learning_rate': 0.0004998931505385624, 'epoch': 2.15}\n",
      "{'loss': 1.8701, 'grad_norm': 0.9849504828453064, 'learning_rate': 0.0004998924656061173, 'epoch': 2.16}\n",
      "{'loss': 1.8584, 'grad_norm': 1.0133906602859497, 'learning_rate': 0.0004998917806736722, 'epoch': 2.18}\n",
      "{'loss': 1.8884, 'grad_norm': 1.051232933998108, 'learning_rate': 0.000499891095741227, 'epoch': 2.19}\n",
      "{'loss': 1.8965, 'grad_norm': 1.0787431001663208, 'learning_rate': 0.000499890410808782, 'epoch': 2.2}\n",
      "{'loss': 1.8962, 'grad_norm': 1.0374987125396729, 'learning_rate': 0.0004998897258763369, 'epoch': 2.22}\n",
      "{'loss': 1.9021, 'grad_norm': 1.0350229740142822, 'learning_rate': 0.0004998890409438917, 'epoch': 2.23}\n",
      "{'loss': 1.8682, 'grad_norm': 1.1548891067504883, 'learning_rate': 0.0004998883560114466, 'epoch': 2.25}\n",
      "{'loss': 1.8918, 'grad_norm': 1.1398468017578125, 'learning_rate': 0.0004998876710790015, 'epoch': 2.26}\n",
      "{'loss': 1.8919, 'grad_norm': 1.070777177810669, 'learning_rate': 0.0004998869861465564, 'epoch': 2.27}\n",
      "{'loss': 1.8705, 'grad_norm': 1.0671091079711914, 'learning_rate': 0.0004998863012141112, 'epoch': 2.29}\n",
      "{'loss': 1.8989, 'grad_norm': 1.0359985828399658, 'learning_rate': 0.0004998856162816662, 'epoch': 2.3}\n",
      "{'loss': 1.9084, 'grad_norm': 1.0246607065200806, 'learning_rate': 0.0004998849313492211, 'epoch': 2.31}\n",
      "{'loss': 1.8976, 'grad_norm': 1.0262832641601562, 'learning_rate': 0.0004998842464167759, 'epoch': 2.33}\n",
      "{'loss': 1.9147, 'grad_norm': 1.0849651098251343, 'learning_rate': 0.0004998835614843308, 'epoch': 2.34}\n",
      "{'loss': 1.9265, 'grad_norm': 1.0774409770965576, 'learning_rate': 0.0004998828765518857, 'epoch': 2.36}\n",
      "{'loss': 1.8606, 'grad_norm': 1.0429770946502686, 'learning_rate': 0.0004998821916194406, 'epoch': 2.37}\n",
      "{'loss': 1.8871, 'grad_norm': 1.0312635898590088, 'learning_rate': 0.0004998815066869954, 'epoch': 2.38}\n",
      "{'loss': 1.8836, 'grad_norm': 1.0799506902694702, 'learning_rate': 0.0004998808217545503, 'epoch': 2.4}\n",
      "  0%|                               | 1750/7300000 [49:08<2829:54:24,  1.40s/it][INFO|trainer.py:3548] 2024-08-14 12:21:50,691 >> Saving model checkpoint to models/marian/marian_output/checkpoint-1750\n",
      "[WARNING|configuration_utils.py:448] 2024-08-14 12:21:50,692 >> Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[59421]], 'forced_eos_token_id': 0}\n",
      "[INFO|configuration_utils.py:472] 2024-08-14 12:21:50,693 >> Configuration saved in models/marian/marian_output/checkpoint-1750/config.json\n",
      "[INFO|configuration_utils.py:807] 2024-08-14 12:21:50,693 >> Configuration saved in models/marian/marian_output/checkpoint-1750/generation_config.json\n",
      "[INFO|modeling_utils.py:2778] 2024-08-14 12:21:51,084 >> Model weights saved in models/marian/marian_output/checkpoint-1750/model.safetensors\n",
      "[INFO|tokenization_utils_base.py:2684] 2024-08-14 12:21:51,085 >> tokenizer config file saved in models/marian/marian_output/checkpoint-1750/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2693] 2024-08-14 12:21:51,086 >> Special tokens file saved in models/marian/marian_output/checkpoint-1750/special_tokens_map.json\n",
      "{'loss': 1.9341, 'grad_norm': 1.0419447422027588, 'learning_rate': 0.0004998801368221053, 'epoch': 2.41}\n",
      "{'loss': 1.904, 'grad_norm': 1.0310193300247192, 'learning_rate': 0.0004998794518896601, 'epoch': 2.42}\n",
      "{'loss': 1.9214, 'grad_norm': 1.0748074054718018, 'learning_rate': 0.000499878766957215, 'epoch': 2.44}\n",
      "{'loss': 1.9363, 'grad_norm': 1.0346921682357788, 'learning_rate': 0.0004998780820247699, 'epoch': 2.45}\n",
      "{'loss': 1.9323, 'grad_norm': 1.0124467611312866, 'learning_rate': 0.0004998773970923248, 'epoch': 2.46}\n",
      "{'loss': 1.8934, 'grad_norm': 1.0508283376693726, 'learning_rate': 0.0004998767121598797, 'epoch': 2.48}\n",
      "{'loss': 1.8819, 'grad_norm': 1.0556211471557617, 'learning_rate': 0.0004998760272274346, 'epoch': 2.49}\n",
      "{'loss': 1.9141, 'grad_norm': 1.041574239730835, 'learning_rate': 0.0004998753422949894, 'epoch': 2.51}\n",
      "{'loss': 1.9084, 'grad_norm': 1.0048003196716309, 'learning_rate': 0.0004998746573625444, 'epoch': 2.52}\n",
      "{'loss': 1.911, 'grad_norm': 1.0409401655197144, 'learning_rate': 0.0004998739724300993, 'epoch': 2.53}\n",
      "{'loss': 1.9221, 'grad_norm': 0.9833512306213379, 'learning_rate': 0.0004998732874976541, 'epoch': 2.55}\n",
      "{'loss': 1.9197, 'grad_norm': 1.0201479196548462, 'learning_rate': 0.000499872602565209, 'epoch': 2.56}\n",
      "{'loss': 1.879, 'grad_norm': 1.0163531303405762, 'learning_rate': 0.0004998719176327639, 'epoch': 2.57}\n",
      "{'loss': 1.8941, 'grad_norm': 1.0345717668533325, 'learning_rate': 0.0004998712327003188, 'epoch': 2.59}\n",
      "{'loss': 1.9102, 'grad_norm': 0.9990619421005249, 'learning_rate': 0.0004998705477678736, 'epoch': 2.6}\n",
      "{'loss': 1.9317, 'grad_norm': 1.0483195781707764, 'learning_rate': 0.0004998698628354285, 'epoch': 2.62}\n",
      "{'loss': 1.9403, 'grad_norm': 1.0997860431671143, 'learning_rate': 0.0004998691779029834, 'epoch': 2.63}\n",
      "{'loss': 1.9082, 'grad_norm': 1.018343210220337, 'learning_rate': 0.0004998684929705383, 'epoch': 2.64}\n",
      "{'loss': 1.9187, 'grad_norm': 1.0383111238479614, 'learning_rate': 0.0004998678080380932, 'epoch': 2.66}\n",
      "{'loss': 1.9001, 'grad_norm': 1.0177892446517944, 'learning_rate': 0.000499867123105648, 'epoch': 2.67}\n",
      "{'loss': 1.9245, 'grad_norm': 1.035831093788147, 'learning_rate': 0.000499866438173203, 'epoch': 2.68}\n",
      "{'loss': 1.8949, 'grad_norm': 0.9892063736915588, 'learning_rate': 0.0004998657532407579, 'epoch': 2.7}\n",
      "{'loss': 1.8826, 'grad_norm': 0.9738435745239258, 'learning_rate': 0.0004998650683083127, 'epoch': 2.71}\n",
      "{'loss': 1.9385, 'grad_norm': 1.0366394519805908, 'learning_rate': 0.0004998643833758677, 'epoch': 2.73}\n",
      "{'loss': 1.9064, 'grad_norm': 0.988466739654541, 'learning_rate': 0.0004998636984434226, 'epoch': 2.74}\n",
      "  0%|                               | 2000/7300000 [55:02<2836:26:51,  1.40s/it][INFO|trainer.py:3548] 2024-08-14 12:27:44,991 >> Saving model checkpoint to models/marian/marian_output/checkpoint-2000\n",
      "[WARNING|configuration_utils.py:448] 2024-08-14 12:27:44,991 >> Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[59421]], 'forced_eos_token_id': 0}\n",
      "[INFO|configuration_utils.py:472] 2024-08-14 12:27:44,992 >> Configuration saved in models/marian/marian_output/checkpoint-2000/config.json\n",
      "[INFO|configuration_utils.py:807] 2024-08-14 12:27:44,993 >> Configuration saved in models/marian/marian_output/checkpoint-2000/generation_config.json\n",
      "[INFO|modeling_utils.py:2778] 2024-08-14 12:27:45,962 >> Model weights saved in models/marian/marian_output/checkpoint-2000/model.safetensors\n",
      "[INFO|tokenization_utils_base.py:2684] 2024-08-14 12:27:45,963 >> tokenizer config file saved in models/marian/marian_output/checkpoint-2000/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2693] 2024-08-14 12:27:45,964 >> Special tokens file saved in models/marian/marian_output/checkpoint-2000/special_tokens_map.json\n",
      "{'loss': 1.9022, 'grad_norm': 0.9218080639839172, 'learning_rate': 0.0004998630135109774, 'epoch': 2.75}\n",
      "{'loss': 1.8928, 'grad_norm': 0.951454222202301, 'learning_rate': 0.0004998623285785323, 'epoch': 2.77}\n",
      "{'loss': 1.947, 'grad_norm': 1.036186933517456, 'learning_rate': 0.0004998616436460873, 'epoch': 2.78}\n",
      "{'loss': 1.9287, 'grad_norm': 1.135683536529541, 'learning_rate': 0.0004998609587136421, 'epoch': 2.79}\n",
      "{'loss': 1.8929, 'grad_norm': 1.0113468170166016, 'learning_rate': 0.000499860273781197, 'epoch': 2.81}\n",
      "{'loss': 1.913, 'grad_norm': 1.0036382675170898, 'learning_rate': 0.0004998595888487518, 'epoch': 2.82}\n",
      "{'loss': 1.8918, 'grad_norm': 0.9864977598190308, 'learning_rate': 0.0004998589039163068, 'epoch': 2.83}\n",
      "{'loss': 1.9173, 'grad_norm': 1.0532830953598022, 'learning_rate': 0.0004998582189838616, 'epoch': 2.85}\n",
      "{'loss': 1.9419, 'grad_norm': 0.9913074970245361, 'learning_rate': 0.0004998575340514165, 'epoch': 2.86}\n",
      "{'loss': 1.9082, 'grad_norm': 1.0425779819488525, 'learning_rate': 0.0004998568491189714, 'epoch': 2.88}\n",
      "{'loss': 1.9346, 'grad_norm': 1.037678599357605, 'learning_rate': 0.0004998561641865263, 'epoch': 2.89}\n",
      "{'loss': 1.9333, 'grad_norm': 1.0419918298721313, 'learning_rate': 0.0004998554792540812, 'epoch': 2.9}\n",
      "{'loss': 1.9076, 'grad_norm': 0.9584633111953735, 'learning_rate': 0.000499854794321636, 'epoch': 2.92}\n",
      "{'loss': 1.8824, 'grad_norm': 0.9984142184257507, 'learning_rate': 0.0004998541093891909, 'epoch': 2.93}\n",
      "{'loss': 1.91, 'grad_norm': 1.0808781385421753, 'learning_rate': 0.0004998534244567459, 'epoch': 2.94}\n",
      "{'loss': 1.8883, 'grad_norm': 1.0480202436447144, 'learning_rate': 0.0004998527395243007, 'epoch': 2.96}\n",
      "{'loss': 1.9185, 'grad_norm': 0.9961753487586975, 'learning_rate': 0.0004998520545918556, 'epoch': 2.97}\n",
      "{'loss': 1.9226, 'grad_norm': 1.022661805152893, 'learning_rate': 0.0004998513696594106, 'epoch': 2.99}\n",
      "{'loss': 1.9277, 'grad_norm': 0.9597862362861633, 'learning_rate': 0.0004998506847269654, 'epoch': 3.0}\n",
      "{'loss': 1.7144, 'grad_norm': 1.034333348274231, 'learning_rate': 0.0004998499997945203, 'epoch': 3.01}\n",
      "{'loss': 1.6878, 'grad_norm': 1.0011303424835205, 'learning_rate': 0.0004998493148620752, 'epoch': 3.03}\n",
      "{'loss': 1.6981, 'grad_norm': 1.0327441692352295, 'learning_rate': 0.00049984862992963, 'epoch': 3.04}\n",
      "{'loss': 1.6997, 'grad_norm': 1.0267781019210815, 'learning_rate': 0.000499847944997185, 'epoch': 3.05}\n",
      "{'loss': 1.698, 'grad_norm': 1.0230903625488281, 'learning_rate': 0.0004998472600647398, 'epoch': 3.07}\n",
      "{'loss': 1.6895, 'grad_norm': 1.0483676195144653, 'learning_rate': 0.0004998465751322947, 'epoch': 3.08}\n",
      "  0%|                             | 2250/7300000 [1:00:51<2913:45:39,  1.44s/it][INFO|trainer.py:3548] 2024-08-14 12:33:34,198 >> Saving model checkpoint to models/marian/marian_output/checkpoint-2250\n",
      "[WARNING|configuration_utils.py:448] 2024-08-14 12:33:34,198 >> Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[59421]], 'forced_eos_token_id': 0}\n",
      "[INFO|configuration_utils.py:472] 2024-08-14 12:33:34,199 >> Configuration saved in models/marian/marian_output/checkpoint-2250/config.json\n",
      "[INFO|configuration_utils.py:807] 2024-08-14 12:33:34,199 >> Configuration saved in models/marian/marian_output/checkpoint-2250/generation_config.json\n",
      "[INFO|modeling_utils.py:2778] 2024-08-14 12:33:34,625 >> Model weights saved in models/marian/marian_output/checkpoint-2250/model.safetensors\n",
      "[INFO|tokenization_utils_base.py:2684] 2024-08-14 12:33:34,626 >> tokenizer config file saved in models/marian/marian_output/checkpoint-2250/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2693] 2024-08-14 12:33:34,626 >> Special tokens file saved in models/marian/marian_output/checkpoint-2250/special_tokens_map.json\n",
      "{'loss': 1.7083, 'grad_norm': 0.9797554016113281, 'learning_rate': 0.0004998458901998496, 'epoch': 3.09}\n",
      "{'loss': 1.6808, 'grad_norm': 1.0090187788009644, 'learning_rate': 0.0004998452052674045, 'epoch': 3.11}\n",
      "{'loss': 1.7303, 'grad_norm': 1.005190372467041, 'learning_rate': 0.0004998445203349594, 'epoch': 3.12}\n",
      "{'loss': 1.727, 'grad_norm': 0.9947436451911926, 'learning_rate': 0.0004998438354025142, 'epoch': 3.14}\n",
      "{'loss': 1.7381, 'grad_norm': 0.9951388239860535, 'learning_rate': 0.0004998431504700692, 'epoch': 3.15}\n",
      "{'loss': 1.7209, 'grad_norm': 1.0349286794662476, 'learning_rate': 0.000499842465537624, 'epoch': 3.16}\n",
      "{'loss': 1.7441, 'grad_norm': 1.038861870765686, 'learning_rate': 0.0004998417806051789, 'epoch': 3.18}\n",
      "{'loss': 1.7135, 'grad_norm': 0.9762808680534363, 'learning_rate': 0.0004998410956727337, 'epoch': 3.19}\n",
      "{'loss': 1.7514, 'grad_norm': 1.0491290092468262, 'learning_rate': 0.0004998404107402887, 'epoch': 3.2}\n",
      "{'loss': 1.743, 'grad_norm': 0.9907057285308838, 'learning_rate': 0.0004998397258078436, 'epoch': 3.22}\n",
      "{'loss': 1.7334, 'grad_norm': 1.0384725332260132, 'learning_rate': 0.0004998390408753984, 'epoch': 3.23}\n",
      "{'loss': 1.7637, 'grad_norm': 1.0225461721420288, 'learning_rate': 0.0004998383559429533, 'epoch': 3.25}\n",
      "{'loss': 1.7726, 'grad_norm': 1.0285342931747437, 'learning_rate': 0.0004998376710105083, 'epoch': 3.26}\n",
      "{'loss': 1.7368, 'grad_norm': 1.0257917642593384, 'learning_rate': 0.0004998369860780631, 'epoch': 3.27}\n",
      "{'loss': 1.7643, 'grad_norm': 1.0096791982650757, 'learning_rate': 0.000499836301145618, 'epoch': 3.29}\n",
      "{'loss': 1.7748, 'grad_norm': 1.0791963338851929, 'learning_rate': 0.000499835616213173, 'epoch': 3.3}\n",
      "{'loss': 1.7441, 'grad_norm': 0.9822873473167419, 'learning_rate': 0.0004998349312807278, 'epoch': 3.31}\n",
      "{'loss': 1.7359, 'grad_norm': 1.030347466468811, 'learning_rate': 0.0004998342463482827, 'epoch': 3.33}\n",
      "{'loss': 1.7586, 'grad_norm': 1.0719350576400757, 'learning_rate': 0.0004998335614158376, 'epoch': 3.34}\n",
      "{'loss': 1.7907, 'grad_norm': 1.0093531608581543, 'learning_rate': 0.0004998328764833925, 'epoch': 3.36}\n",
      "{'loss': 1.7667, 'grad_norm': 1.02531099319458, 'learning_rate': 0.0004998321915509474, 'epoch': 3.37}\n",
      "{'loss': 1.7422, 'grad_norm': 0.9943501353263855, 'learning_rate': 0.0004998315066185022, 'epoch': 3.38}\n",
      "{'loss': 1.7742, 'grad_norm': 1.0106128454208374, 'learning_rate': 0.0004998308216860571, 'epoch': 3.4}\n",
      "{'loss': 1.7855, 'grad_norm': 1.010235071182251, 'learning_rate': 0.000499830136753612, 'epoch': 3.41}\n",
      "{'loss': 1.7618, 'grad_norm': 1.0062882900238037, 'learning_rate': 0.0004998294518211669, 'epoch': 3.42}\n",
      "  0%|                             | 2500/7300000 [1:06:45<2806:21:15,  1.38s/it][INFO|trainer.py:3548] 2024-08-14 12:39:27,785 >> Saving model checkpoint to models/marian/marian_output/checkpoint-2500\n",
      "[WARNING|configuration_utils.py:448] 2024-08-14 12:39:27,786 >> Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[59421]], 'forced_eos_token_id': 0}\n",
      "[INFO|configuration_utils.py:472] 2024-08-14 12:39:27,787 >> Configuration saved in models/marian/marian_output/checkpoint-2500/config.json\n",
      "[INFO|configuration_utils.py:807] 2024-08-14 12:39:27,787 >> Configuration saved in models/marian/marian_output/checkpoint-2500/generation_config.json\n",
      "[INFO|modeling_utils.py:2778] 2024-08-14 12:39:28,186 >> Model weights saved in models/marian/marian_output/checkpoint-2500/model.safetensors\n",
      "[INFO|tokenization_utils_base.py:2684] 2024-08-14 12:39:28,186 >> tokenizer config file saved in models/marian/marian_output/checkpoint-2500/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2693] 2024-08-14 12:39:28,187 >> Special tokens file saved in models/marian/marian_output/checkpoint-2500/special_tokens_map.json\n",
      "{'loss': 1.7748, 'grad_norm': 0.986638069152832, 'learning_rate': 0.0004998287668887217, 'epoch': 3.44}\n",
      "{'loss': 1.7783, 'grad_norm': 1.0758692026138306, 'learning_rate': 0.0004998280819562766, 'epoch': 3.45}\n",
      "{'loss': 1.7623, 'grad_norm': 0.9746963977813721, 'learning_rate': 0.0004998273970238316, 'epoch': 3.46}\n",
      "{'loss': 1.791, 'grad_norm': 0.994922935962677, 'learning_rate': 0.0004998267120913864, 'epoch': 3.48}\n",
      "{'loss': 1.801, 'grad_norm': 1.0337228775024414, 'learning_rate': 0.0004998260271589413, 'epoch': 3.49}\n",
      "{'loss': 1.7594, 'grad_norm': 1.0090934038162231, 'learning_rate': 0.0004998253422264962, 'epoch': 3.51}\n",
      "{'loss': 1.7644, 'grad_norm': 1.0084781646728516, 'learning_rate': 0.0004998246572940511, 'epoch': 3.52}\n",
      "{'loss': 1.7866, 'grad_norm': 1.0254853963851929, 'learning_rate': 0.000499823972361606, 'epoch': 3.53}\n",
      "{'loss': 1.7911, 'grad_norm': 0.9999054670333862, 'learning_rate': 0.0004998232874291609, 'epoch': 3.55}\n",
      "{'loss': 1.7613, 'grad_norm': 0.9826233386993408, 'learning_rate': 0.0004998226024967157, 'epoch': 3.56}\n",
      "{'loss': 1.7761, 'grad_norm': 1.015411138534546, 'learning_rate': 0.0004998219175642707, 'epoch': 3.57}\n",
      "{'loss': 1.7654, 'grad_norm': 1.0219675302505493, 'learning_rate': 0.0004998212326318256, 'epoch': 3.59}\n",
      "{'loss': 1.814, 'grad_norm': 0.9716143012046814, 'learning_rate': 0.0004998205476993804, 'epoch': 3.6}\n",
      "{'loss': 1.7897, 'grad_norm': 0.9658204913139343, 'learning_rate': 0.0004998198627669353, 'epoch': 3.62}\n",
      "{'loss': 1.7835, 'grad_norm': 1.0426000356674194, 'learning_rate': 0.0004998191778344902, 'epoch': 3.63}\n",
      "{'loss': 1.8033, 'grad_norm': 1.0177137851715088, 'learning_rate': 0.0004998184929020451, 'epoch': 3.64}\n",
      "{'loss': 1.8099, 'grad_norm': 1.0295134782791138, 'learning_rate': 0.0004998178079695999, 'epoch': 3.66}\n",
      "{'loss': 1.8125, 'grad_norm': 0.9722340106964111, 'learning_rate': 0.0004998171230371548, 'epoch': 3.67}\n",
      "{'loss': 1.7892, 'grad_norm': 0.9734554290771484, 'learning_rate': 0.0004998164381047098, 'epoch': 3.68}\n",
      "{'loss': 1.802, 'grad_norm': 0.9970264434814453, 'learning_rate': 0.0004998157531722646, 'epoch': 3.7}\n",
      "{'loss': 1.7944, 'grad_norm': 1.0853275060653687, 'learning_rate': 0.0004998150682398195, 'epoch': 3.71}\n",
      "{'loss': 1.8019, 'grad_norm': 0.9858691692352295, 'learning_rate': 0.0004998143833073743, 'epoch': 3.72}\n",
      "{'loss': 1.8176, 'grad_norm': 0.972332239151001, 'learning_rate': 0.0004998136983749293, 'epoch': 3.74}\n",
      "{'loss': 1.8282, 'grad_norm': 0.9627240300178528, 'learning_rate': 0.0004998130134424842, 'epoch': 3.75}\n",
      "{'loss': 1.7981, 'grad_norm': 1.0629894733428955, 'learning_rate': 0.000499812328510039, 'epoch': 3.77}\n",
      "  0%|                             | 2750/7300000 [1:12:26<2728:27:54,  1.35s/it][INFO|trainer.py:3548] 2024-08-14 12:45:09,457 >> Saving model checkpoint to models/marian/marian_output/checkpoint-2750\n",
      "[WARNING|configuration_utils.py:448] 2024-08-14 12:45:09,457 >> Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[59421]], 'forced_eos_token_id': 0}\n",
      "[INFO|configuration_utils.py:472] 2024-08-14 12:45:09,458 >> Configuration saved in models/marian/marian_output/checkpoint-2750/config.json\n",
      "[INFO|configuration_utils.py:807] 2024-08-14 12:45:09,459 >> Configuration saved in models/marian/marian_output/checkpoint-2750/generation_config.json\n",
      "[INFO|modeling_utils.py:2778] 2024-08-14 12:45:09,859 >> Model weights saved in models/marian/marian_output/checkpoint-2750/model.safetensors\n",
      "[INFO|tokenization_utils_base.py:2684] 2024-08-14 12:45:09,860 >> tokenizer config file saved in models/marian/marian_output/checkpoint-2750/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2693] 2024-08-14 12:45:09,860 >> Special tokens file saved in models/marian/marian_output/checkpoint-2750/special_tokens_map.json\n",
      "{'loss': 1.8054, 'grad_norm': 0.9777653813362122, 'learning_rate': 0.000499811643577594, 'epoch': 3.78}\n",
      "{'loss': 1.7805, 'grad_norm': 0.9950017333030701, 'learning_rate': 0.0004998109586451489, 'epoch': 3.79}\n",
      "{'loss': 1.8427, 'grad_norm': 1.0062782764434814, 'learning_rate': 0.0004998102737127037, 'epoch': 3.81}\n",
      "{'loss': 1.7734, 'grad_norm': 1.0053200721740723, 'learning_rate': 0.0004998095887802586, 'epoch': 3.82}\n",
      "{'loss': 1.8036, 'grad_norm': 0.9505984783172607, 'learning_rate': 0.0004998089038478136, 'epoch': 3.83}\n",
      "{'loss': 1.8205, 'grad_norm': 1.0314465761184692, 'learning_rate': 0.0004998082189153684, 'epoch': 3.85}\n",
      "{'loss': 1.8128, 'grad_norm': 1.0354334115982056, 'learning_rate': 0.0004998075339829233, 'epoch': 3.86}\n",
      "{'loss': 1.8318, 'grad_norm': 0.9697483777999878, 'learning_rate': 0.0004998068490504781, 'epoch': 3.88}\n",
      "{'loss': 1.7856, 'grad_norm': 0.9841785430908203, 'learning_rate': 0.0004998061641180331, 'epoch': 3.89}\n",
      "{'loss': 1.7705, 'grad_norm': 0.9853464961051941, 'learning_rate': 0.000499805479185588, 'epoch': 3.9}\n",
      "{'loss': 1.807, 'grad_norm': 0.9625869989395142, 'learning_rate': 0.0004998047942531428, 'epoch': 3.92}\n",
      "{'loss': 1.7932, 'grad_norm': 0.9720630645751953, 'learning_rate': 0.0004998041093206977, 'epoch': 3.93}\n",
      "{'loss': 1.8198, 'grad_norm': 0.9976368546485901, 'learning_rate': 0.0004998034243882526, 'epoch': 3.94}\n",
      "{'loss': 1.8299, 'grad_norm': 0.9848730564117432, 'learning_rate': 0.0004998027394558075, 'epoch': 3.96}\n",
      "{'loss': 1.8245, 'grad_norm': 1.0004850625991821, 'learning_rate': 0.0004998020545233623, 'epoch': 3.97}\n",
      "{'loss': 1.8315, 'grad_norm': 0.9734598994255066, 'learning_rate': 0.0004998013695909172, 'epoch': 3.98}\n",
      "{'loss': 1.8054, 'grad_norm': 0.9550826549530029, 'learning_rate': 0.0004998006846584722, 'epoch': 4.0}\n",
      "{'loss': 1.5809, 'grad_norm': 0.9926576614379883, 'learning_rate': 0.000499799999726027, 'epoch': 4.01}\n",
      "{'loss': 1.5883, 'grad_norm': 1.0120896100997925, 'learning_rate': 0.0004997993147935819, 'epoch': 4.03}\n",
      "{'loss': 1.5736, 'grad_norm': 1.0061408281326294, 'learning_rate': 0.0004997986298611369, 'epoch': 4.04}\n",
      "{'loss': 1.5701, 'grad_norm': 0.9773524403572083, 'learning_rate': 0.0004997979449286917, 'epoch': 4.05}\n",
      "{'loss': 1.5649, 'grad_norm': 0.9686572551727295, 'learning_rate': 0.0004997972599962466, 'epoch': 4.07}\n",
      "{'loss': 1.6009, 'grad_norm': 0.9397557377815247, 'learning_rate': 0.0004997965750638015, 'epoch': 4.08}\n",
      "{'loss': 1.6218, 'grad_norm': 0.9930327534675598, 'learning_rate': 0.0004997958901313564, 'epoch': 4.09}\n",
      "{'loss': 1.6227, 'grad_norm': 0.969920814037323, 'learning_rate': 0.0004997952051989113, 'epoch': 4.11}\n",
      "  0%|                             | 3000/7300000 [1:20:42<3468:56:22,  1.71s/it][INFO|trainer.py:3548] 2024-08-14 12:53:24,920 >> Saving model checkpoint to models/marian/marian_output/checkpoint-3000\n",
      "[WARNING|configuration_utils.py:448] 2024-08-14 12:53:24,920 >> Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[59421]], 'forced_eos_token_id': 0}\n",
      "[INFO|configuration_utils.py:472] 2024-08-14 12:53:24,921 >> Configuration saved in models/marian/marian_output/checkpoint-3000/config.json\n",
      "[INFO|configuration_utils.py:807] 2024-08-14 12:53:24,922 >> Configuration saved in models/marian/marian_output/checkpoint-3000/generation_config.json\n",
      "[INFO|modeling_utils.py:2778] 2024-08-14 12:53:25,541 >> Model weights saved in models/marian/marian_output/checkpoint-3000/model.safetensors\n",
      "[INFO|tokenization_utils_base.py:2684] 2024-08-14 12:53:25,542 >> tokenizer config file saved in models/marian/marian_output/checkpoint-3000/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2693] 2024-08-14 12:53:25,542 >> Special tokens file saved in models/marian/marian_output/checkpoint-3000/special_tokens_map.json\n",
      "{'loss': 1.6415, 'grad_norm': 1.000112533569336, 'learning_rate': 0.0004997945202664661, 'epoch': 4.12}\n",
      "{'loss': 1.6041, 'grad_norm': 0.9943897724151611, 'learning_rate': 0.000499793835334021, 'epoch': 4.14}\n",
      "{'loss': 1.6114, 'grad_norm': 0.9710409641265869, 'learning_rate': 0.000499793150401576, 'epoch': 4.15}\n",
      "{'loss': 1.6109, 'grad_norm': 1.0062575340270996, 'learning_rate': 0.0004997924654691308, 'epoch': 4.16}\n",
      "{'loss': 1.6287, 'grad_norm': 0.9913185238838196, 'learning_rate': 0.0004997917805366857, 'epoch': 4.18}\n",
      "{'loss': 1.612, 'grad_norm': 1.0034880638122559, 'learning_rate': 0.0004997910956042405, 'epoch': 4.19}\n",
      "{'loss': 1.6215, 'grad_norm': 1.0996410846710205, 'learning_rate': 0.0004997904106717955, 'epoch': 4.2}\n",
      "{'loss': 1.6451, 'grad_norm': 0.9695723056793213, 'learning_rate': 0.0004997897257393503, 'epoch': 4.22}\n",
      "{'loss': 1.6298, 'grad_norm': 0.9943298101425171, 'learning_rate': 0.0004997890408069052, 'epoch': 4.23}\n",
      "{'loss': 1.652, 'grad_norm': 0.9932947158813477, 'learning_rate': 0.00049978835587446, 'epoch': 4.25}\n",
      "{'loss': 1.6537, 'grad_norm': 1.0027079582214355, 'learning_rate': 0.000499787670942015, 'epoch': 4.26}\n",
      "{'loss': 1.6404, 'grad_norm': 0.9948268532752991, 'learning_rate': 0.0004997869860095699, 'epoch': 4.27}\n",
      "{'loss': 1.677, 'grad_norm': 1.0319582223892212, 'learning_rate': 0.0004997863010771247, 'epoch': 4.29}\n",
      "{'loss': 1.6559, 'grad_norm': 1.0345733165740967, 'learning_rate': 0.0004997856161446796, 'epoch': 4.3}\n",
      "{'loss': 1.663, 'grad_norm': 1.0230824947357178, 'learning_rate': 0.0004997849312122346, 'epoch': 4.31}\n",
      "{'loss': 1.6522, 'grad_norm': 1.0314772129058838, 'learning_rate': 0.0004997842462797894, 'epoch': 4.33}\n",
      "{'loss': 1.6737, 'grad_norm': 1.0135198831558228, 'learning_rate': 0.0004997835613473443, 'epoch': 4.34}\n",
      "{'loss': 1.6611, 'grad_norm': 0.9693197011947632, 'learning_rate': 0.0004997828764148993, 'epoch': 4.35}\n",
      "{'loss': 1.6649, 'grad_norm': 0.985109806060791, 'learning_rate': 0.0004997821914824541, 'epoch': 4.37}\n",
      "{'loss': 1.6598, 'grad_norm': 0.962544858455658, 'learning_rate': 0.000499781506550009, 'epoch': 4.38}\n",
      "{'loss': 1.6543, 'grad_norm': 0.9490797519683838, 'learning_rate': 0.0004997808216175639, 'epoch': 4.4}\n",
      "{'loss': 1.6898, 'grad_norm': 0.9562655687332153, 'learning_rate': 0.0004997801366851188, 'epoch': 4.41}\n",
      "{'loss': 1.6827, 'grad_norm': 1.0421161651611328, 'learning_rate': 0.0004997794517526737, 'epoch': 4.42}\n",
      "{'loss': 1.6643, 'grad_norm': 0.9743552207946777, 'learning_rate': 0.0004997787668202285, 'epoch': 4.44}\n",
      "{'loss': 1.6911, 'grad_norm': 1.0114326477050781, 'learning_rate': 0.0004997780818877834, 'epoch': 4.45}\n",
      "  0%|                             | 3250/7300000 [1:29:28<2776:40:51,  1.37s/it][INFO|trainer.py:3548] 2024-08-14 13:02:11,143 >> Saving model checkpoint to models/marian/marian_output/checkpoint-3250\n",
      "[WARNING|configuration_utils.py:448] 2024-08-14 13:02:11,143 >> Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[59421]], 'forced_eos_token_id': 0}\n",
      "[INFO|configuration_utils.py:472] 2024-08-14 13:02:11,144 >> Configuration saved in models/marian/marian_output/checkpoint-3250/config.json\n",
      "[INFO|configuration_utils.py:807] 2024-08-14 13:02:11,145 >> Configuration saved in models/marian/marian_output/checkpoint-3250/generation_config.json\n",
      "[INFO|modeling_utils.py:2778] 2024-08-14 13:02:11,618 >> Model weights saved in models/marian/marian_output/checkpoint-3250/model.safetensors\n",
      "[INFO|tokenization_utils_base.py:2684] 2024-08-14 13:02:11,619 >> tokenizer config file saved in models/marian/marian_output/checkpoint-3250/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2693] 2024-08-14 13:02:11,619 >> Special tokens file saved in models/marian/marian_output/checkpoint-3250/special_tokens_map.json\n",
      "{'loss': 1.6589, 'grad_norm': 0.9998022317886353, 'learning_rate': 0.0004997773969553383, 'epoch': 4.46}\n",
      "{'loss': 1.645, 'grad_norm': 0.959840714931488, 'learning_rate': 0.0004997767120228932, 'epoch': 4.48}\n",
      "{'loss': 1.6482, 'grad_norm': 0.9649704694747925, 'learning_rate': 0.0004997760270904481, 'epoch': 4.49}\n",
      "{'loss': 1.7213, 'grad_norm': 1.0056946277618408, 'learning_rate': 0.0004997753421580029, 'epoch': 4.51}\n",
      "{'loss': 1.7165, 'grad_norm': 1.0149227380752563, 'learning_rate': 0.0004997746572255579, 'epoch': 4.52}\n",
      "{'loss': 1.68, 'grad_norm': 0.9605841040611267, 'learning_rate': 0.0004997739722931127, 'epoch': 4.53}\n",
      "{'loss': 1.7287, 'grad_norm': 0.9828689098358154, 'learning_rate': 0.0004997732873606676, 'epoch': 4.55}\n",
      "{'loss': 1.683, 'grad_norm': 0.9660707712173462, 'learning_rate': 0.0004997726024282225, 'epoch': 4.56}\n",
      "{'loss': 1.7148, 'grad_norm': 0.9932576417922974, 'learning_rate': 0.0004997719174957774, 'epoch': 4.57}\n",
      "{'loss': 1.6699, 'grad_norm': 0.9591143727302551, 'learning_rate': 0.0004997712325633323, 'epoch': 4.59}\n",
      "{'loss': 1.704, 'grad_norm': 1.003240704536438, 'learning_rate': 0.0004997705476308872, 'epoch': 4.6}\n",
      "{'loss': 1.7066, 'grad_norm': 1.0100476741790771, 'learning_rate': 0.000499769862698442, 'epoch': 4.61}\n",
      "{'loss': 1.6975, 'grad_norm': 1.0015684366226196, 'learning_rate': 0.000499769177765997, 'epoch': 4.63}\n",
      "{'loss': 1.7017, 'grad_norm': 1.017417311668396, 'learning_rate': 0.0004997684928335519, 'epoch': 4.64}\n",
      "{'loss': 1.6951, 'grad_norm': 1.0013854503631592, 'learning_rate': 0.0004997678079011067, 'epoch': 4.66}\n",
      "{'loss': 1.6952, 'grad_norm': 0.9660000205039978, 'learning_rate': 0.0004997671229686616, 'epoch': 4.67}\n",
      "{'loss': 1.6947, 'grad_norm': 0.9590032696723938, 'learning_rate': 0.0004997664380362165, 'epoch': 4.68}\n",
      "{'loss': 1.7008, 'grad_norm': 0.9841663241386414, 'learning_rate': 0.0004997657531037714, 'epoch': 4.7}\n",
      "{'loss': 1.6913, 'grad_norm': 0.9167040586471558, 'learning_rate': 0.0004997650681713263, 'epoch': 4.71}\n",
      "{'loss': 1.7248, 'grad_norm': 0.9844708442687988, 'learning_rate': 0.0004997643832388811, 'epoch': 4.72}\n",
      "{'loss': 1.6963, 'grad_norm': 1.0137237310409546, 'learning_rate': 0.0004997636983064361, 'epoch': 4.74}\n",
      "{'loss': 1.7141, 'grad_norm': 1.0168166160583496, 'learning_rate': 0.0004997630133739909, 'epoch': 4.75}\n",
      "{'loss': 1.6924, 'grad_norm': 1.0203361511230469, 'learning_rate': 0.0004997623284415458, 'epoch': 4.77}\n",
      "{'loss': 1.6905, 'grad_norm': 1.1323819160461426, 'learning_rate': 0.0004997616435091006, 'epoch': 4.78}\n",
      "{'loss': 1.7063, 'grad_norm': 1.0938630104064941, 'learning_rate': 0.0004997609585766556, 'epoch': 4.79}\n",
      "  0%|                             | 3500/7300000 [1:38:09<3559:21:59,  1.76s/it][INFO|trainer.py:3548] 2024-08-14 13:10:52,505 >> Saving model checkpoint to models/marian/marian_output/checkpoint-3500\n",
      "[WARNING|configuration_utils.py:448] 2024-08-14 13:10:52,506 >> Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[59421]], 'forced_eos_token_id': 0}\n",
      "[INFO|configuration_utils.py:472] 2024-08-14 13:10:52,507 >> Configuration saved in models/marian/marian_output/checkpoint-3500/config.json\n",
      "[INFO|configuration_utils.py:807] 2024-08-14 13:10:52,507 >> Configuration saved in models/marian/marian_output/checkpoint-3500/generation_config.json\n",
      "[INFO|modeling_utils.py:2778] 2024-08-14 13:10:52,886 >> Model weights saved in models/marian/marian_output/checkpoint-3500/model.safetensors\n",
      "[INFO|tokenization_utils_base.py:2684] 2024-08-14 13:10:52,887 >> tokenizer config file saved in models/marian/marian_output/checkpoint-3500/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2693] 2024-08-14 13:10:52,887 >> Special tokens file saved in models/marian/marian_output/checkpoint-3500/special_tokens_map.json\n",
      "{'loss': 1.7114, 'grad_norm': 0.9437345266342163, 'learning_rate': 0.0004997602736442105, 'epoch': 4.81}\n",
      "{'loss': 1.7042, 'grad_norm': 1.0156151056289673, 'learning_rate': 0.0004997595887117653, 'epoch': 4.82}\n",
      "{'loss': 1.6948, 'grad_norm': 0.9477301239967346, 'learning_rate': 0.0004997589037793203, 'epoch': 4.83}\n",
      "{'loss': 1.7309, 'grad_norm': 0.9832021594047546, 'learning_rate': 0.0004997582188468752, 'epoch': 4.85}\n",
      "{'loss': 1.7015, 'grad_norm': 0.986377477645874, 'learning_rate': 0.00049975753391443, 'epoch': 4.86}\n",
      "{'loss': 1.7191, 'grad_norm': 0.9866474866867065, 'learning_rate': 0.0004997568489819849, 'epoch': 4.88}\n",
      "{'loss': 1.7153, 'grad_norm': 0.9630730152130127, 'learning_rate': 0.0004997561640495399, 'epoch': 4.89}\n",
      "{'loss': 1.6989, 'grad_norm': 0.9503991007804871, 'learning_rate': 0.0004997554791170947, 'epoch': 4.9}\n",
      "{'loss': 1.7166, 'grad_norm': 0.9540424346923828, 'learning_rate': 0.0004997547941846496, 'epoch': 4.92}\n",
      "{'loss': 1.6739, 'grad_norm': 0.9335483312606812, 'learning_rate': 0.0004997541092522045, 'epoch': 4.93}\n",
      "{'loss': 1.7248, 'grad_norm': 1.0183603763580322, 'learning_rate': 0.0004997534243197594, 'epoch': 4.94}\n",
      "{'loss': 1.6951, 'grad_norm': 0.9920461773872375, 'learning_rate': 0.0004997527393873143, 'epoch': 4.96}\n",
      "{'loss': 1.7258, 'grad_norm': 0.9710285663604736, 'learning_rate': 0.0004997520544548691, 'epoch': 4.97}\n",
      "{'loss': 1.741, 'grad_norm': 0.9868180155754089, 'learning_rate': 0.000499751369522424, 'epoch': 4.98}\n",
      "{'loss': 1.7494, 'grad_norm': 0.956152617931366, 'learning_rate': 0.0004997506845899789, 'epoch': 5.0}\n",
      "{'loss': 1.4851, 'grad_norm': 0.9556992053985596, 'learning_rate': 0.0004997499996575338, 'epoch': 5.01}\n",
      "{'loss': 1.4585, 'grad_norm': 0.9235764145851135, 'learning_rate': 0.0004997493147250886, 'epoch': 5.03}\n",
      "{'loss': 1.4818, 'grad_norm': 1.01948881149292, 'learning_rate': 0.0004997486297926435, 'epoch': 5.04}\n",
      "{'loss': 1.4898, 'grad_norm': 0.9810680150985718, 'learning_rate': 0.0004997479448601985, 'epoch': 5.05}\n",
      "{'loss': 1.5023, 'grad_norm': 0.9783115983009338, 'learning_rate': 0.0004997472599277533, 'epoch': 5.07}\n",
      "{'loss': 1.5071, 'grad_norm': 1.0038721561431885, 'learning_rate': 0.0004997465749953082, 'epoch': 5.08}\n",
      "{'loss': 1.4796, 'grad_norm': 0.9799715876579285, 'learning_rate': 0.000499745890062863, 'epoch': 5.09}\n",
      "{'loss': 1.5112, 'grad_norm': 1.0096690654754639, 'learning_rate': 0.000499745205130418, 'epoch': 5.11}\n",
      "{'loss': 1.5329, 'grad_norm': 0.9445865750312805, 'learning_rate': 0.0004997445201979729, 'epoch': 5.12}\n",
      "{'loss': 1.5446, 'grad_norm': 0.9585664868354797, 'learning_rate': 0.0004997438352655277, 'epoch': 5.14}\n",
      "  0%|                             | 3750/7300000 [1:46:17<2997:47:38,  1.48s/it][INFO|trainer.py:3548] 2024-08-14 13:19:00,507 >> Saving model checkpoint to models/marian/marian_output/checkpoint-3750\n",
      "[WARNING|configuration_utils.py:448] 2024-08-14 13:19:00,508 >> Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[59421]], 'forced_eos_token_id': 0}\n",
      "[INFO|configuration_utils.py:472] 2024-08-14 13:19:00,509 >> Configuration saved in models/marian/marian_output/checkpoint-3750/config.json\n",
      "[INFO|configuration_utils.py:807] 2024-08-14 13:19:00,509 >> Configuration saved in models/marian/marian_output/checkpoint-3750/generation_config.json\n",
      "[INFO|modeling_utils.py:2778] 2024-08-14 13:19:01,320 >> Model weights saved in models/marian/marian_output/checkpoint-3750/model.safetensors\n",
      "[INFO|tokenization_utils_base.py:2684] 2024-08-14 13:19:01,321 >> tokenizer config file saved in models/marian/marian_output/checkpoint-3750/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2693] 2024-08-14 13:19:01,321 >> Special tokens file saved in models/marian/marian_output/checkpoint-3750/special_tokens_map.json\n",
      "{'loss': 1.5353, 'grad_norm': 0.9804662466049194, 'learning_rate': 0.0004997431503330827, 'epoch': 5.15}\n",
      "{'loss': 1.5362, 'grad_norm': 0.9782013893127441, 'learning_rate': 0.0004997424654006376, 'epoch': 5.16}\n",
      "{'loss': 1.5363, 'grad_norm': 0.962173581123352, 'learning_rate': 0.0004997417804681924, 'epoch': 5.18}\n",
      "{'loss': 1.5323, 'grad_norm': 0.9786987900733948, 'learning_rate': 0.0004997410955357473, 'epoch': 5.19}\n",
      "{'loss': 1.5287, 'grad_norm': 0.9354367852210999, 'learning_rate': 0.0004997404106033023, 'epoch': 5.2}\n",
      "{'loss': 1.5264, 'grad_norm': 0.9502590298652649, 'learning_rate': 0.0004997397256708571, 'epoch': 5.22}\n",
      "{'loss': 1.5557, 'grad_norm': 1.0298207998275757, 'learning_rate': 0.000499739040738412, 'epoch': 5.23}\n",
      "{'loss': 1.5496, 'grad_norm': 0.9617252945899963, 'learning_rate': 0.0004997383558059668, 'epoch': 5.24}\n",
      "{'loss': 1.572, 'grad_norm': 1.0224865674972534, 'learning_rate': 0.0004997376708735218, 'epoch': 5.26}\n",
      "{'loss': 1.5641, 'grad_norm': 0.9718223810195923, 'learning_rate': 0.0004997369859410766, 'epoch': 5.27}\n",
      "{'loss': 1.5677, 'grad_norm': 0.9540340900421143, 'learning_rate': 0.0004997363010086315, 'epoch': 5.29}\n",
      "{'loss': 1.5735, 'grad_norm': 0.96762615442276, 'learning_rate': 0.0004997356160761864, 'epoch': 5.3}\n",
      "{'loss': 1.5566, 'grad_norm': 1.046825885772705, 'learning_rate': 0.0004997349311437413, 'epoch': 5.31}\n",
      "{'loss': 1.5716, 'grad_norm': 0.9638369083404541, 'learning_rate': 0.0004997342462112962, 'epoch': 5.33}\n",
      "{'loss': 1.597, 'grad_norm': 0.9912764430046082, 'learning_rate': 0.000499733561278851, 'epoch': 5.34}\n",
      "{'loss': 1.583, 'grad_norm': 0.942158579826355, 'learning_rate': 0.0004997328763464059, 'epoch': 5.35}\n",
      "{'loss': 1.5734, 'grad_norm': 1.004561185836792, 'learning_rate': 0.0004997321914139609, 'epoch': 5.37}\n",
      "{'loss': 1.5952, 'grad_norm': 0.9610203504562378, 'learning_rate': 0.0004997315064815157, 'epoch': 5.38}\n",
      "{'loss': 1.6028, 'grad_norm': 0.9988425374031067, 'learning_rate': 0.0004997308215490706, 'epoch': 5.4}\n",
      "{'loss': 1.586, 'grad_norm': 0.9475991129875183, 'learning_rate': 0.0004997301366166256, 'epoch': 5.41}\n",
      "{'loss': 1.6124, 'grad_norm': 0.9464977383613586, 'learning_rate': 0.0004997294516841804, 'epoch': 5.42}\n",
      "{'loss': 1.6182, 'grad_norm': 0.997606098651886, 'learning_rate': 0.0004997287667517353, 'epoch': 5.44}\n",
      "{'loss': 1.5832, 'grad_norm': 1.0205491781234741, 'learning_rate': 0.0004997280818192902, 'epoch': 5.45}\n",
      "{'loss': 1.5766, 'grad_norm': 0.9607951641082764, 'learning_rate': 0.000499727396886845, 'epoch': 5.46}\n",
      "{'loss': 1.5935, 'grad_norm': 0.9762508273124695, 'learning_rate': 0.0004997267119544, 'epoch': 5.48}\n",
      "  0%|                             | 4000/7300000 [1:54:43<2846:45:50,  1.40s/it][INFO|trainer.py:3548] 2024-08-14 13:27:26,233 >> Saving model checkpoint to models/marian/marian_output/checkpoint-4000\n",
      "[WARNING|configuration_utils.py:448] 2024-08-14 13:27:26,234 >> Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[59421]], 'forced_eos_token_id': 0}\n",
      "[INFO|configuration_utils.py:472] 2024-08-14 13:27:26,235 >> Configuration saved in models/marian/marian_output/checkpoint-4000/config.json\n",
      "[INFO|configuration_utils.py:807] 2024-08-14 13:27:26,235 >> Configuration saved in models/marian/marian_output/checkpoint-4000/generation_config.json\n",
      "[INFO|modeling_utils.py:2778] 2024-08-14 13:27:26,724 >> Model weights saved in models/marian/marian_output/checkpoint-4000/model.safetensors\n",
      "[INFO|tokenization_utils_base.py:2684] 2024-08-14 13:27:26,725 >> tokenizer config file saved in models/marian/marian_output/checkpoint-4000/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2693] 2024-08-14 13:27:26,725 >> Special tokens file saved in models/marian/marian_output/checkpoint-4000/special_tokens_map.json\n",
      "{'loss': 1.6082, 'grad_norm': 0.9449507594108582, 'learning_rate': 0.0004997260270219548, 'epoch': 5.49}\n",
      "{'loss': 1.6182, 'grad_norm': 0.9313840866088867, 'learning_rate': 0.0004997253420895097, 'epoch': 5.5}\n",
      "{'loss': 1.6334, 'grad_norm': 1.0015993118286133, 'learning_rate': 0.0004997246571570647, 'epoch': 5.52}\n",
      "{'loss': 1.6152, 'grad_norm': 0.9685205817222595, 'learning_rate': 0.0004997239722246195, 'epoch': 5.53}\n",
      "{'loss': 1.5675, 'grad_norm': 0.9254890084266663, 'learning_rate': 0.0004997232872921744, 'epoch': 5.55}\n",
      "{'loss': 1.584, 'grad_norm': 0.9607484340667725, 'learning_rate': 0.0004997226023597292, 'epoch': 5.56}\n",
      "{'loss': 1.6148, 'grad_norm': 0.9518457055091858, 'learning_rate': 0.0004997219174272842, 'epoch': 5.57}\n",
      "{'loss': 1.6202, 'grad_norm': 0.9668752551078796, 'learning_rate': 0.000499721232494839, 'epoch': 5.59}\n",
      "{'loss': 1.6496, 'grad_norm': 0.9749091267585754, 'learning_rate': 0.0004997205475623939, 'epoch': 5.6}\n",
      "{'loss': 1.6394, 'grad_norm': 1.0027756690979004, 'learning_rate': 0.0004997198626299488, 'epoch': 5.61}\n",
      "{'loss': 1.6043, 'grad_norm': 0.9631322622299194, 'learning_rate': 0.0004997191776975037, 'epoch': 5.63}\n",
      "{'loss': 1.6194, 'grad_norm': 0.9284746050834656, 'learning_rate': 0.0004997184927650586, 'epoch': 5.64}\n",
      "{'loss': 1.6196, 'grad_norm': 0.9279764294624329, 'learning_rate': 0.0004997178078326135, 'epoch': 5.66}\n",
      "{'loss': 1.5866, 'grad_norm': 0.9729985594749451, 'learning_rate': 0.0004997171229001683, 'epoch': 5.67}\n",
      "{'loss': 1.6235, 'grad_norm': 0.9525743722915649, 'learning_rate': 0.0004997164379677233, 'epoch': 5.68}\n",
      "{'loss': 1.6262, 'grad_norm': 1.0017009973526, 'learning_rate': 0.0004997157530352782, 'epoch': 5.7}\n",
      "{'loss': 1.6187, 'grad_norm': 0.9904450178146362, 'learning_rate': 0.000499715068102833, 'epoch': 5.71}\n",
      "{'loss': 1.6324, 'grad_norm': 1.0037486553192139, 'learning_rate': 0.000499714383170388, 'epoch': 5.72}\n",
      "{'loss': 1.6121, 'grad_norm': 0.9788970947265625, 'learning_rate': 0.0004997136982379429, 'epoch': 5.74}\n",
      "{'loss': 1.6356, 'grad_norm': 0.9385727047920227, 'learning_rate': 0.0004997130133054977, 'epoch': 5.75}\n",
      "{'loss': 1.6402, 'grad_norm': 0.9814251661300659, 'learning_rate': 0.0004997123283730526, 'epoch': 5.77}\n",
      "{'loss': 1.6153, 'grad_norm': 0.9807438254356384, 'learning_rate': 0.0004997116434406074, 'epoch': 5.78}\n",
      "{'loss': 1.636, 'grad_norm': 0.9969778060913086, 'learning_rate': 0.0004997109585081624, 'epoch': 5.79}\n",
      "{'loss': 1.6379, 'grad_norm': 0.919618546962738, 'learning_rate': 0.0004997102735757172, 'epoch': 5.81}\n",
      "{'loss': 1.6245, 'grad_norm': 0.9317750930786133, 'learning_rate': 0.0004997095886432721, 'epoch': 5.82}\n",
      "  0%|                             | 4250/7300000 [2:00:59<2868:21:18,  1.42s/it][INFO|trainer.py:3548] 2024-08-14 13:33:41,615 >> Saving model checkpoint to models/marian/marian_output/checkpoint-4250\n",
      "[WARNING|configuration_utils.py:448] 2024-08-14 13:33:41,616 >> Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[59421]], 'forced_eos_token_id': 0}\n",
      "[INFO|configuration_utils.py:472] 2024-08-14 13:33:41,616 >> Configuration saved in models/marian/marian_output/checkpoint-4250/config.json\n",
      "[INFO|configuration_utils.py:807] 2024-08-14 13:33:41,617 >> Configuration saved in models/marian/marian_output/checkpoint-4250/generation_config.json\n",
      "[INFO|modeling_utils.py:2778] 2024-08-14 13:33:42,045 >> Model weights saved in models/marian/marian_output/checkpoint-4250/model.safetensors\n",
      "[INFO|tokenization_utils_base.py:2684] 2024-08-14 13:33:42,046 >> tokenizer config file saved in models/marian/marian_output/checkpoint-4250/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2693] 2024-08-14 13:33:42,046 >> Special tokens file saved in models/marian/marian_output/checkpoint-4250/special_tokens_map.json\n",
      "{'loss': 1.6308, 'grad_norm': 0.9560208320617676, 'learning_rate': 0.000499708903710827, 'epoch': 5.83}\n",
      "{'loss': 1.6302, 'grad_norm': 0.9255746006965637, 'learning_rate': 0.0004997082187783819, 'epoch': 5.85}\n",
      "{'loss': 1.651, 'grad_norm': 0.9732550978660583, 'learning_rate': 0.0004997075338459368, 'epoch': 5.86}\n",
      "{'loss': 1.6427, 'grad_norm': 0.9542466402053833, 'learning_rate': 0.0004997068489134916, 'epoch': 5.87}\n",
      "{'loss': 1.6474, 'grad_norm': 0.9919851422309875, 'learning_rate': 0.0004997061639810466, 'epoch': 5.89}\n",
      "{'loss': 1.639, 'grad_norm': 0.9456713795661926, 'learning_rate': 0.0004997054790486015, 'epoch': 5.9}\n",
      "{'loss': 1.645, 'grad_norm': 0.9725359678268433, 'learning_rate': 0.0004997047941161563, 'epoch': 5.92}\n",
      "{'loss': 1.656, 'grad_norm': 0.9837175011634827, 'learning_rate': 0.0004997041091837112, 'epoch': 5.93}\n",
      "{'loss': 1.66, 'grad_norm': 0.9420996308326721, 'learning_rate': 0.0004997034242512661, 'epoch': 5.94}\n",
      "{'loss': 1.6489, 'grad_norm': 0.9731234908103943, 'learning_rate': 0.000499702739318821, 'epoch': 5.96}\n",
      "{'loss': 1.621, 'grad_norm': 0.9664574861526489, 'learning_rate': 0.0004997020543863759, 'epoch': 5.97}\n",
      "{'loss': 1.6666, 'grad_norm': 0.9430837631225586, 'learning_rate': 0.0004997013694539307, 'epoch': 5.98}\n",
      "{'loss': 1.6566, 'grad_norm': 0.966923177242279, 'learning_rate': 0.0004997006845214857, 'epoch': 6.0}\n",
      "{'loss': 1.4419, 'grad_norm': 0.9311948418617249, 'learning_rate': 0.0004996999995890406, 'epoch': 6.01}\n",
      "{'loss': 1.3854, 'grad_norm': 0.950384259223938, 'learning_rate': 0.0004996993146565954, 'epoch': 6.03}\n",
      "{'loss': 1.4104, 'grad_norm': 0.9218244552612305, 'learning_rate': 0.0004996986297241503, 'epoch': 6.04}\n",
      "{'loss': 1.4128, 'grad_norm': 0.9272663593292236, 'learning_rate': 0.0004996979447917052, 'epoch': 6.05}\n",
      "{'loss': 1.4369, 'grad_norm': 0.9840302467346191, 'learning_rate': 0.0004996972598592601, 'epoch': 6.07}\n",
      "{'loss': 1.4136, 'grad_norm': 0.9498932361602783, 'learning_rate': 0.000499696574926815, 'epoch': 6.08}\n",
      "{'loss': 1.4235, 'grad_norm': 0.9844347238540649, 'learning_rate': 0.0004996958899943698, 'epoch': 6.09}\n",
      "{'loss': 1.4349, 'grad_norm': 0.9815662503242493, 'learning_rate': 0.0004996952050619248, 'epoch': 6.11}\n",
      "{'loss': 1.4471, 'grad_norm': 0.9791133999824524, 'learning_rate': 0.0004996945201294796, 'epoch': 6.12}\n",
      "{'loss': 1.4304, 'grad_norm': 0.9524977803230286, 'learning_rate': 0.0004996938351970345, 'epoch': 6.13}\n",
      "{'loss': 1.4527, 'grad_norm': 0.9494432210922241, 'learning_rate': 0.0004996931502645893, 'epoch': 6.15}\n",
      "{'loss': 1.4417, 'grad_norm': 0.9107177257537842, 'learning_rate': 0.0004996924653321443, 'epoch': 6.16}\n",
      "  0%|                             | 4500/7300000 [2:08:52<2860:05:30,  1.41s/it][INFO|trainer.py:3548] 2024-08-14 13:41:35,453 >> Saving model checkpoint to models/marian/marian_output/checkpoint-4500\n",
      "[WARNING|configuration_utils.py:448] 2024-08-14 13:41:35,454 >> Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[59421]], 'forced_eos_token_id': 0}\n",
      "[INFO|configuration_utils.py:472] 2024-08-14 13:41:35,456 >> Configuration saved in models/marian/marian_output/checkpoint-4500/config.json\n",
      "[INFO|configuration_utils.py:807] 2024-08-14 13:41:35,457 >> Configuration saved in models/marian/marian_output/checkpoint-4500/generation_config.json\n",
      "[INFO|modeling_utils.py:2778] 2024-08-14 13:41:36,152 >> Model weights saved in models/marian/marian_output/checkpoint-4500/model.safetensors\n",
      "[INFO|tokenization_utils_base.py:2684] 2024-08-14 13:41:36,153 >> tokenizer config file saved in models/marian/marian_output/checkpoint-4500/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2693] 2024-08-14 13:41:36,153 >> Special tokens file saved in models/marian/marian_output/checkpoint-4500/special_tokens_map.json\n",
      "{'loss': 1.4408, 'grad_norm': 1.0308616161346436, 'learning_rate': 0.0004996917803996992, 'epoch': 6.18}\n",
      "{'loss': 1.4879, 'grad_norm': 1.0118303298950195, 'learning_rate': 0.000499691095467254, 'epoch': 6.19}\n",
      "{'loss': 1.47, 'grad_norm': 0.9260727763175964, 'learning_rate': 0.000499690410534809, 'epoch': 6.2}\n",
      "{'loss': 1.4746, 'grad_norm': 0.9772218465805054, 'learning_rate': 0.0004996897256023639, 'epoch': 6.22}\n",
      "{'loss': 1.4729, 'grad_norm': 0.946578323841095, 'learning_rate': 0.0004996890406699187, 'epoch': 6.23}\n",
      "{'loss': 1.4665, 'grad_norm': 0.993360698223114, 'learning_rate': 0.0004996883557374736, 'epoch': 6.24}\n",
      "{'loss': 1.4824, 'grad_norm': 0.9857587218284607, 'learning_rate': 0.0004996876708050286, 'epoch': 6.26}\n",
      "{'loss': 1.4805, 'grad_norm': 0.9920747876167297, 'learning_rate': 0.0004996869858725834, 'epoch': 6.27}\n",
      "{'loss': 1.4901, 'grad_norm': 0.9852738976478577, 'learning_rate': 0.0004996863009401383, 'epoch': 6.29}\n",
      "{'loss': 1.4906, 'grad_norm': 0.9973182082176208, 'learning_rate': 0.0004996856160076931, 'epoch': 6.3}\n",
      "{'loss': 1.5032, 'grad_norm': 0.9843530654907227, 'learning_rate': 0.0004996849310752481, 'epoch': 6.31}\n",
      "{'loss': 1.4797, 'grad_norm': 0.9992473125457764, 'learning_rate': 0.000499684246142803, 'epoch': 6.33}\n",
      "{'loss': 1.5029, 'grad_norm': 0.9938052296638489, 'learning_rate': 0.0004996835612103578, 'epoch': 6.34}\n",
      "{'loss': 1.5044, 'grad_norm': 0.9772951006889343, 'learning_rate': 0.0004996828762779127, 'epoch': 6.35}\n",
      "{'loss': 1.4995, 'grad_norm': 0.9352806806564331, 'learning_rate': 0.0004996821913454676, 'epoch': 6.37}\n",
      "{'loss': 1.5096, 'grad_norm': 0.9425291419029236, 'learning_rate': 0.0004996815064130225, 'epoch': 6.38}\n",
      "{'loss': 1.5166, 'grad_norm': 0.9396880269050598, 'learning_rate': 0.0004996808214805773, 'epoch': 6.4}\n",
      "{'loss': 1.5131, 'grad_norm': 1.0001909732818604, 'learning_rate': 0.0004996801365481322, 'epoch': 6.41}\n",
      "{'loss': 1.5133, 'grad_norm': 0.9081727862358093, 'learning_rate': 0.0004996794516156872, 'epoch': 6.42}\n",
      "{'loss': 1.539, 'grad_norm': 0.9679819941520691, 'learning_rate': 0.000499678766683242, 'epoch': 6.44}\n",
      "{'loss': 1.5183, 'grad_norm': 0.9751452803611755, 'learning_rate': 0.0004996780817507969, 'epoch': 6.45}\n",
      "{'loss': 1.5222, 'grad_norm': 0.9656015634536743, 'learning_rate': 0.0004996773968183519, 'epoch': 6.46}\n",
      "{'loss': 1.5486, 'grad_norm': 0.9767528176307678, 'learning_rate': 0.0004996767118859067, 'epoch': 6.48}\n",
      "{'loss': 1.5474, 'grad_norm': 0.9804948568344116, 'learning_rate': 0.0004996760269534616, 'epoch': 6.49}\n",
      "{'loss': 1.5542, 'grad_norm': 0.9799546599388123, 'learning_rate': 0.0004996753420210165, 'epoch': 6.5}\n",
      "  0%|                             | 4750/7300000 [2:17:12<2782:45:26,  1.37s/it][INFO|trainer.py:3548] 2024-08-14 13:49:54,622 >> Saving model checkpoint to models/marian/marian_output/checkpoint-4750\n",
      "[WARNING|configuration_utils.py:448] 2024-08-14 13:49:54,623 >> Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[59421]], 'forced_eos_token_id': 0}\n",
      "[INFO|configuration_utils.py:472] 2024-08-14 13:49:54,624 >> Configuration saved in models/marian/marian_output/checkpoint-4750/config.json\n",
      "[INFO|configuration_utils.py:807] 2024-08-14 13:49:54,624 >> Configuration saved in models/marian/marian_output/checkpoint-4750/generation_config.json\n",
      "[INFO|modeling_utils.py:2778] 2024-08-14 13:49:54,991 >> Model weights saved in models/marian/marian_output/checkpoint-4750/model.safetensors\n",
      "[INFO|tokenization_utils_base.py:2684] 2024-08-14 13:49:54,991 >> tokenizer config file saved in models/marian/marian_output/checkpoint-4750/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2693] 2024-08-14 13:49:54,992 >> Special tokens file saved in models/marian/marian_output/checkpoint-4750/special_tokens_map.json\n",
      "{'loss': 1.5145, 'grad_norm': 0.9694753885269165, 'learning_rate': 0.0004996746570885714, 'epoch': 6.52}\n",
      "{'loss': 1.5382, 'grad_norm': 1.0077539682388306, 'learning_rate': 0.0004996739721561263, 'epoch': 6.53}\n",
      "{'loss': 1.5439, 'grad_norm': 1.0013680458068848, 'learning_rate': 0.0004996732872236812, 'epoch': 6.55}\n",
      "{'loss': 1.52, 'grad_norm': 0.9536177515983582, 'learning_rate': 0.000499672602291236, 'epoch': 6.56}\n",
      "{'loss': 1.5425, 'grad_norm': 0.9758474826812744, 'learning_rate': 0.000499671917358791, 'epoch': 6.57}\n",
      "{'loss': 1.5736, 'grad_norm': 0.9776660799980164, 'learning_rate': 0.0004996712324263458, 'epoch': 6.59}\n",
      "{'loss': 1.5712, 'grad_norm': 0.9899812936782837, 'learning_rate': 0.0004996705474939007, 'epoch': 6.6}\n",
      "{'loss': 1.5077, 'grad_norm': 0.9648432731628418, 'learning_rate': 0.0004996698625614555, 'epoch': 6.61}\n",
      "{'loss': 1.5347, 'grad_norm': 0.9700154662132263, 'learning_rate': 0.0004996691776290105, 'epoch': 6.63}\n",
      "{'loss': 1.5514, 'grad_norm': 0.9615636467933655, 'learning_rate': 0.0004996684926965653, 'epoch': 6.64}\n",
      "{'loss': 1.5558, 'grad_norm': 0.9935785531997681, 'learning_rate': 0.0004996678077641202, 'epoch': 6.66}\n",
      "{'loss': 1.5637, 'grad_norm': 0.9857934713363647, 'learning_rate': 0.0004996671228316751, 'epoch': 6.67}\n",
      "{'loss': 1.549, 'grad_norm': 1.0024980306625366, 'learning_rate': 0.00049966643789923, 'epoch': 6.68}\n",
      "{'loss': 1.5615, 'grad_norm': 0.9913386106491089, 'learning_rate': 0.0004996657529667849, 'epoch': 6.7}\n",
      "{'loss': 1.5561, 'grad_norm': 0.9081906676292419, 'learning_rate': 0.0004996650680343398, 'epoch': 6.71}\n",
      "{'loss': 1.562, 'grad_norm': 0.9955893158912659, 'learning_rate': 0.0004996643831018946, 'epoch': 6.72}\n",
      "{'loss': 1.5937, 'grad_norm': 0.9617369174957275, 'learning_rate': 0.0004996636981694496, 'epoch': 6.74}\n",
      "{'loss': 1.581, 'grad_norm': 0.9657679796218872, 'learning_rate': 0.0004996630132370045, 'epoch': 6.75}\n",
      "{'loss': 1.5773, 'grad_norm': 0.956221878528595, 'learning_rate': 0.0004996623283045593, 'epoch': 6.76}\n",
      "{'loss': 1.5725, 'grad_norm': 0.9538683295249939, 'learning_rate': 0.0004996616433721142, 'epoch': 6.78}\n",
      "{'loss': 1.5606, 'grad_norm': 0.965635359287262, 'learning_rate': 0.0004996609584396692, 'epoch': 6.79}\n",
      "{'loss': 1.5632, 'grad_norm': 0.9674456715583801, 'learning_rate': 0.000499660273507224, 'epoch': 6.81}\n",
      "{'loss': 1.561, 'grad_norm': 0.9901992678642273, 'learning_rate': 0.0004996595885747789, 'epoch': 6.82}\n",
      "{'loss': 1.5672, 'grad_norm': 1.0053293704986572, 'learning_rate': 0.0004996589036423338, 'epoch': 6.83}\n",
      "{'loss': 1.5842, 'grad_norm': 0.9648140072822571, 'learning_rate': 0.0004996582187098887, 'epoch': 6.85}\n",
      "  0%|                             | 5000/7300000 [2:22:57<2834:17:24,  1.40s/it][INFO|trainer.py:3548] 2024-08-14 13:55:40,471 >> Saving model checkpoint to models/marian/marian_output/checkpoint-5000\n",
      "[WARNING|configuration_utils.py:448] 2024-08-14 13:55:40,472 >> Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[59421]], 'forced_eos_token_id': 0}\n",
      "[INFO|configuration_utils.py:472] 2024-08-14 13:55:40,472 >> Configuration saved in models/marian/marian_output/checkpoint-5000/config.json\n",
      "[INFO|configuration_utils.py:807] 2024-08-14 13:55:40,473 >> Configuration saved in models/marian/marian_output/checkpoint-5000/generation_config.json\n",
      "[INFO|modeling_utils.py:2778] 2024-08-14 13:55:41,004 >> Model weights saved in models/marian/marian_output/checkpoint-5000/model.safetensors\n",
      "[INFO|tokenization_utils_base.py:2684] 2024-08-14 13:55:41,005 >> tokenizer config file saved in models/marian/marian_output/checkpoint-5000/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2693] 2024-08-14 13:55:41,005 >> Special tokens file saved in models/marian/marian_output/checkpoint-5000/special_tokens_map.json\n",
      "{'loss': 1.5827, 'grad_norm': 0.9601690769195557, 'learning_rate': 0.0004996575337774435, 'epoch': 6.86}\n",
      "{'loss': 1.6047, 'grad_norm': 0.9622457027435303, 'learning_rate': 0.0004996568488449984, 'epoch': 6.87}\n",
      "{'loss': 1.5602, 'grad_norm': 1.000552773475647, 'learning_rate': 0.0004996561639125534, 'epoch': 6.89}\n",
      "{'loss': 1.5738, 'grad_norm': 0.9376933574676514, 'learning_rate': 0.0004996554789801082, 'epoch': 6.9}\n",
      "{'loss': 1.6046, 'grad_norm': 0.9127441048622131, 'learning_rate': 0.0004996547940476631, 'epoch': 6.92}\n",
      "{'loss': 1.6169, 'grad_norm': 0.9495107531547546, 'learning_rate': 0.0004996541091152179, 'epoch': 6.93}\n",
      "{'loss': 1.553, 'grad_norm': 0.946370542049408, 'learning_rate': 0.0004996534241827729, 'epoch': 6.94}\n",
      "{'loss': 1.5599, 'grad_norm': 0.9635632038116455, 'learning_rate': 0.0004996527392503277, 'epoch': 6.96}\n",
      "{'loss': 1.5728, 'grad_norm': 0.969031810760498, 'learning_rate': 0.0004996520543178826, 'epoch': 6.97}\n",
      "{'loss': 1.5811, 'grad_norm': 0.979338526725769, 'learning_rate': 0.0004996513693854375, 'epoch': 6.98}\n",
      "{'loss': 1.5981, 'grad_norm': 0.9668008685112, 'learning_rate': 0.0004996506844529924, 'epoch': 7.0}\n",
      "{'loss': 1.3609, 'grad_norm': 0.9338358044624329, 'learning_rate': 0.0004996499995205473, 'epoch': 7.01}\n",
      "{'loss': 1.3416, 'grad_norm': 0.9671077132225037, 'learning_rate': 0.0004996493145881022, 'epoch': 7.02}\n",
      "{'loss': 1.3589, 'grad_norm': 0.9524616003036499, 'learning_rate': 0.000499648629655657, 'epoch': 7.04}\n",
      "  0%|                             | 5147/7300000 [2:28:49<2827:57:55,  1.40s/it]^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/zindi/transformers/examples/pytorch/translation/run_translation.py\", line 697, in <module>\n",
      "    main()\n",
      "  File \"/root/zindi/transformers/examples/pytorch/translation/run_translation.py\", line 612, in main\n",
      "    train_result = trainer.train(resume_from_checkpoint=checkpoint)\n",
      "  File \"/root/zindi/transformers/src/transformers/trainer.py\", line 1964, in train\n",
      "    return inner_training_loop(\n",
      "  File \"/root/zindi/transformers/src/transformers/trainer.py\", line 2305, in _inner_training_loop\n",
      "    tr_loss_step = self.training_step(model, inputs)\n",
      "  File \"/root/zindi/transformers/src/transformers/trainer.py\", line 3361, in training_step\n",
      "    loss = self.compute_loss(model, inputs)\n",
      "  File \"/root/zindi/transformers/src/transformers/trainer.py\", line 3408, in compute_loss\n",
      "    outputs = model(**inputs)\n",
      "  File \"/root/.cache/pypoetry/virtualenvs/zindi-LtLKIbXv-py3.9/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/root/.cache/pypoetry/virtualenvs/zindi-LtLKIbXv-py3.9/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/root/.cache/pypoetry/virtualenvs/zindi-LtLKIbXv-py3.9/lib/python3.9/site-packages/accelerate/utils/operations.py\", line 819, in forward\n",
      "    return model_forward(*args, **kwargs)\n",
      "  File \"/root/.cache/pypoetry/virtualenvs/zindi-LtLKIbXv-py3.9/lib/python3.9/site-packages/accelerate/utils/operations.py\", line 807, in __call__\n",
      "    return convert_to_fp32(self.model_forward(*args, **kwargs))\n",
      "  File \"/root/.cache/pypoetry/virtualenvs/zindi-LtLKIbXv-py3.9/lib/python3.9/site-packages/torch/amp/autocast_mode.py\", line 43, in decorate_autocast\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/root/zindi/transformers/src/transformers/models/marian/modeling_marian.py\", line 1399, in forward\n",
      "    outputs = self.model(\n",
      "  File \"/root/.cache/pypoetry/virtualenvs/zindi-LtLKIbXv-py3.9/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/root/.cache/pypoetry/virtualenvs/zindi-LtLKIbXv-py3.9/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/root/zindi/transformers/src/transformers/models/marian/modeling_marian.py\", line 1194, in forward\n",
      "    decoder_outputs = self.decoder(\n",
      "  File \"/root/.cache/pypoetry/virtualenvs/zindi-LtLKIbXv-py3.9/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/root/.cache/pypoetry/virtualenvs/zindi-LtLKIbXv-py3.9/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/root/zindi/transformers/src/transformers/models/marian/modeling_marian.py\", line 994, in forward\n",
      "    layer_outputs = decoder_layer(\n",
      "  File \"/root/.cache/pypoetry/virtualenvs/zindi-LtLKIbXv-py3.9/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/root/.cache/pypoetry/virtualenvs/zindi-LtLKIbXv-py3.9/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/root/zindi/transformers/src/transformers/models/marian/modeling_marian.py\", line 404, in forward\n",
      "    hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
      "  File \"/root/.cache/pypoetry/virtualenvs/zindi-LtLKIbXv-py3.9/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/root/.cache/pypoetry/virtualenvs/zindi-LtLKIbXv-py3.9/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/root/zindi/transformers/src/transformers/models/marian/modeling_marian.py\", line 186, in forward\n",
      "    value_states = self._shape(self.v_proj(hidden_states), -1, bsz)\n",
      "  File \"/root/.cache/pypoetry/virtualenvs/zindi-LtLKIbXv-py3.9/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/root/.cache/pypoetry/virtualenvs/zindi-LtLKIbXv-py3.9/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/root/.cache/pypoetry/virtualenvs/zindi-LtLKIbXv-py3.9/lib/python3.9/site-packages/torch/nn/modules/linear.py\", line 117, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "KeyboardInterrupt\n",
      "  0%|                             | 5147/7300000 [2:28:50<3515:42:22,  1.73s/it]\n"
     ]
    }
   ],
   "source": [
    "!python transformers/examples/pytorch/translation/run_translation.py \\\n",
    "--per_device_train_batch_size $$per_device_train_batch_size \\\n",
    "--save_steps $$save_steps \\\n",
    "--num_train_epochs $$num_train_epochs \\\n",
    "--logging_steps $$logging_steps \\\n",
    "--label_smoothing_factor $$label_smoothing_factor \\\n",
    "--learning_rate $$learning_rate \\\n",
    "--run_name $$run_name \\\n",
    "--output_dir $$output_dir \\\n",
    "--logging_dir $$logging_dir \\\n",
    "--eval_steps $$eval_steps \\\n",
    "--gradient_accumulation_steps $$gradient_accumulation_steps \\\n",
    "--model_name_or_path  $$model_name_or_path  \\\n",
    "--dataset_name  $$dataset_name  \\\n",
    "--generation_max_length $$generation_max_length \\\n",
    "--generation_num_beams $$generation_num_beams \\\n",
    "--source_lang $$source_lang \\\n",
    "--target_lang $$target_lang \\\n",
    "--dataset_config_name $$dataset_config_name \\\n",
    "--predict_with_generate $$predict_with_generate \\\n",
    "--max_source_length $$max_source_length \\\n",
    "--dataloader_drop_last $$dataloader_drop_last \\\n",
    "--warmup_steps $$warmup_steps \\\n",
    "--weight_decay $$weight_decay \\\n",
    "--save_total_limit $$save_total_limit \\\n",
    "--seed $$seed \\\n",
    "--overwrite_output_dir $$overwrite_output_dir \\\n",
    "--jit_mode_eval $$jit_mode_eval \\\n",
    "--do_eval $$do_eval \\\n",
    "--do_predict $$do_predict \\\n",
    "--do_train $$do_train \\\n",
    "--fp16 $$fp16 \\\n",
    "--fp16_backend $$fp16_backend \\\n",
    "--fp16_full_eval $$fp16_full_eval \\\n",
    "--full_determinism $$full_determinism \\\n",
    "--generation_config $$generation_config\n",
    "# --resume_from_checkpoint {resume_from_checkpoint} \n",
    "# --use_cpu {use_cpu} \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source text: o n'a ta b nin koni gona tntara\n",
      "Source tokens: [63, 7, 30905, 30890, 130, 840, 190, 8004, 110, 79, 1201, 5795, 5806, 2]\n",
      "Source token IDs: ['o', 'n', \"'\", 'a', 'ta', 'b', 'nin', 'koni', '', 'g', 'ona', 'tn', 'tara', '</s>']\n",
      "\n",
      "Target text: ce nest pas un petit dbat.\n",
      "Target tokens: [126, 7, 30980, 49, 74, 91, 1952, 11015, 30903, 2]\n",
      "Target token IDs: ['ce', 'n', '', 'est', 'pas', 'un', 'petit', 'dbat', '.', '</s>']\n",
      "\n",
      "==================================================\n",
      "\n",
      "Source text: Miseli asie laman be fogon dji sanf kunna tansn ksn.\n",
      "Source tokens: [6440, 875, 15, 3530, 19515, 40, 477, 2344, 3246, 6640, 1987, 13, 141, 1269, 22515, 30903, 2]\n",
      "Source token IDs: ['Mis', 'eli', 'a', 'sie', 'laman', 'be', 'fo', 'gon', 'dji', 'sanf', 'kunna', 't', 'ans', 'n', 'ksn', '.', '</s>']\n",
      "\n",
      "Target text: il fut par la suite recteur de l'universit et censeur royal.\n",
      "Target tokens: [157, 1084, 144, 23, 1912, 201, 3124, 27, 5, 30905, 12043, 65, 22426, 125, 15630, 30903, 2]\n",
      "Target token IDs: ['il', 'fut', 'par', 'la', 'suite', 're', 'cteur', 'de', 'l', \"'\", 'universit', 'et', 'cens', 'eur', 'royal', '.', '</s>']\n",
      "\n",
      "==================================================\n",
      "\n",
      "Source text: a wolo la yan f\n",
      "Source tokens: [15, 1188, 23, 736, 1256, 2]\n",
      "Source token IDs: ['a', 'wolo', 'la', 'yan', 'f', '</s>']\n",
      "\n",
      "Target text: cest lui, samuel!\n",
      "Target tokens: [22, 30980, 49, 256, 30912, 69, 444, 67, 30946, 2]\n",
      "Target token IDs: ['c', '', 'est', 'lui', ',', 'sa', 'mu', 'el', '!', '</s>']\n",
      "\n",
      "==================================================\n",
      "\n",
      "Source text: Komi Timbuktu sira ka gwr, mgw hakili ra sisan dugu d lo min be yr wr ani min yr ka jan.\n",
      "Source tokens: [5823, 1072, 9086, 30901, 327, 533, 19, 2332, 30912, 539, 894, 354, 885, 372, 205, 111, 72, 40, 448, 553, 214, 72, 448, 19, 776, 30903, 2]\n",
      "Source token IDs: ['Komi', 'Ti', 'mbu', 'k', 'tu', 'sira', 'ka', 'gwr', ',', 'mgw', 'hakili', 'ra', 'sisan', 'dugu', 'd', 'lo', 'min', 'be', 'yr', 'wr', 'ani', 'min', 'yr', 'ka', 'jan', '.', '</s>']\n",
      "\n",
      "Target text: Faire voler un drone prs dun aroport ou au-dessus dune foule est presque toujours une mauvaise ide, mme si ce nest pas illgal dans votre rgion.\n",
      "Target tokens: [6465, 18492, 91, 8604, 2193, 2302, 4, 30980, 25, 15, 12117, 447, 142, 30923, 4152, 4, 30980, 396, 2799, 140, 6528, 882, 207, 6956, 4565, 30912, 509, 107, 126, 7, 30980, 49, 74, 19827, 4432, 174, 1111, 3658, 30903, 2]\n",
      "Target token IDs: ['Faire', 'voler', 'un', 'dr', 'one', 'prs', 'd', '', 'un', 'a', 'roport', 'ou', 'au', '-', 'dessus', 'd', '', 'une', 'foule', 'est', 'presque', 'toujours', 'une', 'mauvaise', 'ide', ',', 'mme', 'si', 'ce', 'n', '', 'est', 'pas', 'ill', 'gal', 'dans', 'votre', 'rgion', '.', '</s>']\n",
      "\n",
      "==================================================\n",
      "\n",
      "Source text: O ya jamakulu ka yaala damin tuma minan o ya bolo kr dumunifen dgyala. O be k wagati tminan, jamakulu be gnaga dw dilan mun te m ani mun be ylma lon b.\n",
      "Source tokens: [156, 246, 11326, 19, 3467, 3649, 382, 3779, 63, 246, 754, 3691, 981, 4907, 21139, 48, 30903, 156, 40, 510, 962, 13, 7291, 30912, 11326, 40, 25464, 6300, 3119, 412, 181, 6901, 214, 412, 40, 7447, 698, 519, 30903, 2]\n",
      "Source token IDs: ['O', 'ya', 'jamakulu', 'ka', 'yaala', 'damin', 'tuma', 'minan', 'o', 'ya', 'bolo', 'kr', 'dumuni', 'fen', 'dgya', 'la', '.', 'O', 'be', 'k', 'wagati', 't', 'minan', ',', 'jamakulu', 'be', 'gnaga', 'dw', 'dilan', 'mun', 'te', 'm', 'ani', 'mun', 'be', 'ylma', 'lon', 'b', '.', '</s>']\n",
      "\n",
      "Target text: cest juste ce que jai fait.\n",
      "Target tokens: [22, 30980, 49, 2240, 126, 93, 35, 30980, 124, 279, 30903, 2]\n",
      "Target token IDs: ['c', '', 'est', 'juste', 'ce', 'que', 'j', '', 'ai', 'fait', '.', '</s>']\n",
      "\n",
      "==================================================\n",
      "\n",
      "Vocabulary size: 32000\n",
      "Special token IDs:\n",
      "<unk>: 0\n",
      "<s>: 1\n",
      "</s>: 2\n",
      "<pad>: 31999\n"
     ]
    }
   ],
   "source": [
    "from transformers import MarianTokenizer\n",
    "import random\n",
    "\n",
    "# Load your tokenizer\n",
    "tokenizer = MarianTokenizer.from_pretrained(\"/home/rana/Projects/zindi/models/marian/marian_output/base_model\")\n",
    "\n",
    "# Function to get a random sample from your dataset\n",
    "def get_random_sample(file_path, num_samples=5):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "    return random.sample(lines, num_samples)\n",
    "\n",
    "# Get samples from your source and target files\n",
    "source_samples = get_random_sample(\"/home/rana/Projects/zindi/data/all_dyu.txt\")\n",
    "target_samples = get_random_sample(\"/home/rana/Projects/zindi/data/all_fr.txt\")\n",
    "\n",
    "# Tokenize and print samples\n",
    "for src, tgt in zip(source_samples, target_samples):\n",
    "    src_tokens = tokenizer.encode(src.strip())\n",
    "    tgt_tokens = tokenizer.encode(tgt.strip())\n",
    "    \n",
    "    print(\"Source text:\", src.strip())\n",
    "    print(\"Source tokens:\", src_tokens)\n",
    "    print(\"Source token IDs:\", [tokenizer.convert_ids_to_tokens(id) for id in src_tokens])\n",
    "    print(\"\\nTarget text:\", tgt.strip())\n",
    "    print(\"Target tokens:\", tgt_tokens)\n",
    "    print(\"Target token IDs:\", [tokenizer.convert_ids_to_tokens(id) for id in tgt_tokens])\n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Print vocabulary size and special token IDs\n",
    "print(\"Vocabulary size:\", len(tokenizer))\n",
    "print(\"Special token IDs:\")\n",
    "for special_token in [\"<unk>\", \"<s>\", \"</s>\", \"<pad>\"]:\n",
    "    print(f\"{special_token}: {tokenizer.convert_tokens_to_ids(special_token)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zindi-z3yfXQo9-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
