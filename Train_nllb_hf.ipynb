{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.cache/pypoetry/virtualenvs/zindi-LtLKIbXv-py3.9/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, concatenate_datasets\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import DataCollatorForSeq2Seq\n",
    "from transformers import AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer, AutoConfig, GenerationConfig\n",
    "from transformers.integrations import TensorBoardCallback\n",
    "import evaluate\n",
    "import numpy as np\n",
    "metric = evaluate.load(\"bleu\")\n",
    "source_lang = \"dyu_Latn\"\n",
    "target_lang = \"fra_Latn\"\n",
    "checkpoint = \"/root/zindi/models/nllb/nllb_output/checkpoint-108\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#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\n",
    "#huggingface-cli login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "zindi_ds = load_dataset(\"uvci/Koumankan_mt_dyu_fr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import sys\n",
    "import unicodedata\n",
    "from sacremoses import MosesPunctNormalizer\n",
    "\n",
    "mpn = MosesPunctNormalizer(lang=\"fr\")\n",
    "mpn.substitutions = [\n",
    "    (re.compile(r), sub) for r, sub in mpn.substitutions\n",
    "]\n",
    "\n",
    "def get_non_printing_char_replacer(replace_by: str = \" \"):\n",
    "    non_printable_map = {\n",
    "        ord(c): replace_by\n",
    "        for c in (chr(i) for i in range(sys.maxunicode + 1))\n",
    "        # same as \\p{C} in perl\n",
    "        # see https://www.unicode.org/reports/tr44/#General_Category_Values\n",
    "        if unicodedata.category(c) in {\"C\", \"Cc\", \"Cf\", \"Cs\", \"Co\", \"Cn\"}\n",
    "    }\n",
    "\n",
    "    def replace_non_printing_char(line) -> str:\n",
    "        return line.translate(non_printable_map)\n",
    "\n",
    "    return replace_non_printing_char\n",
    "\n",
    "replace_nonprint = get_non_printing_char_replacer(\" \")\n",
    "\n",
    "def preproc(text):\n",
    "    clean = mpn.normalize(text)\n",
    "    clean = replace_nonprint(clean)\n",
    "    # replace ùìïùîØùîûùî´ùî†ùî¢ùî∞ùî†ùîû by Francesca\n",
    "    clean = unicodedata.normalize(\"NFKC\", clean)\n",
    "    return clean\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    inputs = [preproc(example[\"dyu\"]) for example in examples[\"translation\"]]\n",
    "    targets = [preproc(example[\"fr\"]) for example in examples[\"translation\"]]\n",
    "    model_inputs = tokenizer(inputs, text_target=targets, max_length=50, truncation=True, padding=\"max_length\")\n",
    "    # Check for None values in input_ids and labels\n",
    "    if None in model_inputs[\"input_ids\"] or None in model_inputs[\"labels\"]:\n",
    "        print(\"Warning: None values found in tokenized output\")\n",
    "        # Remove examples with None values\n",
    "        valid_indices = [i for i, (inp, lab) in enumerate(zip(model_inputs[\"input_ids\"], model_inputs[\"labels\"]))\n",
    "                         if inp is not None and lab is not None]\n",
    "        for key in model_inputs.keys():\n",
    "            model_inputs[key] = [model_inputs[key][i] for i in valid_indices]\n",
    "    return model_inputs\n",
    "\n",
    "def postprocess_text(preds, labels):\n",
    "    preds = [pred.strip() for pred in preds]\n",
    "    labels = [[label.strip()] for label in labels]\n",
    "\n",
    "    return preds, labels\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "    if isinstance(preds, tuple):\n",
    "        preds = preds[0]\n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n",
    "\n",
    "    result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "    print(result)\n",
    "    result = {\"bleu\": result[\"bleu\"]}\n",
    "\n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "    result = {k: round(v, 4) for k, v in result.items()}\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8065/8065 [00:00<00:00, 8337.47 examples/s]\n",
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1471/1471 [00:00<00:00, 6094.82 examples/s]\n",
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1393/1393 [00:00<00:00, 8935.73 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# source_lang = \"dyu_Latn\"\n",
    "# target_lang = \"fra_Latn\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint, src_lang=source_lang, tgt_lang=target_lang)\n",
    "# Apply preprocessing to the dataset\n",
    "tokenized_zds = zindi_ds.map(\n",
    "    preprocess_function,\n",
    "    batched=True,\n",
    "    remove_columns=zindi_ds[\"train\"].column_names  # Remove original columns\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_ds = concatenate_datasets([tokenized_zds['train'], tokenized_zds['test']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Max len of 50 is enough\n",
    "# def length_excluding_terminating_ones(list_of_lists):\n",
    "#     lengths = []\n",
    "#     for lst in list_of_lists:\n",
    "#         # Reverse the list and find the first occurrence of a number not equal to 1\n",
    "#         index = next((i for i, x in enumerate(reversed(lst)) if x != 1), len(lst))\n",
    "#         # Calculate the length excluding the trailing 1s\n",
    "#         lengths.append(len(lst) - index)\n",
    "#     return lengths\n",
    "# max(length_excluding_terminating_ones(tokenized_zds['validation']['input_ids']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# M2M100Config {\n",
    "#   \"_name_or_path\": \"facebook/nllb-200-distilled-600M\",\n",
    "#   \"activation_dropout\": 0.0,\n",
    "#   \"activation_function\": \"relu\",\n",
    "#   \"architectures\": [\n",
    "#     \"M2M100ForConditionalGeneration\"\n",
    "#   ],\n",
    "#   \"attention_dropout\": 0.1,\n",
    "#   \"bos_token_id\": 0,\n",
    "#   \"d_model\": 1024,\n",
    "#   \"decoder_attention_heads\": 16,\n",
    "#   \"decoder_ffn_dim\": 4096,\n",
    "#   \"decoder_layerdrop\": 0,\n",
    "#   \"decoder_layers\": 12,\n",
    "#   \"decoder_start_token_id\": 2,\n",
    "#   \"dropout\": 0.1,\n",
    "#   \"encoder_attention_heads\": 16,\n",
    "#   \"encoder_ffn_dim\": 4096,\n",
    "#   \"encoder_layerdrop\": 0,\n",
    "#   \"encoder_layers\": 12,\n",
    "#   \"eos_token_id\": 2,\n",
    "#   \"init_std\": 0.02,\n",
    "#   \"is_encoder_decoder\": true,\n",
    "#   \"max_length\": 200,\n",
    "#   \"max_position_embeddings\": 1024,\n",
    "#   \"model_type\": \"m2m_100\",\n",
    "#   \"num_hidden_layers\": 12,\n",
    "#   \"pad_token_id\": 1,\n",
    "#   \"scale_embedding\": true,\n",
    "#   \"tokenizer_class\": \"NllbTokenizer\",\n",
    "#   \"torch_dtype\": \"float32\",\n",
    "#   \"transformers_version\": \"4.45.0.dev0\",\n",
    "#   \"use_cache\": true,\n",
    "#   \"vocab_size\": 256206\n",
    "# }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!rm -rf models/nllb/nllb_output/base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 50}\n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 50}\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "# GenerationConfig {\n",
    "#   \"bos_token_id\": 0,\n",
    "#   \"decoder_start_token_id\": 2,\n",
    "#   \"eos_token_id\": 2,\n",
    "#   \"max_length\": 200,\n",
    "#   \"pad_token_id\": 1\n",
    "# }\n",
    "# Create a GenerationConfig object\n",
    "\n",
    "#Load model and config\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(checkpoint)\n",
    "config = AutoConfig.from_pretrained(checkpoint)\n",
    "\n",
    "#Save model,config and tokenizer\n",
    "model.save_pretrained('models/nllb/nllb_output/base_model')\n",
    "tokenizer.save_pretrained('models/nllb/nllb_output/base_model')\n",
    "\n",
    "#Update config\n",
    "config.dropout=0.5\n",
    "config.max_length=50\n",
    "config.save_pretrained('models/nllb/nllb_output/base_model')\n",
    "\n",
    "#Update generation config\n",
    "generation_config = GenerationConfig(\n",
    "  bos_token_id= 0,\n",
    "  decoder_start_token_id= 2,\n",
    "  eos_token_id= 2,\n",
    "  max_length= 50,\n",
    "  pad_token_id= 1\n",
    ")\n",
    "generation_config.save_pretrained('models/nllb/nllb_output/base_model')\n",
    "del model\n",
    "gc.collect()\n",
    "\n",
    "#Reload model\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained('models/nllb/nllb_output/base_model')\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model='models/nllb/nllb_output/base_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc, torch\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.synchronize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/root/.cache/pypoetry/virtualenvs/zindi-LtLKIbXv-py3.9/lib/python3.9/site-packages/accelerate/accelerator.py:488: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='621' max='1200000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [    621/1200000 1:52:26 < 3631:22:16, 0.09 it/s, Epoch 91.18/200000]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Bleu</th>\n",
       "      <th>Gen Len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.249700</td>\n",
       "      <td>0.694405</td>\n",
       "      <td>0.117100</td>\n",
       "      <td>11.405200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.254100</td>\n",
       "      <td>0.699035</td>\n",
       "      <td>0.117100</td>\n",
       "      <td>11.567000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.259000</td>\n",
       "      <td>0.702424</td>\n",
       "      <td>0.118400</td>\n",
       "      <td>11.766100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.250900</td>\n",
       "      <td>0.708485</td>\n",
       "      <td>0.118700</td>\n",
       "      <td>11.675700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.245500</td>\n",
       "      <td>0.712764</td>\n",
       "      <td>0.116500</td>\n",
       "      <td>11.475200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.234500</td>\n",
       "      <td>0.714981</td>\n",
       "      <td>0.114900</td>\n",
       "      <td>11.233900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.236400</td>\n",
       "      <td>0.717659</td>\n",
       "      <td>0.120200</td>\n",
       "      <td>11.420100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.239900</td>\n",
       "      <td>0.715488</td>\n",
       "      <td>0.117900</td>\n",
       "      <td>11.510500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.233400</td>\n",
       "      <td>0.724775</td>\n",
       "      <td>0.120200</td>\n",
       "      <td>11.645100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.227700</td>\n",
       "      <td>0.722733</td>\n",
       "      <td>0.121100</td>\n",
       "      <td>11.569700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.224100</td>\n",
       "      <td>0.732766</td>\n",
       "      <td>0.121200</td>\n",
       "      <td>11.865400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.230700</td>\n",
       "      <td>0.726157</td>\n",
       "      <td>0.122400</td>\n",
       "      <td>11.973500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.228400</td>\n",
       "      <td>0.738260</td>\n",
       "      <td>0.122200</td>\n",
       "      <td>11.815100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.269000</td>\n",
       "      <td>0.710062</td>\n",
       "      <td>0.119400</td>\n",
       "      <td>11.699500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.253700</td>\n",
       "      <td>0.712100</td>\n",
       "      <td>0.121600</td>\n",
       "      <td>11.772900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.263600</td>\n",
       "      <td>0.709331</td>\n",
       "      <td>0.116400</td>\n",
       "      <td>11.241300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.257600</td>\n",
       "      <td>0.714847</td>\n",
       "      <td>0.120400</td>\n",
       "      <td>11.561500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.250900</td>\n",
       "      <td>0.714142</td>\n",
       "      <td>0.121200</td>\n",
       "      <td>11.897300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.257700</td>\n",
       "      <td>0.716540</td>\n",
       "      <td>0.115400</td>\n",
       "      <td>11.095900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.255500</td>\n",
       "      <td>0.715142</td>\n",
       "      <td>0.117300</td>\n",
       "      <td>11.358300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.251600</td>\n",
       "      <td>0.717213</td>\n",
       "      <td>0.122500</td>\n",
       "      <td>11.883100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.248300</td>\n",
       "      <td>0.722027</td>\n",
       "      <td>0.119600</td>\n",
       "      <td>11.532300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.248200</td>\n",
       "      <td>0.722606</td>\n",
       "      <td>0.121000</td>\n",
       "      <td>11.397700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.241100</td>\n",
       "      <td>0.726952</td>\n",
       "      <td>0.117700</td>\n",
       "      <td>11.592100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.240300</td>\n",
       "      <td>0.729811</td>\n",
       "      <td>0.118000</td>\n",
       "      <td>11.236600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.242300</td>\n",
       "      <td>0.731155</td>\n",
       "      <td>0.116700</td>\n",
       "      <td>11.054400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.224700</td>\n",
       "      <td>0.735394</td>\n",
       "      <td>0.119000</td>\n",
       "      <td>11.291600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.242400</td>\n",
       "      <td>0.732252</td>\n",
       "      <td>0.120500</td>\n",
       "      <td>11.673700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.222300</td>\n",
       "      <td>0.736304</td>\n",
       "      <td>0.120400</td>\n",
       "      <td>11.714500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.228400</td>\n",
       "      <td>0.737333</td>\n",
       "      <td>0.121600</td>\n",
       "      <td>12.089700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.224400</td>\n",
       "      <td>0.740418</td>\n",
       "      <td>0.118700</td>\n",
       "      <td>11.647200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.222000</td>\n",
       "      <td>0.739839</td>\n",
       "      <td>0.117100</td>\n",
       "      <td>11.311400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.218800</td>\n",
       "      <td>0.742217</td>\n",
       "      <td>0.123900</td>\n",
       "      <td>11.949700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>0.206000</td>\n",
       "      <td>0.751489</td>\n",
       "      <td>0.121400</td>\n",
       "      <td>11.853800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.217500</td>\n",
       "      <td>0.748734</td>\n",
       "      <td>0.118400</td>\n",
       "      <td>11.652600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>0.220000</td>\n",
       "      <td>0.750691</td>\n",
       "      <td>0.119000</td>\n",
       "      <td>11.420100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.206100</td>\n",
       "      <td>0.760243</td>\n",
       "      <td>0.121200</td>\n",
       "      <td>11.576500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>0.200600</td>\n",
       "      <td>0.755872</td>\n",
       "      <td>0.121300</td>\n",
       "      <td>11.392900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>0.212500</td>\n",
       "      <td>0.752802</td>\n",
       "      <td>0.117900</td>\n",
       "      <td>11.286200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>0.210800</td>\n",
       "      <td>0.755980</td>\n",
       "      <td>0.122000</td>\n",
       "      <td>12.142800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.205400</td>\n",
       "      <td>0.760808</td>\n",
       "      <td>0.122100</td>\n",
       "      <td>11.435100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>0.199500</td>\n",
       "      <td>0.765022</td>\n",
       "      <td>0.120200</td>\n",
       "      <td>11.424200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>0.198800</td>\n",
       "      <td>0.763653</td>\n",
       "      <td>0.115300</td>\n",
       "      <td>11.184900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>0.200800</td>\n",
       "      <td>0.771278</td>\n",
       "      <td>0.117800</td>\n",
       "      <td>11.250200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>0.201000</td>\n",
       "      <td>0.770369</td>\n",
       "      <td>0.120500</td>\n",
       "      <td>11.930000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>0.188900</td>\n",
       "      <td>0.774351</td>\n",
       "      <td>0.119400</td>\n",
       "      <td>11.163200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>0.194600</td>\n",
       "      <td>0.771279</td>\n",
       "      <td>0.120800</td>\n",
       "      <td>11.958500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>0.198800</td>\n",
       "      <td>0.775974</td>\n",
       "      <td>0.122200</td>\n",
       "      <td>11.560800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.187100</td>\n",
       "      <td>0.782483</td>\n",
       "      <td>0.118900</td>\n",
       "      <td>11.138700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>0.182000</td>\n",
       "      <td>0.782706</td>\n",
       "      <td>0.119300</td>\n",
       "      <td>11.630200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>0.187100</td>\n",
       "      <td>0.783100</td>\n",
       "      <td>0.122100</td>\n",
       "      <td>11.620000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>0.180200</td>\n",
       "      <td>0.785157</td>\n",
       "      <td>0.122800</td>\n",
       "      <td>11.700200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>0.196700</td>\n",
       "      <td>0.784921</td>\n",
       "      <td>0.123000</td>\n",
       "      <td>12.254200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>0.192800</td>\n",
       "      <td>0.792248</td>\n",
       "      <td>0.121900</td>\n",
       "      <td>11.825300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>0.188300</td>\n",
       "      <td>0.791625</td>\n",
       "      <td>0.122200</td>\n",
       "      <td>12.129200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>0.176100</td>\n",
       "      <td>0.791369</td>\n",
       "      <td>0.122000</td>\n",
       "      <td>11.503100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.180500</td>\n",
       "      <td>0.796859</td>\n",
       "      <td>0.127500</td>\n",
       "      <td>11.923200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71</td>\n",
       "      <td>0.172900</td>\n",
       "      <td>0.797788</td>\n",
       "      <td>0.125700</td>\n",
       "      <td>11.984400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>0.164800</td>\n",
       "      <td>0.802638</td>\n",
       "      <td>0.121000</td>\n",
       "      <td>11.615900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73</td>\n",
       "      <td>0.171500</td>\n",
       "      <td>0.805646</td>\n",
       "      <td>0.124100</td>\n",
       "      <td>11.879000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.167800</td>\n",
       "      <td>0.804064</td>\n",
       "      <td>0.120400</td>\n",
       "      <td>11.276700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>0.168500</td>\n",
       "      <td>0.806333</td>\n",
       "      <td>0.119000</td>\n",
       "      <td>11.578500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77</td>\n",
       "      <td>0.168600</td>\n",
       "      <td>0.809811</td>\n",
       "      <td>0.115200</td>\n",
       "      <td>11.103300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78</td>\n",
       "      <td>0.162700</td>\n",
       "      <td>0.809880</td>\n",
       "      <td>0.124900</td>\n",
       "      <td>11.896000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.169600</td>\n",
       "      <td>0.809418</td>\n",
       "      <td>0.124500</td>\n",
       "      <td>11.970800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81</td>\n",
       "      <td>0.166100</td>\n",
       "      <td>0.813622</td>\n",
       "      <td>0.124600</td>\n",
       "      <td>11.667600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82</td>\n",
       "      <td>0.165200</td>\n",
       "      <td>0.811728</td>\n",
       "      <td>0.125800</td>\n",
       "      <td>12.044200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>83</td>\n",
       "      <td>0.167400</td>\n",
       "      <td>0.818740</td>\n",
       "      <td>0.116900</td>\n",
       "      <td>11.238600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>0.161400</td>\n",
       "      <td>0.819264</td>\n",
       "      <td>0.127400</td>\n",
       "      <td>12.283500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86</td>\n",
       "      <td>0.155100</td>\n",
       "      <td>0.819227</td>\n",
       "      <td>0.118900</td>\n",
       "      <td>11.159800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87</td>\n",
       "      <td>0.161900</td>\n",
       "      <td>0.823709</td>\n",
       "      <td>0.123700</td>\n",
       "      <td>12.077500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88</td>\n",
       "      <td>0.161400</td>\n",
       "      <td>0.825940</td>\n",
       "      <td>0.120700</td>\n",
       "      <td>11.422200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.154000</td>\n",
       "      <td>0.827297</td>\n",
       "      <td>0.126000</td>\n",
       "      <td>11.904100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bleu': 0.11711129409509477, 'precisions': [0.3869575361642557, 0.16603295310519645, 0.10192074753417546, 0.06276619592019726], 'brevity_penalty': 0.8225025962954745, 'length_ratio': 0.8365375231775154, 'translation_length': 8572, 'reference_length': 10247}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 50}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bleu': 0.11712021186375826, 'precisions': [0.3851266185401627, 0.16400220507166482, 0.09959555106167846, 0.0600346770697876], 'brevity_penalty': 0.8401522869864303, 'length_ratio': 0.8516639016297453, 'translation_length': 8727, 'reference_length': 10247}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 50}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bleu': 0.11835269389043589, 'precisions': [0.380515117581187, 0.16128167314653438, 0.09763265306122448, 0.05906908787309539], 'brevity_penalty': 0.8628793478853494, 'length_ratio': 0.8714745779252464, 'translation_length': 8930, 'reference_length': 10247}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 50}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bleu': 0.11867357851812017, 'precisions': [0.38450259418001353, 0.16375929682217716, 0.0984447385837194, 0.0596633283613893], 'brevity_penalty': 0.8557614759620363, 'length_ratio': 0.8652288474675515, 'translation_length': 8866, 'reference_length': 10247}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 50}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bleu': 0.11621035359545959, 'precisions': [0.38767695521002554, 0.16510423954106618, 0.1006872852233677, 0.06027580071174377], 'brevity_penalty': 0.8277674883789404, 'length_ratio': 0.8410266419439836, 'translation_length': 8618, 'reference_length': 10247}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 50}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bleu': 0.11645026253686239, 'precisions': [0.3902439024390244, 0.16562802935881457, 0.09884117246080436, 0.05887560867640549], 'brevity_penalty': 0.8361893987250133, 'length_ratio': 0.8482482677856934, 'translation_length': 8692, 'reference_length': 10247}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 50}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bleu': 0.11493819487601392, 'precisions': [0.390465924062762, 0.170689153823786, 0.1038037682189833, 0.06262857142857142], 'brevity_penalty': 0.7966557588134452, 'length_ratio': 0.8147750561139846, 'translation_length': 8349, 'reference_length': 10247}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 50}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bleu': 0.12020631807814525, 'precisions': [0.39134448932487015, 0.1690297470113984, 0.1031596925704526, 0.06350962602345651], 'brevity_penalty': 0.8331233472552837, 'length_ratio': 0.8456133502488533, 'translation_length': 8665, 'reference_length': 10247}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 50}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bleu': 0.11789233488700968, 'precisions': [0.3861488822309288, 0.16636603302344943, 0.10147382686769439, 0.06107367963486199], 'brevity_penalty': 0.8346005697879634, 'length_ratio': 0.8468820142480726, 'translation_length': 8678, 'reference_length': 10247}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 50}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bleu': 0.11501374945521445, 'precisions': [0.38954954954954957, 0.17172454041435659, 0.10453648915187377, 0.06300860265054639], 'brevity_penalty': 0.7938419675390699, 'length_ratio': 0.812432907192349, 'translation_length': 8325, 'reference_length': 10247}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 50}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bleu': 0.12022866612755323, 'precisions': [0.3853801830301661, 0.16571815718157182, 0.1004950495049505, 0.06118143459915612], 'brevity_penalty': 0.854086936438421, 'length_ratio': 0.8637650043915293, 'translation_length': 8851, 'reference_length': 10247}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 50}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bleu': 0.1211460982631057, 'precisions': [0.393781207444394, 0.16796076828769924, 0.10140797854508883, 0.06160208968219417], 'brevity_penalty': 0.849721934476216, 'length_ratio': 0.8599590123938714, 'translation_length': 8812, 'reference_length': 10247}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 50}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bleu': 0.12123538115178274, 'precisions': [0.38595909342178, 0.1622656456297861, 0.0980297157622739, 0.05987525987525988], 'brevity_penalty': 0.8755604354002521, 'length_ratio': 0.882697374841417, 'translation_length': 9045, 'reference_length': 10247}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 50}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bleu': 0.12241053048196006, 'precisions': [0.38355565274436915, 0.16130293159609121, 0.0984884645982498, 0.059640522875817], 'brevity_penalty': 0.8865830328247704, 'length_ratio': 0.8925539182199668, 'translation_length': 9146, 'reference_length': 10247}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 50}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bleu': 0.1213092096479343, 'precisions': [0.3833023306707517, 0.16066770996348462, 0.09626687847498014, 0.05932547744819179], 'brevity_penalty': 0.885822534984257, 'length_ratio': 0.8918707914511564, 'translation_length': 9139, 'reference_length': 10247}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 50}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bleu': 0.12222960957600523, 'precisions': [0.38570315109675984, 0.16511318242343542, 0.10025957170668397, 0.061436280614362807], 'brevity_penalty': 0.8685203539035803, 'length_ratio': 0.876451644383722, 'translation_length': 8981, 'reference_length': 10247}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 50}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bleu': 0.11941900184692854, 'precisions': [0.3889516493447808, 0.16501829020457934, 0.09893934371892608, 0.06015358361774744], 'brevity_penalty': 0.8541986468031265, 'length_ratio': 0.8638625939299307, 'translation_length': 8852, 'reference_length': 10247}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 50}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bleu': 0.12156522468201407, 'precisions': [0.38995108937305467, 0.16438538205980066, 0.09960873818063254, 0.059654300168634065], 'brevity_penalty': 0.8701742454622539, 'length_ratio': 0.8779154874597443, 'translation_length': 8996, 'reference_length': 10247}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 50}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bleu': 0.11639391073228435, 'precisions': [0.3961008083689967, 0.17086875090044662, 0.10368663594470046, 0.06258628624022089], 'brevity_penalty': 0.8040122679239887, 'length_ratio': 0.820923197033278, 'translation_length': 8412, 'reference_length': 10247}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 50}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bleu': 0.12201944281736665, 'precisions': [0.38830022075055187, 0.1628673079457109, 0.09864384888601872, 0.06001250260470931], 'brevity_penalty': 0.8772042192542276, 'length_ratio': 0.8841612179174393, 'translation_length': 9060, 'reference_length': 10247}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 50}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bleu': 0.12043263418014323, 'precisions': [0.38902828467153283, 0.16609565574893792, 0.10230136065849152, 0.06248643957474506], 'brevity_penalty': 0.8447778637312635, 'length_ratio': 0.8556650727042061, 'translation_length': 8768, 'reference_length': 10247}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 50}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bleu': 0.12118030038930838, 'precisions': [0.38717523493642897, 0.1622656456297861, 0.09853012437409142, 0.059276206322795344], 'brevity_penalty': 0.8755604354002521, 'length_ratio': 0.882697374841417, 'translation_length': 9045, 'reference_length': 10247}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 50}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bleu': 0.11538910383259839, 'precisions': [0.38766626360338574, 0.1707604059420503, 0.10640216411181244, 0.06548590072244233], 'brevity_penalty': 0.7873701333426283, 'length_ratio': 0.8070654825802674, 'translation_length': 8270, 'reference_length': 10247}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 50}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bleu': 0.11725258860790261, 'precisions': [0.3900709219858156, 0.169409071397911, 0.1045326774420239, 0.06369426751592357], 'brevity_penalty': 0.8095883952995467, 'length_ratio': 0.8256074948765493, 'translation_length': 8460, 'reference_length': 10247}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 50}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bleu': 0.12078141082364427, 'precisions': [0.38402320651567556, 0.16243993593166045, 0.09972253957891301, 0.06067604450976275], 'brevity_penalty': 0.8665325493361479, 'length_ratio': 0.8746950326924954, 'translation_length': 8963, 'reference_length': 10247}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 50}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bleu': 0.12250318614132011, 'precisions': [0.38386847622200154, 0.1620126448893572, 0.09998389953308646, 0.061076604554865424], 'brevity_penalty': 0.8775326923656148, 'length_ratio': 0.8844539865326437, 'translation_length': 9063, 'reference_length': 10247}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 50}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bleu': 0.11959262671909926, 'precisions': [0.38904299583911234, 0.16724690154574573, 0.10368978476255551, 0.06338339222614842], 'brevity_penalty': 0.8316443119831952, 'length_ratio': 0.844344686249634, 'translation_length': 8652, 'reference_length': 10247}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 50}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bleu': 0.12101359314026437, 'precisions': [0.3897968713518562, 0.16983791402396053, 0.10690846286701208, 0.0664288898796255], 'brevity_penalty': 0.821814192550625, 'length_ratio': 0.8359519859471065, 'translation_length': 8566, 'reference_length': 10247}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 50}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bleu': 0.11767908908243897, 'precisions': [0.38617374384800274, 0.1635012386457473, 0.10016891891891892, 0.060533216783216784], 'brevity_penalty': 0.8412821331023466, 'length_ratio': 0.8526397970137601, 'translation_length': 8737, 'reference_length': 10247}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 50}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bleu': 0.11669048672074253, 'precisions': [0.39006329869819656, 0.16966096783541001, 0.10554371002132196, 0.06498277841561424], 'brevity_penalty': 0.7994633073142109, 'length_ratio': 0.8171172050356201, 'translation_length': 8373, 'reference_length': 10247}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 50}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bleu': 0.11801541012187038, 'precisions': [0.39019725044829645, 0.17188859878154916, 0.10716833095577746, 0.06637372802960222], 'brevity_penalty': 0.7985281512486925, 'length_ratio': 0.8163364887284084, 'translation_length': 8365, 'reference_length': 10247}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 50}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bleu': 0.11674636881142783, 'precisions': [0.3928092626447288, 0.1744876744876745, 0.10926669098869025, 0.06712361143937604], 'brevity_penalty': 0.7796792680772735, 'length_ratio': 0.800722162584171, 'translation_length': 8205, 'reference_length': 10247}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 50}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bleu': 0.11896928208872795, 'precisions': [0.3949219215639528, 0.17259323503902863, 0.10768956924172303, 0.06618838231890765], 'brevity_penalty': 0.8013315397936626, 'length_ratio': 0.8186786376500439, 'translation_length': 8389, 'reference_length': 10247}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 50}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bleu': 0.12051660848215867, 'precisions': [0.3891032917139614, 0.16500885679247854, 0.1015389762462362, 0.062134661182074044], 'brevity_penalty': 0.8494976517418725, 'length_ratio': 0.8597638333170684, 'translation_length': 8810, 'reference_length': 10247}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 50}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bleu': 0.11763188418095266, 'precisions': [0.38675917215428035, 0.16721171619508032, 0.10464913808114226, 0.06422636424882101], 'brevity_penalty': 0.8146779716379029, 'length_ratio': 0.8299014345662145, 'translation_length': 8504, 'reference_length': 10247}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 50}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bleu': 0.12036879311190843, 'precisions': [0.38754090960388216, 0.16400541271989175, 0.10071345611415297, 0.061307609860664525], 'brevity_penalty': 0.8552035617801065, 'length_ratio': 0.864740899775544, 'translation_length': 8861, 'reference_length': 10247}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 50}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bleu': 0.12164443514940208, 'precisions': [0.3843834141087776, 0.1577937036089071, 0.09520836584985172, 0.057388522295540895], 'brevity_penalty': 0.9015786741779402, 'length_ratio': 0.906118864057773, 'translation_length': 9285, 'reference_length': 10247}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 50}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bleu': 0.11874344443408902, 'precisions': [0.3859187178019462, 0.16492290748898678, 0.10105935765932403, 0.061771058315334776], 'brevity_penalty': 0.8410562494288131, 'length_ratio': 0.8524446179369571, 'translation_length': 8735, 'reference_length': 10247}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 50}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bleu': 0.11714117882053116, 'precisions': [0.38564809314482595, 0.16757846242441693, 0.10527246992215145, 0.0660398991057097], 'brevity_penalty': 0.8045942772800627, 'length_ratio': 0.8214111447252854, 'translation_length': 8417, 'reference_length': 10247}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 50}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bleu': 0.11970865615070135, 'precisions': [0.3912129002103295, 0.16918301114717088, 0.10512642881884308, 0.06499327655759748], 'brevity_penalty': 0.8208957178307029, 'length_ratio': 0.8351712696398946, 'translation_length': 8558, 'reference_length': 10247}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 50}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bleu': 0.12388995206553237, 'precisions': [0.38931633326005716, 0.1625803068047725, 0.10017716218392655, 0.06157378417866834], 'brevity_penalty': 0.881357899998883, 'length_ratio': 0.8878696203766956, 'translation_length': 9098, 'reference_length': 10247}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 50}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bleu': 0.12142253792191339, 'precisions': [0.39231885676007594, 0.16283729628640128, 0.09990141307919816, 0.06059312993385961], 'brevity_penalty': 0.8658691873060747, 'length_ratio': 0.8741094954620865, 'translation_length': 8957, 'reference_length': 10247}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 50}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bleu': 0.1184261157948861, 'precisions': [0.38590680676107814, 0.1633493479752917, 0.10063844086021505, 0.061268672872916215], 'brevity_penalty': 0.8434258955743296, 'length_ratio': 0.8544939982433883, 'translation_length': 8756, 'reference_length': 10247}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 50}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bleu': 0.11902594035191454, 'precisions': [0.38768582465176166, 0.167420814479638, 0.10539088230195874, 0.0651589789520824], 'brevity_penalty': 0.819171719435908, 'length_ratio': 0.8337074265638723, 'translation_length': 8543, 'reference_length': 10247}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 50}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bleu': 0.11738219050167567, 'precisions': [0.38794705062703205, 0.16482285394202492, 0.10226882090065315, 0.06204136090727151], 'brevity_penalty': 0.8270820538641993, 'length_ratio': 0.8404411047135747, 'translation_length': 8612, 'reference_length': 10247}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 50}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bleu': 0.12116579624870609, 'precisions': [0.38948092127878997, 0.1657938257993385, 0.10413839891451832, 0.06433135051773518], 'brevity_penalty': 0.8401522869864303, 'length_ratio': 0.8516639016297453, 'translation_length': 8727, 'reference_length': 10247}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 50}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bleu': 0.12132341669576559, 'precisions': [0.39127366811713515, 0.17007963594994313, 0.1086501569584932, 0.06806400721208024], 'brevity_penalty': 0.8145625315875773, 'length_ratio': 0.829803845027813, 'translation_length': 8503, 'reference_length': 10247}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 50}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bleu': 0.1179356297419643, 'precisions': [0.3899595527004521, 0.16914203316510454, 0.1065036328194223, 0.0661308840413318], 'brevity_penalty': 0.8033134995818489, 'length_ratio': 0.8203376598028691, 'translation_length': 8406, 'reference_length': 10247}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 50}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bleu': 0.12202873582787761, 'precisions': [0.38030006523157206, 0.15827617445321598, 0.09783809373520594, 0.05941794664510913], 'brevity_penalty': 0.8922164384307543, 'length_ratio': 0.8976285742168439, 'translation_length': 9198, 'reference_length': 10247}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 50}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bleu': 0.12165697802009884, 'precisions': [0.38768489852081184, 0.16537931034482758, 0.10452312383533796, 0.06581834137779728], 'brevity_penalty': 0.8394738659076754, 'length_ratio': 0.8510783643993364, 'translation_length': 8721, 'reference_length': 10247}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 50}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bleu': 0.12210339323489289, 'precisions': [0.3900551190336578, 0.1707766439909297, 0.10853658536585366, 0.06889541450192004], 'brevity_penalty': 0.8173301149381055, 'length_ratio': 0.8321459939494487, 'translation_length': 8527, 'reference_length': 10247}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 50}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bleu': 0.12022375855849747, 'precisions': [0.3878171401847305, 0.16958486303304152, 0.10540867461551753, 0.06654796349877587], 'brevity_penalty': 0.8203213210593847, 'length_ratio': 0.8346833219478872, 'translation_length': 8553, 'reference_length': 10247}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 50}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bleu': 0.11527258897967484, 'precisions': [0.3846246681148926, 0.17006603081438004, 0.1065397053539346, 0.06529289187311878], 'brevity_penalty': 0.7892562339846001, 'length_ratio': 0.8086269151946911, 'translation_length': 8286, 'reference_length': 10247}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 50}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bleu': 0.11780022554993393, 'precisions': [0.39075530140576603, 0.1698685540950455, 0.10620567375886525, 0.06605504587155964], 'brevity_penalty': 0.8019147939225872, 'length_ratio': 0.8191665853420513, 'translation_length': 8394, 'reference_length': 10247}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 50}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bleu': 0.12033960559450518, 'precisions': [0.380623973727422, 0.1589248434237996, 0.09632224168126094, 0.05857142857142857], 'brevity_penalty': 0.8853877349037641, 'length_ratio': 0.8914804332975506, 'translation_length': 9135, 'reference_length': 10247}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 50}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bleu': 0.12048761690978936, 'precisions': [0.3822139166758272, 0.16076580120639916, 0.09741296710316193, 0.05837926107368851], 'brevity_penalty': 0.8812487866146104, 'length_ratio': 0.8877720308382941, 'translation_length': 9097, 'reference_length': 10247}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 50}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bleu': 0.11944153746310103, 'precisions': [0.3925301204819277, 0.17323180553521744, 0.10975170924793091, 0.0696969696969697], 'brevity_penalty': 0.7909042931780006, 'length_ratio': 0.8099931687323119, 'translation_length': 8300, 'reference_length': 10247}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 50}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bleu': 0.12083796590220613, 'precisions': [0.37978323379783235, 0.1606128648791441, 0.09837646680597975, 0.06055008210180624], 'brevity_penalty': 0.8752313948463067, 'length_ratio': 0.8824046062262125, 'translation_length': 9042, 'reference_length': 10247}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 50}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bleu': 0.12219457118684075, 'precisions': [0.39118393722594047, 0.16775538568450313, 0.10537119397878891, 0.06688888888888889], 'brevity_penalty': 0.833237044102556, 'length_ratio': 0.8457109397872548, 'translation_length': 8666, 'reference_length': 10247}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 50}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bleu': 0.11680627866580512, 'precisions': [0.3875399739429113, 0.16695352839931152, 0.10411537108688006, 0.06495571201453554], 'brevity_penalty': 0.807616366261078, 'length_ratio': 0.8239484727237241, 'translation_length': 8443, 'reference_length': 10247}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 50}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bleu': 0.11891963992321684, 'precisions': [0.3931748933577087, 0.17508167508167508, 0.11151670012776053, 0.07049917198959073], 'brevity_penalty': 0.7796792680772735, 'length_ratio': 0.800722162584171, 'translation_length': 8205, 'reference_length': 10247}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 50}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bleu': 0.11927418218337504, 'precisions': [0.3873190902825637, 0.16627505183137525, 0.10224776068953861, 0.06239130434782609], 'brevity_penalty': 0.8377761277848439, 'length_ratio': 0.8496145213233142, 'translation_length': 8706, 'reference_length': 10247}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 50}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bleu': 0.12211836366569179, 'precisions': [0.3901174844505874, 0.16946331992788796, 0.10563020921925498, 0.0654945054945055], 'brevity_penalty': 0.8350547352617792, 'length_ratio': 0.8472723724016785, 'translation_length': 8682, 'reference_length': 10247}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 50}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bleu': 0.12277550736269136, 'precisions': [0.38812941444520394, 0.1665526207745997, 0.10488336969290149, 0.06545296922410056], 'brevity_penalty': 0.8459033294741843, 'length_ratio': 0.856640968088221, 'translation_length': 8778, 'reference_length': 10247}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 50}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bleu': 0.11984991196787205, 'precisions': [0.38320330426801286, 0.16521739130434782, 0.10313447927199192, 0.06379757785467129], 'brevity_penalty': 0.8389082207728882, 'length_ratio': 0.8505904167073289, 'translation_length': 8716, 'reference_length': 10247}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 50}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bleu': 0.12295592029194351, 'precisions': [0.37666380420781453, 0.15768005098789037, 0.09707385044124478, 0.059124950729207724], 'brevity_penalty': 0.9048956962598861, 'length_ratio': 0.909144139748219, 'translation_length': 9316, 'reference_length': 10247}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 50}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bleu': 0.12193381638369097, 'precisions': [0.38525683789192794, 0.16177057025122957, 0.10074869791666667, 0.061464233270400674], 'brevity_penalty': 0.8699538637127764, 'length_ratio': 0.8777203083829413, 'translation_length': 8994, 'reference_length': 10247}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 50}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bleu': 0.12216368642957541, 'precisions': [0.38037940379403795, 0.15849883930874387, 0.09738829452485841, 0.05908449284129865], 'brevity_penalty': 0.8951303687932044, 'length_ratio': 0.900263491753684, 'translation_length': 9225, 'reference_length': 10247}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 50}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bleu': 0.12203973011282104, 'precisions': [0.38890830711872304, 0.16957255343082114, 0.1078194970719945, 0.067747667703243], 'brevity_penalty': 0.8237636632435801, 'length_ratio': 0.8376110080999317, 'translation_length': 8583, 'reference_length': 10247}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 50}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bleu': 0.12019561662881598, 'precisions': [0.39037183820958155, 0.16980866629150254, 0.10546334716459198, 0.06497871386959445], 'brevity_penalty': 0.8233052441383305, 'length_ratio': 0.8372206499463257, 'translation_length': 8579, 'reference_length': 10247}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 50}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bleu': 0.127470850093765, 'precisions': [0.38994535519125684, 0.16525589269436125, 0.10274409700063816, 0.06441654661452974], 'brevity_penalty': 0.8870173732094067, 'length_ratio': 0.8929442763735728, 'translation_length': 9150, 'reference_length': 10247}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 50}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bleu': 0.12569305063608194, 'precisions': [0.3829506756014501, 0.16430817610062892, 0.10231444533120511, 0.0640947132067769], 'brevity_penalty': 0.8819033097639368, 'length_ratio': 0.888357568068703, 'translation_length': 9103, 'reference_length': 10247}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 50}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bleu': 0.12103010904218549, 'precisions': [0.3839518783339008, 0.16580381471389646, 0.10277731581573257, 0.06294004693834009], 'brevity_penalty': 0.8496097984356122, 'length_ratio': 0.8598614228554698, 'translation_length': 8811, 'reference_length': 10247}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 50}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bleu': 0.12405153540137381, 'precisions': [0.3827893175074184, 0.16360776088096488, 0.1010230179028133, 0.0620012277470841], 'brevity_penalty': 0.8814670029051701, 'length_ratio': 0.8879672099150971, 'translation_length': 9099, 'reference_length': 10247}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 50}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bleu': 0.11772016725284387, 'precisions': [0.38911242603550295, 0.1689353775612552, 0.10482879719051799, 0.06524694154961486], 'brevity_penalty': 0.8084287565598959, 'length_ratio': 0.8246315994925344, 'translation_length': 8450, 'reference_length': 10247}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 50}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bleu': 0.12041336443748354, 'precisions': [0.38654761904761903, 0.17159763313609466, 0.1093224836370069, 0.06986301369863014], 'brevity_penalty': 0.8026143416016254, 'length_ratio': 0.8197521225724602, 'translation_length': 8400, 'reference_length': 10247}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 50}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bleu': 0.11896766207567198, 'precisions': [0.38315280018437425, 0.16567226307756347, 0.10294615645106671, 0.06317846287451151], 'brevity_penalty': 0.8346005697879634, 'length_ratio': 0.8468820142480726, 'translation_length': 8678, 'reference_length': 10247}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 50}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bleu': 0.11523461794229725, 'precisions': [0.38733774185647807, 0.17266616878267363, 0.108330288637194, 0.06745005875440659], 'brevity_penalty': 0.7750427192294073, 'length_ratio': 0.7969161705865131, 'translation_length': 8166, 'reference_length': 10247}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 50}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bleu': 0.12492696620026558, 'precisions': [0.3886729594669628, 0.16551632598885055, 0.1038961038961039, 0.06326999373564418], 'brevity_penalty': 0.871165441454367, 'length_ratio': 0.8787937933053577, 'translation_length': 9005, 'reference_length': 10247}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 50}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bleu': 0.12950977048154352, 'precisions': [0.3864951768488746, 0.16554268990965773, 0.10297305667389285, 0.06326611308817714], 'brevity_penalty': 0.9063904533435665, 'length_ratio': 0.9105103932858397, 'translation_length': 9330, 'reference_length': 10247}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 50}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bleu': 0.12454516164277749, 'precisions': [0.3828047298043983, 0.16442333069411455, 0.10276616275329688, 0.06316872427983539], 'brevity_penalty': 0.8759990089584934, 'length_ratio': 0.883087732995023, 'translation_length': 9049, 'reference_length': 10247}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 50}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bleu': 0.1245714212587496, 'precisions': [0.39018850783556663, 0.1694614860259032, 0.10610878661087866, 0.06604590731918579], 'brevity_penalty': 0.8490489584247445, 'length_ratio': 0.8593734751634625, 'translation_length': 8806, 'reference_length': 10247}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 50}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bleu': 0.12576617734001633, 'precisions': [0.38318979614084814, 0.16424305375227213, 0.10188261351052048, 0.06232294617563739], 'brevity_penalty': 0.8895115894101571, 'length_ratio': 0.8951888357568069, 'translation_length': 9173, 'reference_length': 10247}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 50}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bleu': 0.11690575770007212, 'precisions': [0.38381044022131344, 0.1705392371766769, 0.10799213302342213, 0.06697353279631761], 'brevity_penalty': 0.7925502259825656, 'length_ratio': 0.8113594222699326, 'translation_length': 8314, 'reference_length': 10247}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 50}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bleu': 0.11979349111263884, 'precisions': [0.3758927590374684, 0.15858453473132372, 0.0974637103206253, 0.05865580448065173], 'brevity_penalty': 0.8816851772864813, 'length_ratio': 0.8881623889919, 'translation_length': 9101, 'reference_length': 10247}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 50}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bleu': 0.12738937551702847, 'precisions': [0.3790443539747161, 0.16266056212641486, 0.10100541376643465, 0.06253698954428881], 'brevity_penalty': 0.9068171554790965, 'length_ratio': 0.9109007514394457, 'translation_length': 9334, 'reference_length': 10247}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 50}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bleu': 0.11890064620459145, 'precisions': [0.3864623552123552, 0.17324336218277836, 0.1101878612716763, 0.06973467950223057], 'brevity_penalty': 0.7894918012197684, 'length_ratio': 0.8088220942714941, 'translation_length': 8288, 'reference_length': 10247}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 50}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bleu': 0.12374910080054202, 'precisions': [0.37474165125639075, 0.15993265993265993, 0.10015723270440252, 0.0618], 'brevity_penalty': 0.8916759894174714, 'length_ratio': 0.8971406265248365, 'translation_length': 9193, 'reference_length': 10247}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 50}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bleu': 0.1207480096252133, 'precisions': [0.3839897757639131, 0.16704035874439463, 0.10601374570446735, 0.06699201419698314], 'brevity_penalty': 0.826510562821342, 'length_ratio': 0.8399531570215673, 'translation_length': 8607, 'reference_length': 10247}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 50}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bleu': 0.1262568936426746, 'precisions': [0.38239173444713126, 0.16454700406450767, 0.10339852516832318, 0.06472892187177902], 'brevity_penalty': 0.881357899998883, 'length_ratio': 0.8878696203766956, 'translation_length': 9098, 'reference_length': 10247}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 50}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bleu': 0.1259724319826109, 'precisions': [0.3875719982277359, 0.16567420934233162, 0.10363872644574398, 0.06494325346784363], 'brevity_penalty': 0.8736946206868657, 'length_ratio': 0.8810383526885918, 'translation_length': 9028, 'reference_length': 10247}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 50}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 45\u001b[0m\n\u001b[1;32m      1\u001b[0m training_args \u001b[38;5;241m=\u001b[39m Seq2SeqTrainingArguments(\n\u001b[1;32m      2\u001b[0m     output_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels/nllb/nllb_output\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      3\u001b[0m     eval_strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     32\u001b[0m     run_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest3\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     33\u001b[0m )\n\u001b[1;32m     35\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Seq2SeqTrainer(\n\u001b[1;32m     36\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     37\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     42\u001b[0m     compute_metrics\u001b[38;5;241m=\u001b[39mcompute_metrics,\n\u001b[1;32m     43\u001b[0m )\n\u001b[0;32m---> 45\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/zindi/transformers/src/transformers/trainer.py:1955\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1953\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1954\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1955\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1956\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1957\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1958\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1959\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1960\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/zindi/transformers/src/transformers/trainer.py:2296\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2293\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_begin(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[1;32m   2295\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[0;32m-> 2296\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2298\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2299\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2300\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m   2301\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2302\u001b[0m ):\n\u001b[1;32m   2303\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2304\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m~/zindi/transformers/src/transformers/trainer.py:3413\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   3411\u001b[0m         scaled_loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m   3412\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3413\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3415\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mdetach() \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mgradient_accumulation_steps\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/zindi-LtLKIbXv-py3.9/lib/python3.9/site-packages/accelerate/accelerator.py:2155\u001b[0m, in \u001b[0;36mAccelerator.backward\u001b[0;34m(self, loss, **kwargs)\u001b[0m\n\u001b[1;32m   2153\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   2154\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 2155\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2156\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m learning_rate \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhas_lomo_optimizer:\n\u001b[1;32m   2157\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlomo_backward(loss, learning_rate)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/zindi-LtLKIbXv-py3.9/lib/python3.9/site-packages/torch/_tensor.py:521\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    513\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    514\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    519\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    520\u001b[0m     )\n\u001b[0;32m--> 521\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/zindi-LtLKIbXv-py3.9/lib/python3.9/site-packages/torch/autograd/__init__.py:289\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    284\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    286\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 289\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/zindi-LtLKIbXv-py3.9/lib/python3.9/site-packages/torch/autograd/graph.py:768\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    766\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    767\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 768\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    769\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    770\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    771\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    772\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"models/nllb/nllb_output\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    learning_rate=1e-4,\n",
    "    per_device_train_batch_size=70,\n",
    "    per_device_eval_batch_size=70,\n",
    "    # weight_decay=0.01,\n",
    "    num_train_epochs=200000,\n",
    "    predict_with_generate=True,\n",
    "    fp16=True,\n",
    "    # push_to_hub=False,\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    gradient_accumulation_steps=20,\n",
    "    logging_dir= \"models/nllb/nllb_output/logs\",\n",
    "    logging_steps = 1,\n",
    "    save_strategy = 'epoch',\n",
    "    save_steps = 2,\n",
    "    save_total_limit = 3,\n",
    "    seed = 42,\n",
    "    dataloader_drop_last = False,\n",
    "    eval_steps = 1,\n",
    "    # label_smoothing_factor: float = 0.0,\n",
    "    optim = 'adafactor',\n",
    "    # resume_from_checkpoint: Optional[str] = None,\n",
    "    # fp16_backend: str = 'auto',\n",
    "    # batch_eval_metrics: bool = False,\n",
    "    # eval_on_start=True,\n",
    "    # generation_max_length= 50,\n",
    "    generation_num_beams=2,\n",
    "    generation_config = \"models/nllb/nllb_output/base_model/generation_config.json\",\n",
    "    run_name=\"Test3\"\n",
    ")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=concat_ds,\n",
    "    eval_dataset=tokenized_zds[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 100}\n"
     ]
    }
   ],
   "source": [
    "# trainer.save_model(\"/root/zindi/models/nllb/nllb_output/checkpoint-300\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zindi-z3yfXQo9-py3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
